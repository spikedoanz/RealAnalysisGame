msgid ""
msgstr "Project-Id-Version: Game v4.23.0-rc2\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-12-11\n"
"Last-Translator: \n"
"Language-Team: none\n"
"Language: en\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit"

#: Game.Levels.L6Pset.L6Pset3
msgid "# Problem 3\n"
"\n"
"You are given that a sequence `a : ℕ → ℝ` converges to 5.\n"
"Prove that it is eventually positive."
msgstr ""

#: Game.Levels.L3Levels.L01_ArchProp
msgid "Prove the \\\"Archimedean Property\\\"\n"
"that no matter how small `ε > 0` may be,\n"
"there is always a natural number `N` with `1 / ε < N`."
msgstr ""

#: Game.Levels.L23Levels.L03
msgid "A continuous function on a compact set is uniformly continuous on that set."
msgstr ""

#: Game.Levels.L10Pset.L10Pset6
msgid "# Problem 5:\n"
"\n"
"Show that the sequence `a n = n` is unbounded."
msgstr ""

#: Game.Levels.L16Levels.L01_check
msgid "`(a : ℕ → ℝ) : Prop := SeqConv (Series a)`\n"
"\n"
"The Series of a sequence `a : N → ℝ` converges if the sequence of its partial sums converges."
msgstr ""

#: Game.Levels.L20Pset.L03
msgid "If `f → L` as `x → c`, then `k · f → k · L`."
msgstr ""

#: Game.Levels.L7Levels.L02_SeqOfAbs
msgid "The absolute value function is Lipschitz with constant 1."
msgstr ""

#: Game.Levels.L10Pset.L10Pset5
msgid "# Problem 4:\n"
"\n"
"Exhibit (by starting with `let a : ℕ → ℝ := fun n ↦ ???`)\n"
"a sequence so that\n"
"\n"
"- the terms are all strictly positive: `∀ n, 0 < a n`,\n"
"- and yet the sequence converges to zero (and not something strictly positive!).\n"
"\n"
"When you define a new sequence using `let`, you might find it\n"
"convenient to immediately prove a trivial theorem restating the definition:\n"
"\n"
"`have ha : ∀ n, a n = ??? := by intro n; rfl`\n"
"\n"
"This may become useful should you want to `rewrite` by `ha` (you can't rewrite by `a`, since it's a definition, not a theorem!)...\n"
"\n"
"**Extra challenge:** See if you can do it by using theorems we already proved, not by going into the `ε-N` definition..."
msgstr ""

#: Game.Levels.L1RealAnalysisStory.L05_use
msgid "The `use` tactic provides a specific value to prove an existence statement."
msgstr ""

#: Game.Levels.L5Levels.L01_DoubleSeqConv
msgid "You can't use `abs_mul` just yet, because you don't have a product of things inside the absolute values! So first factor out the 2: `have factor : 2 * a n - 2 * L = 2 * (a n - L) := by ring_nf`"
msgstr ""

#: Game
msgid "Learn real analysis through the historical crises that forced mathematicians to rebuild calculus from the ground up in the 19th century."
msgstr ""

#: Game.Levels.L7Levels.L04_ByCases
msgid "ByCases"
msgstr ""

#: Game.Levels.L14Lecture
msgid "# Lecture 14: Bolzano-Weierstrass"
msgstr ""

#: Game.Levels.L23Levels.L03
msgid "`IsCompact (S : Set ℝ) : Prop :=\n"
"  ∀ (ι : Type) (xs : ι → ℝ) (δs : ι → ℝ), (∀ i, 0 < δs i) → (S ⊆ ⋃ i, Ball (xs i) (δs i)) →\n"
"    ∃ (V : Finset ι), S ⊆ ⋃ i ∈ V, Ball (xs i) (δs i)`\n"
"\n"
"A set `S` is compact if for every cover of `S` by balls, there exists a finite subcover."
msgstr ""

#: Game.Levels.L11Levels.L01_IsCauchyOfLim
msgid "# Congratulations! You've proven that convergence implies Cauchy!\n"
"\n"
"This is one of the most fundamental results in analysis. You've just shown that the \"self-referential\" Cauchy property is a *necessary condition* for convergence.\n"
"\n"
"## What you've learned\n"
"\n"
"- How to work with the Cauchy definition using multiple indices `m` and `n`\n"
"- The power of the `ε/2` trick to make inequalities work out\n"
"- How to use `abs_sub_comm` to flip differences inside absolute values\n"
"- How to connect a sequence to itself rather than to an external limit\n"
"\n"
"## The Big Question\n"
"\n"
"You've proven: **convergence ⟹ Cauchy**\n"
"\n"
"But what about the converse? Is every Cauchy sequence convergent?\n"
"\n"
"- **For rational sequences**: NO! The sequence `1, 1.4, 1.41, 1.414, ...` is Cauchy in ℚ but doesn't converge to a rational number.\n"
"- **For real sequences**: This is the *Cauchy Completeness Theorem*, and it's **YES**! But we'll need to carefully construct the real numbers first to prove it.\n"
"\n"
"This is why Cauchy sequences are so important—they give us a way to *define* the real numbers as the completion of the rationals!\n"
"\n"
"Onward to the next level!"
msgstr ""

#: Game.Levels.L4Levels.L01_NonConverge
msgid "`(a : ℕ → ℝ) := ∃ L, SeqLim a L`\n"
"\n"
"A sequence `a : N → ℝ` converges (`SeqConv a` holds) if there exists some\n"
"`L : ℝ` so that `a → L`, that is, `SeqLim a L` holds."
msgstr ""

#: Game.Levels.L6Levels.L04_Cases'
msgid "When have a hypothesis `h : P ∨ Q`, you can say `cases' h with h1 h2`; this will make two new Game Boards, one with an extra hypothesis `h1 : P`, and the other with the hypothesis `h2 : Q`. You'll have to solve both to solve the original Goal!"
msgstr ""

#: Game.Levels.L17Levels.L04
msgid "Magnificent! You've proven that the Basel series converges—a major milestone in the history of mathematics!\n"
"\n"
"## What You've Accomplished\n"
"\n"
"**Theorem:** The series `∑ k, 1/(k+2)² = 1/4 + 1/9 + 1/16 + ...` converges.\n"
"\n"
"You proved this using the **Monotone Bounded Convergence Theorem**, which you first established by connecting two powerful results:\n"
"- `IsCauchy_of_MonotoneBdd`: monotone bounded sequences are Cauchy\n"
"- `Conv_of_IsCauchy`: by completeness of ℝ, Cauchy sequences converge\n"
"\n"
"## The Proof Strategy\n"
"\n"
"Your proof had three elegant components:\n"
"\n"
"1. **Comparison with Leibniz:** You showed `1/(k+2)² ≤ 1/((k+1)(k+2))`, so by `SeriesOrderThm`, the Basel partial sums are bounded by the Leibniz partial sums, which equal `1 - 1/(n+1) < 1`.\n"
"\n"
"2. **Boundedness:** The Basel series has partial sums bounded above by 1.\n"
"\n"
"3. **Monotonicity:** Since each term `1/(k+2)² > 0`, the partial sums form a monotone increasing sequence.\n"
"\n"
"Monotone + Bounded = Convergent! This is one of the fundamental patterns in real analysis.\n"
"\n"
"## What We Haven't Shown\n"
"\n"
"Notice that we've proven convergence but **not** computed the exact value! We know the series converges to *some* real number less than 1, but we don't know what it is.\n"
"\n"
"Computing the exact value is much harder. Euler's brilliant solution in 1734 showed:\n"
"$\\sum_{k=1}^\\infty 1/k^2 = \\pi^2/6 \\approx 1.6449...$\n"
"\n"
"See the homework problems for more details!\n"
"\n"
"## The Broader Story: Riemann Zeta Function\n"
"\n"
"Euler went on to evaluate `∑ 1/k^(2n)` for all positive integers `n`, showing each equals a rational multiple of `π^(2n)`. These are now known as special values of the **Riemann zeta function**:\n"
"`ζ(s) = ∑_{k=1}^∞ 1/k^s`\n"
"\n"
"So `ζ(2) = π²/6`, `ζ(4) = π⁴/90`, `ζ(6) = π⁶/945`, etc.\n"
"\n"
"But what about odd values? Is `ζ(3) = ∑ 1/k³` related to `π`, or any other known constant? This question is still open today! Only in 1978, did Roger Apéry manage to prove that `ζ(3)` is **irrational**! We do not have a **right** to mathematical knowledge; any time our ignorance is momentarily lifted, it is a cause for celebration.\n"
"\n"
"## The Power of Comparison\n"
"\n"
"Your proof demonstrated the **comparison test** in action: to prove a series converges, find a known convergent series that dominates it term-by-term. This is one of the most practical convergence tests in analysis.\n"
"\n"
"## Historical Significance\n"
"\n"
"The Basel Problem launched Euler's career and revolutionized the study of infinite series. It showed that series could encode deep connections between discrete sums and continuous quantities like `π`.\n"
"\n"
"---\n"
"\n"
"**Congratulations!** You've completed Lecture 17 and proven some of the most beautiful classical results about infinite series. You've mastered telescoping sums, the comparison test, and the monotone bounded convergence theorem—powerful tools you'll use throughout analysis.\n"
"\n"
"**Next lecture:** We'll explore more sophisticated convergence tests and dive deeper into the theory of series!"
msgstr ""

#: Game.Levels.L16Pset.L16Pset2
msgid "The partial sums of the series `∑ k, c * a k` is equal to that of `c * ∑ k, a k`."
msgstr ""

#: Game.Levels.L1RealAnalysisStory.L02_rfl
msgid "The `rfl` tactic proves goals of the form `A = A` where both sides are *identical*."
msgstr ""

#: Game.Levels.L11Levels.L01_IsCauchyOfLim
msgid "Big Boss : Limits are Cauchy"
msgstr ""

#: Game.Levels.L9Pset.L9Pset1
msgid "# Problem 1\n"
"\n"
"Prove the same theorem as `Bdd_of_ConvNonzero`, but without the assumption that `L ≠ 0`. (Hint: break\n"
"the proof into cases, and the case `L ≠ 0` should just be an appeal to `Bdd_of_ConvNonzero`. What\n"
"do you do in the other case?)"
msgstr ""

#: Game.Levels.L6Levels.L00_SumOfSeqs
msgid "Prove that the sum of two convergent sequences converges to the sum of their limits.\n"
"This is the mathematician's version of 'if two factories each meet their quality standards, their combined output will too!'"
msgstr ""

#: Game.Levels.L10Levels.L08_Mono
msgid "Beautiful! That was remarkably simple for such a powerful theorem.\n"
"\n"
"**Why This Proof Works:**\n"
"\n"
"The key insight is that subsequences can only \"spread out\" indices, never compress them. Since `σ(n) ≥ n` always, if `a` is eventually within `ε` of `L` (for all indices ≥ N), then `a ∘ σ` is too—because `σ` maps `n ≥ N` to even larger indices where `a` is still close to `L`.\n"
"\n"
"The same `N` works for all subsequences!\n"
"\n"
"**The Contrapositive: A Divergence Test**\n"
"\n"
"The Subsequence Theorem says: *If `a n → L`, then every subsequence converges to `L`.*\n"
"\n"
"By contrapositive: *If there exist two subsequences converging to different limits, then `a` does not converge.*\n"
"\n"
"This is a powerful tool for proving divergence!\n"
"\n"
"**Example Application:**\n"
"\n"
"Consider `a n = (-1)^n`, which oscillates between -1 and 1:\n"
"- The even-indexed subsequence: `a(0), a(2), a(4), ... = 1, 1, 1, ...` converges to 1\n"
"- The odd-indexed subsequence: `a(1), a(3), a(5), ... = -1, -1, -1, ...` converges to -1\n"
"\n"
"Since we have subsequences converging to different limits (1 and -1), the sequence `a n = (-1)^n` does not converge. We'll see this in the next level!\n"
"\n"
"**Looking Ahead:**\n"
"\n"
"Subsequences are fundamental in analysis:\n"
"- **Bolzano-Weierstrass Theorem:** Every bounded sequence has a convergent subsequence\n"
"- **Compactness:** Sequential compactness is defined using subsequences\n"
"- **Cauchy sequences:** Can be understood through subsequences\n"
"- **limsup and liminf:** Defined as limits of monotone subsequences\n"
"\n"
"The concept generalizes to metric spaces and topological spaces, where it's crucial for understanding convergence and compactness.\n"
"\n"
"**Exercise:** Prove that if a sequence has two subsequences converging to different limits, then the sequence diverges. (Hint: use proof by contradiction—assume the sequence converges and derive that the two limits must be equal.)"
msgstr ""

#: Game.Levels.L10Pset.L10Pset7
msgid "Problem 6"
msgstr ""

#: Game.Levels.L13Levels.L03_MonotoneSubseq
msgid "Monotone Subsequence"
msgstr ""

#: Game.Levels.L3Levels.L02_OneOverN
msgid "Now we need `1 / n < ε`. First establish that everything is positive. Start with: `have f3 : 0 < 1 / ε := by bound`"
msgstr ""

#: Game.Levels.L11Levels.L01_IsCauchyOfLim
msgid "If a sequence `a : ℕ → ℝ` converges, then it is Cauchy."
msgstr ""

#: Game.Levels.L22Levels.L03
msgid "Summation distributes: `∑ i ∈ s, (f i + g i) = ∑ i ∈ s, f i + ∑ i ∈ s, g i`"
msgstr ""

#: Game.Levels.L20Pset.L01
msgid "ContinuousIff I"
msgstr ""

#: Game.Levels.L20Lecture
msgid "Lecture 20: Function Limits"
msgstr ""

#: Game.Levels.L19Levels.L02
msgid "# Congratulations!\n"
"\n"
"You've just proven the **Eventually Covers Property** for rearrangements—a beautiful result about bijections of the natural numbers!\n"
"\n"
"## What We've Accomplished\n"
"\n"
"This theorem tells us that no matter how wildly a rearrangement `σ` scrambles the natural numbers, it can't \"hide\" any element forever. Given any target set `{0, 1, ..., M-1}`, there's a point `N` beyond which we're guaranteed to have seen all of these elements as outputs.\n"
"\n"
"## The Proof Technique\n"
"\n"
"The proof uses a clever construction:\n"
"1. Since `σ` is surjective, each element `j < M` appears as `σ(k_j)` for some `k_j`\n"
"2. We use the axiom of choice (via `choose`) to select all these preimages simultaneously\n"
"3. We set `N` larger than all the `k_j` values\n"
"4. Then for any `n ≥ N`, all the required preimages are in `range n`, so all their images are covered\n"
"\n"
"The key insight is that finite sets have maximum elements, so we can always find a threshold that works.\n"
"\n"
"## A Concrete Example\n"
"\n"
"Consider the rearrangement that sends:\n"
"- `0 → 1, 1 → 2, 2 → 3, ...` (shift everything right)\n"
"- except `1000000 → 0` (one element goes way back)\n"
"\n"
"To cover `range 1` (just `{0}`), we need `N ≥ 1000001`, because `0` doesn't appear as `σ(k)` until `k = 1000000`.\n"
"\n"
"But the theorem guarantees such an `N` exists! No matter how we rearrange, we eventually catch everything.\n"
"\n"
"## Why This Matters for Series\n"
"\n"
"When we rearrange a series `∑ a_n` to get `∑ a_(σ(n))`, the partial sums are:\n"
"- Original: `a_0 + a_1 + ... + a_(n-1)`\n"
"- Rearranged: `a_(σ(0)) + a_(σ(1)) + ... + a_(σ(n-1))`\n"
"\n"
"This theorem tells us that for large enough `n`, the rearranged partial sum includes all the terms `a_0, a_1, ..., a_M` from the original series. Combined with the strong Cauchy property from Level 1, this will let us prove that the rearranged series converges to the same limit!\n"
"\n"
"## Next Steps\n"
"\n"
"In Level 3, we'll combine this result with the strong Cauchy property to prove the magnificent **Rearrangement Theorem**: absolutely convergent series can be rearranged without changing their sum!"
msgstr ""

#: Game.Levels.L3Levels.L01_ArchProp
msgid "And now the `bound` tactic will do the trick."
msgstr ""

#: Game.Levels.L24PsetIntro
msgid "# Problem Set 24\n"
"\n"
"Prove Problems 1 - 6 formally (in natural language); the rest can be proved using sketches of the main ideas.\n"
"\n"
"$\\# 1)$ Prove that an arbitrary union of open sets is open.\n"
"\n"
"$\\# 2)$ Prove that a finite intersection of open sets is open. Give a counterexample to show that an infinite intersection of open sets need not be open.\n"
"\n"
"$\\# 3)$ Prove that an arbitrary intersection of closed sets is closed.\n"
"\n"
"$\\# 4)$ Prove that a finite union of closed sets is closed. Give a counterexample to show that an infinite union of closed sets need not be closed.\n"
"\n"
"$\\# 5)$ Prove that if a set `S : Set ℝ` is closed, then it contains all its limit points; that is, if a sequence `(x_n)` in `S` converges to `x`, then `x ∈ S`. (This is in fact what closed sets are \"closed\" under -- taking limits!)\n"
"\n"
"$\\# 6)$ Prove that if a set `S : Set ℝ` contains all its limit points (`∀ (x : ℕ → ℝ) (L : ℝ), (∀ n, x n ∈ S) → (SeqLim x L) → (L ∈ S)`), then it is closed.\n"
"\n"
"$\\# 7)$ Give a different proof that a closed interval `[a, b]` is Closed. Suppose `xₙ` is a sequence in `[a, b]` converging to `L`. Show that `L ∈ [a, b]`. [Hint: Try the Order Limit Theorem from Lecture 10, Level 2...]\n"
"\n"
"$\\# 8)$ Let `S` be a set of reals, and let `T` be the set of its limit points (that is, the set of all `L : ℝ` such that there exists a sequence `(x_n)` in `S` converging to `L`). Show that if `L` is a limit point of `S ⋃ T`, then `L` is a limit point of `S`. That is, no new limit points are created when we pass from `S` to its \"closure\" `S ⋃ T`. [Hint: Remember how we proved that the real numbers are complete?...]\n"
"\n"
"$\\# 9)$ Prove that if `S` is compact, then any sequence `(x_n)` in `S` has a subsequence that converges to a limit in `S`. The latter property is called *sequential compactness*.\n"
"\n"
"$\\# 10)$ Conversely, prove that if `S` is sequentially compact (that is, every sequence in `S` has a subsequence converging to a limit in `S`), then it is compact.\n"
"\n"
"$\\# 11)$⋆ (Optional!) Let `C` denote the \"Cantor set\". This is constructed as follows. Start with the closed interval `[0, 1]`. Remove the open middle third `(1/3, 2/3)`, leaving the two closed intervals `[0, 1/3]` and `[2/3, 1]`. Now remove the open middle thirds of these two intervals, leaving four closed intervals: `[0, 1/9]`, `[2/9, 1/3]`, `[2/3, 7/9]`, and `[8/9, 1]`. Continue this process indefinitely. The Cantor set `C` is defined as the intersection of all these sets obtained at each step. Show that the Cantor set `C` is closed and hence compact. A point `p` in a set `S` is said to be an *isolated point* of `S` if there exists a ball `Ball p r` that contains no other points of `S` except for `p` itself; that is, there is no nontrivial sequence in `S` converging to `p`. A set `S` is called *perfect* if it has no isolated points, that is, its every point is a nontrivial limit point.\n"
"Show that the Cantor set is perfect."
msgstr ""

#: Game.Levels.L9Pset.L9Pset3
msgid "# Problem 3\n"
"\n"
"Prove that `2 * (1 + 2 + ... + N) = N * (N + 1)`."
msgstr ""

#: Game.Levels.L1RealAnalysisStory.L06_intro
msgid "The `intro` tactic introduces variables and hypotheses from ∀ statements or implications."
msgstr ""

#: Game.Levels.L10Pset.L10Pset2
msgid "If sequence `a : ℕ → ℝ` converges to `0` and sequence `b : ℕ → ℝ` is bounded, then `a n * b n` converges to `0`."
msgstr ""

#: Game.Levels.L7Pset.L7Pset2
msgid "# Problem 2\n"
"\n"
"Suppose that sequences `a b : ℕ → ℝ` converge to `L` and `M`, resp, with `L < M`. Show that\n"
"eventually, `a n < b n`."
msgstr ""

#: Game.Levels.L25Levels.L02
msgid "# Level 2 **BIG BOSS**: Intermediate Value Theorem\n"
"\n"
"Welcome to the grand finale! We end our journey through formal real analysis with mathematics' most \"obvious\" theorem—one so intuitive that it was used without proof for over **2000 years**.\n"
"\n"
"**The Intermediate Value Theorem**: If a function `f` is continuous on a closed interval `[a, b]`, with `f(a) < 0` and `f(b) > 0`, then there exists some `c ∈ (a, b)` such that `f(c) = 0`.\n"
"\n"
"*Translation*: A continuous function that changes sign must cross zero somewhere.\n"
"\n"
"**Why is this the \"greatest\" theorem?** Because it captures something profound about the real numbers that we take for granted: there are **no gaps**. Unlike the rationals ℚ (where `f(x) = x² - 2` changes sign but never equals zero), the reals ℝ are **complete**.\n"
"\n"
"**Historical irony**: Ancient Greeks used this theorem in geometric constructions. Euler applied it freely. Even Bolzano and Cauchy assumed it initially. Yet the first rigorous proof wasn't given until 1817—after calculus had been developed for 150 years!\n"
"\n"
"**Why so hard to prove?** Because it requires the **Least Upper Bound Principle**—the very completeness of ℝ that distinguishes it from ℚ. This \"obvious\" theorem actually encapsulates the deepest property of real numbers.\n"
"\n"
"Your proof will use *every major tool* we've built: suprema, continuity, proof by contradiction, and the intricate dance between topology and analysis. Ready for the ultimate challenge?"
msgstr ""

#: Game.Levels.L18Pset.L07
msgid "# Level 7: `AntitoneSeriesOdd`\n"
"\n"
"Prove `AntitoneSeriesOdd`:"
msgstr ""

#: Game.Levels.L11Lecture
msgid "# Lecture 11: The Real Numbers I\n"
"\n"
"**SOCRATES:** So far we've learned that *if* a sequence converges, then it's bounded, and moreover that any subsequence of it also converges to the same limit.\n"
"\n"
"**SIMPLICIO:** Yeah, so what?\n"
"\n"
"**SOCRATES:** And we saw that there can be sequences which do not themselves converge -- for example, $(-1)^n$ -- but which are bounded and have subsequences that do converge. The even-indexed terms, in this example, are all equal 1.\n"
"\n"
"**SIMPLICIO:** What are you getting at?\n"
"\n"
"**SOCRATES:** Well, what's a question that a mathematician might naturally ask given that information?\n"
"\n"
"**SIMPLICIO:** You mean whether that always happens?\n"
"\n"
"**SOCRATES:** Yes, something like that. Can you elaborate?\n"
"\n"
"**SIMPLICIO:** Okay, I'll play along. You're trying to get me to formulate some kind of converse. If a sequence is bounded, then... it converges? No, that can't be right -- a bounded sequence can bounce around without converging, like $(-1)^n$ itself.\n"
"\n"
"Ah, but maybe there's always *some* subsequence that converges? Hmm, but that can't be right either, since the sequence `aₙ = n` has no convergent subsequence -- it just escapes to infinity.\n"
"\n"
"Oh! But wait, that sequence isn't bounded. Are you saying that if all I know about a sequence is that it's bounded, then there's always *some* subsequence that converges?\n"
"\n"
"**SOCRATES:** Yes, precisely! This important fact is called the \"Bolzano-Weierstrauss theorem\". But here's where it gets **really** subtle. Think about the sequence of fractions: `a (0) = 1 / 1`, `a (1) = 14 / 10`, `a (2) = 141 / 100`, `a (3) = 1414 / 1000`, ... getting closer and closer to $1.4142\\dots = \\sqrt 2$. The sequence is bounded (by $2$, to be crude), and even increasing, but its limit is not a rational number! So the Bolzno-Weierstrauss theorem is not true for the rationals. As I warned you long ago, we'll have to eventually face the fact that we don't even know what the real numbers *are*. I think that time is now.\n"
"\n"
"**SIMPLICIO:** Fine, I'm ready; tell me what they are.\n"
"\n"
"**SOCRATES:** Unfortunately, it's rather complicated, and it'll take us some time to arrive at the answer, and to see why it *is* the answer. Let's take a step back. What would you *like* to be able to say about the real numbers?\n"
"\n"
"**SIMPLICIO:** Well, I guess I'd like to say something like: they're the limits of their decimal expansions. So they're limits of rational sequences. Like, $\\sqrt{2}$ is the limit of that sequence you just mentioned: $1, 1.4, 1.41, 1.414, \\dots$\n"
"\n"
"**SOCRATES:** Good! So you want to define a real number as \"the limit of a sequence of rationals.\" But remind me, what does it mean for a sequence to have a limit?\n"
"\n"
"**SIMPLICIO:** It means that for all `ε > 0`, there exists an `N`, yadda yadda. The terms get arbitrarily close to some number $L$.\n"
"\n"
"**SOCRATES:** And what is this mysterious number $L$? What *type* of number it?\n"
"\n"
"**SIMPLICIO:** It's... a real number. Oh no.\n"
"\n"
"**SOCRATES:** Exactly! We have a circular definition. We're trying to define the real numbers as limits of rational sequences, but the very notion of \"limit\" that we've been using presupposes that we already know what the real numbers are!\n"
"\n"
"**SIMPLICIO:** So we're stuck? We can't define the real numbers?\n"
"\n"
"**SOCRATES:** Sure seems like it! But this is where Cauchy had a **brilliant** insight. He realized the same thing you did: he can't use real numbers to define limits. He wants to say: \"$a_n$ gets closer and closer to $L$\" but without reference to $L$ itself. He needs to find *something else* that he can say $a_n$ gets close to.\n"
"\n"
"**SIMPLICIO:** But he *has* nothing else.\n"
"\n"
"**SOCRATES:** Exactly!! So...?\n"
"\n"
"**SIMPLICIO:** So if all he has is the sequence $a_n$, and he has to compare it to something, and he has nothing else... Oh!!! He has to compare it to **itself**!?! But how?\n"
"\n"
"**SOCRATES:** Wow, you got it! Yes, exactly, How?\n"
"\n"
"**SIMPLICIO:** Well of course it's pointless to ask if `|aₙ - aₙ| < ε`. But... you could ask for `|aₙ - aₘ| < ε`, once `n` and `m` are *both* large enough?\n"
"\n"
"**SOCRATES:** Ha, you did it! Yes, exactly, if $a_n$ and $a_m$ are both within $\\varepsilon$ of **each other**, that should be a substitute for convergence.\n"
"\n"
"**SIMPLICIO:** That's so clever! So instead of saying \"the sequence converges to $L$,\" we say \"the terms of the sequence get arbitrarily close to each other\"?\n"
"\n"
"**SOCRATES:** Precisely. Can you make this formal, using `ε`'s and `N`'s?\n"
"\n"
"**SIMPLICIO:** I think so. I guess we should say that a sequence $a_n$ has a limit if: for every $\\varepsilon > 0$, there exists an $N$ such that for all $m, n \\geq N$, we have $|a_m - a_n| < \\varepsilon$.\n"
"\n"
"**SOCRATES:** Beautiful! But since we already have a different meaning for the notion of  \"has a limit\", we'll call this property \"Cauchy\". So we say that **a sequence is Cauchy** if, as you said:\n"
"\n"
"`∀ ε > 0, ∃ N, ∀ n ≥ N, ∀ m ≥ n, |a m - a n| < ε`\n"
"\n"
"(It will be very convenient later to know which of `m` and `n` is bigger, instead of needing to break into cases;\n"
" so we can just say `m ≥ n`.)\n"
"\n"
"This is one of the most important definitions in **all of mathematics**.\n"
"It appears not only here in real analysis, but also in higher arithmetic when building the p-adic numbers, in functional analysis when studying Banach spaces and Hilbert spaces, and in topology and geometry when \"completing\" metric spaces. Anywhere mathematicians want to talk about  \"convergence\" but without knowing *a priori* where things converge *to*, they reach for a version of Cauchy's definition.\n"
"\n"
"But before we return to the real numbers, let's first get more familiar\n"
"with this definition and what it can do.\n"
"\n"
"**SIMPLICIO:** I like it; let's go!"
msgstr ""

#: Game.Levels.L17PsetIntro
msgid "Pset 17"
msgstr ""

#: Game.Levels.L3Pset.L3Pset2
msgid "Prove that the sequence `(n + 1) / n` has a limit `L` and determine what it is."
msgstr ""

#: Game.Levels.L18Pset.L08
msgid "Prove `BddSeriesEven`"
msgstr ""

#: Game.Levels.L7Levels.L01_Eventually
msgid "## What You've Proven\n"
"\n"
"Excellent work! You've proven that convergent sequences with nonzero limits are\n"
"**eventually bounded away from zero**. This is more than just a technical lemma—it's\n"
"a deep insight about the behavior of convergent sequences.\n"
"\n"
"## The Reverse Triangle Inequality in Action\n"
"\n"
"This proof showcased a powerful technique: using the triangle inequality \"in reverse\"\n"
"to establish lower bounds rather than upper bounds. The key manipulation was:\n"
"\n"
"$$|L| = |a (n) + (L - a (n))| \\leq |a (n)| + |L - a (n)|$$\n"
"\n"
"This allowed us to isolate `|a (n)|` and bound it from below.\n"
"\n"
"## Looking Ahead\n"
"\n"
"This result is the crucial prerequisite for proving that reciprocals preserve convergence.\n"
"When we want to show that `1/a (n) → 1/L`, we need to ensure that the denominators `a (n)`\n"
"don't get too small. This theorem guarantees exactly that: eventually, `|a (n)| ≥ |L|/2 > 0`,\n"
"so the reciprocals `1/a (n)` are well-defined and bounded.\n"
"\n"
"You now have the key tool needed for the next major theorem!"
msgstr ""

#: Game.Levels.L8Pset.L8Pset4
msgid "# Problem 4\n"
"\n"
"Suppose a sequence `σ : ℕ → ℕ` takes values in the\n"
"*natural numbers* (not reals), and is strictly increasing, that is,\n"
"if `i < j`, then `σ (i) < σ (j)`. Prove that\n"
"`σ (n)` grows at least as fast as `n` itself."
msgstr ""

#: Game.Levels.L3Levels.L02_OneOverN
msgid "The `linarith` tactic, with syntax `linarith [h₁, h₂]`, can solve goals that are linear arithmetic combinations of hypotheses `h₁, h₂` involving `≤`, `<`, `=` with addition and multiplication by constants.\n"
"- ✅ **Linear:** `2*x + y - 3`, `z / 5`\n"
"- ❌ **Not Linear:** `x*y`, `x^2`, `|x|`, `1/x`\n"
"\n"
"Example Usage:\n"
"h1 : x < y\n"
"h2 : y ≤ z\n"
"Goal: x < z + 1\n"
"linarith [h1, h2]"
msgstr ""

#: Game.Levels.L18Pset.L01
msgid "Prove `DiffOfSeries`"
msgstr ""

#: Game.Levels.L22PsetIntro
msgid "Pset 22"
msgstr ""

#: Game.Levels.L9Levels.L05_BddOfConv
msgid "If `a : ℕ → ℝ` is a sequence which converges to a non-zero limit, then it is bounded.\n"
"See also `Bdd_of_Conv` which assumes nothing about the limit."
msgstr ""

#: Game.Levels.L1RealAnalysisStory.L04_ring_nf
msgid "Write `ring_nf` to expand and simplify both sides algebraically."
msgstr ""

#: Game.Levels.L10Levels.L09_Subseq
msgid "Subsequence Example"
msgstr ""

#: Game.Levels.L14Levels.L01_BolzanoWeierstrass
msgid "If a sequence `a : ℕ → X` (where `X` can be `ℚ` or `ℝ`) is antitone and bounded, then it is Cauchy."
msgstr ""

#: Game.Levels.L24Levels.L05
msgid "Any closed subset of a compact set is compact."
msgstr ""

#: Game.Levels.L6PsetIntro
msgid "# Problem Set 6\n"
"\n"
"Good luck!"
msgstr ""

#: Game.Levels.L23Levels.L02
msgid "If a function `f` is uniformly continuous on `[a,b]`, then the Riemann sums of `f` converge to a limit as `N → ∞`."
msgstr ""

#: Game.Levels.L17Levels.L04
msgid "# Level 4: The Basel Problem\n"
"\n"
"Near the turn of the 18th century, the Bernoulli brothers Johann and Jakob became obsessed with evaluating the series:\n"
"\n"
"`∑ k, 1 / ((k + 2)²) = 1/4 + 1/9 + 1/16 + 1/25 + ...`\n"
"\n"
"This became known as the **Basel Problem** (after Basel, Switzerland, where the Bernoullis lived). Despite their considerable mathematical prowess, they could not find its exact value.\n"
"\n"
"It would take several more decades, and their most brilliant student—the legendary Leonhard Euler—to solve it in 1734. Euler showed that:\n"
"$∑_{k=1}^\\infty 1/k^2 = \\pi^2/6$.\n"
"\n"
"(Our series starts at k=2, so it equals `π²/6 - 1`, but that's a minor detail.)\n"
"\n"
"## Our More Modest Goal\n"
"\n"
"In this level, we won't compute the exact value—that requires Euler's revolutionary techniques connecting series to trigonometric functions. Instead, we'll prove something more fundamental: **the series converges at all**.\n"
"\n"
"## The Strategy: Comparison\n"
"\n"
"The key insight is to **compare** the Basel series with the Leibniz series from Levels 1-2. Observe that:\n"
"`1/(k+2)² = 1/((k+2)(k+2)) ≤ 1/((k+1)(k+2))`\n"
"\n"
"Why? Because `(k+2)² ≥ (k+1)(k+2)` for all `k ≥ 0`.\n"
"\n"
"By the Series Order Theorem (Level 3), this means:\n"
"`∑_{k<n} 1/(k+2)² ≤ ∑_{k<n} 1/((k+1)(k+2)) = 1 - 1/(n+1) < 1`\n"
"\n"
"So the partial sums of the Basel series are **bounded above by 1**!\n"
"\n"
"## New Theorems:\n"
"\n"
"**New Theorem (`SeqConv_of_IsCauchy`):** The completeness of `ℝ` (which we proved).\n"
"If a sequence of **real** numbers is Cauchy, then it converges.\n"
"Recall that we had already proved that every Cauchy sequence in `ℚ` converges (`Conv_of_IsCauchy`)\n"
"to a real number. So why are we proving the same theorem again, just with real-valued sequences?\n"
"Couldn't we have stated and proved it once and for all for either type, `a : ℕ → X`?\n"
"\n"
"No! The theorems are true for *completely different* reasons. `Conv_of_IsCauchy` is true\n"
"by the **construction** of the real numbers (as equivalence classes of Cauchy sequences of rationals).\n"
"Meanwhile, `SeqConv_of_IsCauchy` is true because of the **completeness** of the real numbers --\n"
"in fact, any \"completion\" of a metric space as equivalence classes of Cauchy sequences will\n"
"always be complete. Two different reasons / proofs, two different theorem statements.\n"
"\n"
"\n"
"**New Theorem (`SeqConv_of_MonotoneBdd`):** If a sequence `a : ℕ → ℝ` is:\n"
"- **Monotone:** `a n ≤ a (n+1)` for all `n`\n"
"- **Bounded:** `a n ≤ M` for all `n` and some `M`\n"
"\n"
"We already proved that monotone bounded sequences are Cauchy (`IsCauchy_of_MonotoneBdd`). So\n"
"`SeqConv_of_MonotoneBdd` is simply combining\n"
"this with `SeqConv_of_IsCauchy`.\n"
"\n"
"## Your Task\n"
"\n"
"Prove that the Basel series converges by:\n"
"\n"
"1. **First**, prove `SeqConv_of_MonotoneBdd` by combining `IsCauchy_of_MonotoneBdd` with completeness\n"
"\n"
"2. **Then**, apply it to `Series a` where `a n = 1/(n+2)²`, showing:\n"
"   - The partial sums are **bounded** by 1 (using comparison with Leibniz series)\n"
"   - The partial sums are **monotone** (adding positive terms)\n"
"\n"
"**Hints:**\n"
"- Use `LeibnizSeriesFinite` to get the formula for the Leibniz partial sums\n"
"- Use `SeriesOrderThm` to compare Basel with Leibniz\n"
"- Use `Monotone_of_succ` to prove monotonicity\n"
"- The inequality `(k+2)² ≥ (k+1)(k+2)` can be handled with `field_simp` and `bound`\n"
"\n"
"This is a substantial proof—you're standing on the shoulders of giants!"
msgstr ""

#: Game.Levels.L24Levels.L03
msgid "# Level 3: Least Upper Bound Property\n"
"\n"
"**The Big Picture**: We're taking a detour into the deep structure of ℝ itself. To prove that closed bounded sets are compact, we need a fundamental property (that does not hold for ℚ!): **every bounded set has a supremum**.\n"
"\n"
"**New Definitions**:\n"
"- **Upper Bound**: `IsUB S (M : ℝ) := ∀ s ∈ S, s ≤ M`\n"
"  - `M` sits above every point in `S`\n"
"- **Least Upper Bound**: `IsLUB S L := IsUB S L ∧ ∀ M, IsUB S M → L ≤ M`\n"
"  - `L` is an upper bound, and no smaller number is an upper bound\n"
"\n"
"**The Proof Strategy - Bisection**:\n"
"We'll construct a sequence of nested intervals `[aₙ, bₙ]` that shrink to the supremum. Here's where Lean's **dependent types** shine:\n"
"\n"
"`let ab : ∀ (n : ℕ), {p : ℝ × ℝ //\n"
"  (p.1 ∈ S) ∧ IsUB S p.2 ∧ p.1 ≤ p.2 ∧ p.2 - p.1 ≤ (M - s₀) / 2^n}`\n"
"\n"
"This type says: \"For each `n`, give me a pair `(aₙ, bₙ)` such that:\n"
"- `aₙ ∈ S` (so the left endpoint is achievable)\n"
"- `bₙ` is an upper bound for `S`\n"
"- `aₙ ≤ bₙ` (it's a valid interval)\n"
"- The interval length shrinks by half each time\"\n"
"\n"
"**The Inductive Construction**:\n"
"- **Base case**: Start with the `s₀ ∈ S` guaranteed by nonemptyness of `S`, and given upper bound `M`\n"
"- **Inductive step**: Given interval `[aₙ, bₙ]`, look at midpoint `m = (aₙ + bₙ)/2`\n"
"  - If `m` is an upper bound for `S`, set `[aₙ₊₁, bₙ₊₁] = [aₙ, m]`\n"
"  - If not, find some `s ∈ S` with `s > m`, set `[aₙ₊₁, bₙ₊₁] = [s, bₙ]`\n"
"\n"
"**Dependent Types Magic**: The type system *guarantees* that our construction maintains all necessary properties at each step. We're not just building sequences - we're building sequences *with proofs* that they satisfy our constraints!\n"
"\n"
"**Your Mission**: Implement this bisection algorithm and prove that the limit sequences converge to the least upper bound of `S`."
msgstr ""

#: Game.Levels.L22Levels.L02
msgid "`(f : ℕ → ℝ → ℝ) (F : ℝ → ℝ) :=\n"
"∀ ε > 0, ∃ N, ∀ n ≥ N, ∀ x, |f n x - F x| < ε`\n"
"\n"
"The sequence `f : ℕ → ℝ → ℝ` of functions converges uniformly to `F : ℝ → ℝ`."
msgstr ""

#: Game.Levels.L1RealAnalysisStory.L09_big_boss
msgid "**BIG BOSS LEVEL**: This problem requires all the tactics you've learned!"
msgstr ""

#: Game.Levels.L2NewtonsCalculationOfPi
msgid "Lecture 2: Newton's Computation of π"
msgstr ""

#: Game.Levels.L8Pset.L8Pset1
msgid "For all `n : ℕ`, `2 * n + 9 ≤ 2 ^ (n + 4)`."
msgstr ""

#: Game.Levels.L21Levels.L07
msgid "# Level 3: Derivatives Everywhere\n"
"\n"
"In the previous level, we computed the derivative of `f(x) = x² - 1` at a single point `x = 2`. Now we'll prove something much more powerful: we'll find the derivative at **every** point!\n"
"\n"
"## From Point Derivatives to Derivative Functions\n"
"\n"
"So far, `FunDerivAt f L c` tells us that `f` has derivative `L` at the specific point `c`.\n"
"\n"
"But for most functions, we can compute derivatives at *every* point, giving us a **derivative function**.\n"
"\n"
"## The New Definition\n"
"\n"
"**Definition (`FunDeriv`):** We say that `g` is the derivative of `f` (everywhere) if:\n"
"\n"
"`∀ x, FunDerivAt f (g x) x`\n"
"\n"
"This is written `FunDeriv f g`.\n"
"\n"
"In other words: for each point `x`, the derivative of `f` at `x` equals `g(x)`.\n"
"\n"
"## The Power Rule\n"
"\n"
"For `f(x) = x² - 1`, we'll prove that `f'(x) = 2x` for all `x`.\n"
"\n"
"This is an instance of the **power rule**: `d/dx[xⁿ] = n·xⁿ⁻¹`.\n"
"\n"
"## Computing the General Derivative\n"
"\n"
"For arbitrary `x`, we need:\n"
"\n"
"`lim[h→0] (f(x + h) - f(x)) / h`\n"
"\n"
"`     = lim[h→0] ((x + h)² - 1 - (x² - 1)) / h`\n"
"\n"
"`     = lim[h→0] (x² + 2xh + h² - x²) / h`\n"
"\n"
"`     = lim[h→0] (2xh + h²) / h`\n"
"\n"
"`     = lim[h→0] h(2x + h) / h`\n"
"\n"
"`     = lim[h→0] (2x + h)`\n"
"\n"
"`     = 2x`\n"
"\n"
"## Your Challenge\n"
"\n"
"Prove that the derivative of `f(x) = x² - 1` is `g(x) = 2x` everywhere:\n"
"\n"
"`FunDeriv (fun x ↦ x^2 - 1) (fun x ↦ 2 * x)`\n"
"\n"
"**Hint:** You need to prove `∀ x, FunDerivAt (fun x ↦ x^2 - 1) (2 * x) x`.\n"
"\n"
"After introducing `x`, the proof is very similar to Level 2, but with `x` instead of `2`.\n"
"\n"
"Given `ε > 0`, use `δ = ε`. For `h ≠ 0` with `|h| < ε`, simplify:\n"
"- `(x + h)² - 1 - (x² - 1) = 2xh + h²`\n"
"- `(2xh + h²) / h = 2x + h` (for `h ≠ 0`)\n"
"- `|(2x + h) - 2x| = |h| < ε`"
msgstr ""

#: Game.Levels.L7Levels.L00_Uniqueness
msgid "## What You've Proven\n"
"\n"
"Congratulations! You've just established one of the most important foundational results in\n"
"analysis: **limits are unique**.\n"
"\n"
"This theorem justifies our use of the definite article—we can speak of \"**the** limit\"\n"
"of a sequence rather than \"**a** limit.\" Without uniqueness, the entire theory of limits\n"
"would be ambiguous and potentially inconsistent.\n"
"\n"
"## Why Uniqueness Matters\n"
"\n"
"The uniqueness of limits is fundamental to the entire edifice of analysis. It ensures that:\n"
"\n"
"- When we define continuous functions using limits, the definitions are unambiguous\n"
"- Limit notation like `lim_{n→∞} a(n) = L` is well-defined\n"
"- We can safely use limits in computations without worrying about multiple possible values\n"
"- Many standard theorems that rely on \"the limit\" make sense\n"
"\n"
"## The Power of Contradiction\n"
"\n"
"This proof also showcased the power of **proof by contradiction** (`by_contra`). When\n"
"direct proof seems difficult, assuming the opposite and deriving an impossibility can be\n"
"an elegant and effective strategy. You'll use this technique many times throughout\n"
"analysis.\n"
"\n"
"The key insight was geometric: if two points are separated by distance `d`, then no third\n"
"point can be within distance `d/2` of both. This simple observation, made rigorous through\n"
"epsilon-N arguments, gave us our contradiction."
msgstr ""

#: Game.Levels.L10Pset.L10Pset7
msgid "If a sequence `a : ℕ → ℝ` has two convergent subsequences, `a ∘ σ` converges to `L` and `a ∘ τ` converges to `M ≠ L`, then `a` is not convergent."
msgstr ""

#: Game.Levels.L18Levels.L02
msgid "If `a` decreases to `0`, then the alternating series `Series (fun n ↦ (-1)^n * a n)` converges."
msgstr ""

#: Game.Levels.L17Pset.L05
msgid "Monotonicity of Series"
msgstr ""

#: Game.Levels.L12Levels.L01_Choose
msgid "## What You've Accomplished\n"
"\n"
"You've mastered a crucial technique for extracting structured objects from existence statements. By using `choose` to convert the Twin Prime Conjecture into concrete functions, then applying orbit construction to make those functions monotonic, you've built a subsequence that is both strictly increasing and preserves the desired property.\n"
"\n"
"## The Power of `choose`\n"
"\n"
"This level revealed how existence statements like `∀ N, ∃ n > N, p n` are actually encoding:\n"
"- A **function** `τ : ℕ → ℕ` that produces witnesses\n"
"- **Proofs** that these witnesses satisfy the required properties\n"
"- The ability to **extract** these hidden structures for further use\n"
"\n"
"The `choose` tactic transforms abstract existence into concrete tools you can manipulate.\n"
"\n"
"## Bridging Existence and Structure\n"
"\n"
"The key insight is the two-step process:\n"
"1. **Extract witnesses** using `choose` to get a function `τ` satisfying the property\n"
"2. **Add structure** using orbit construction to get a subsequence `σ` that's both monotonic and property-preserving\n"
"\n"
"This pattern - *existence → extraction → structuring* - appears throughout advanced mathematics.\n"
"\n"
"## Looking Ahead\n"
"\n"
"You now have all the tools needed for the main theorem of this lecture. In the next level, you'll see this exact `choose` technique applied to extract subsequences from the negation of the Cauchy property. The orbit construction you've mastered will then be used to accumulate gaps and create the contradiction with boundedness.\n"
"\n"
"The ability to extract functions from complex quantified statements, then transform them to have the structure you need, is a fundamental skill in formal mathematics. You've seen how abstract number theory (Twin Prime Conjecture) and concrete analysis (orbit construction) can work together seamlessly."
msgstr ""

#: Game.Levels.L3Levels.L02_OneOverN
msgid "Clear denominators in the goal: `field_simp`"
msgstr ""

#: Game.Levels.L18Levels.L02
msgid "# Congratulations!\n"
"\n"
"You've just proven the **Alternating Series Test**—one of the most beautiful and practical convergence tests in real analysis!\n"
"\n"
"## What We've Accomplished\n"
"\n"
"This theorem tells us that an alternating series $\\sum_{n=0}^{\\infty} (-1)^n \\cdot a_n$ converges whenever:\n"
"1. The terms $a_n$ are decreasing (antitone)\n"
"2. The terms approach zero: $a_n \\to 0$\n"
"\n"
"These conditions are remarkably easy to check in practice!\n"
"\n"
"## The Power of the Proof Technique\n"
"\n"
"The proof strategy—analyzing even and odd partial sums separately—is a powerful technique that appears throughout analysis:\n"
"- The even partial sums squeeze upward toward the limit\n"
"- The odd partial sums squeeze downward toward the limit\n"
"- They meet in the middle as $a_n \\to 0$\n"
"\n"
"This \"pinching\" or \"squeezing\" argument is elegant and intuitive.\n"
"\n"
"## A Crucial Observation: Conditional Convergence\n"
"\n"
"Notice that the alternating harmonic series $\\sum_{k=1}^{\\infty} \\frac{(-1)^{k+1}}{k}$ converges by this test, but its absolute value series $\\sum_{k=1}^{\\infty} \\frac{1}{k}$ (the harmonic series) diverges!\n"
"\n"
"This makes it **conditionally convergent**—it converges, but not absolutely. As we discussed in the introduction to this lecture, such series have remarkable properties: their sums can be rearranged to converge to *any* real number, or even to diverge! This is **Riemann's Rearrangement Theorem**, which we'll explore in future levels.\n"
"\n"
"## Historical Note\n"
"\n"
"Leibniz discovered this test in the 1670s while studying his famous series for $\\pi/4$ (also known centuries before to the Indian Madhava). It was one of the first convergence tests ever discovered, and it remains one of the most useful and elegant results in all of analysis.\n"
"\n"
"## What's Next?\n"
"\n"
"With absolute convergence (Level 1) and the alternating series test (Level 2) under our belt, we're now ready to explore the deep and sometimes counterintuitive theory of **rearrangements of series**—where the distinction between absolute and conditional convergence becomes truly dramatic!"
msgstr ""

#: Game.Levels.L19Levels.L03
msgid "# Congratulations!\n"
"\n"
"You've just proven the **Rearrangement Theorem**—one of the crown jewels of real analysis!\n"
"\n"
"## What We've Accomplished\n"
"\n"
"This theorem completely characterizes when infinite summation is commutative. For absolutely convergent series, we can reorder terms with complete freedom—the sum is invariant. This is a profound result that took mathematicians centuries to fully understand and prove rigorously.\n"
"\n"
"## The Proof: A Symphony of Ideas\n"
"\n"
"The proof beautifully orchestrated all the machinery we've built:\n"
"- **Strong Cauchy property (Level 1)**: Any scattered collection of large-index terms has negligible sum\n"
"- **Eventually covers property (Level 2)**: Rearrangements eventually capture all early terms\n"
"- **Clever decomposition**: We split the difference between rearranged and original sums into \"covered\" and \"uncovered\" parts\n"
"\n"
"The covered part is close to the limit by convergence of the original series. The uncovered part consists only of large-index terms, which by strong Cauchy have negligible sum. Together: the rearranged series converges to the same limit!\n"
"\n"
"## Historical Significance\n"
"\n"
"This theorem was understood by Cauchy and Abel in the 1820s, during the period when mathematicians were establishing rigorous foundations for calculus. It marked a crucial distinction between finite and infinite operations.\n"
"\n"
"The realization that *order matters* for infinite sums was shocking at first. But this theorem shows the situation is elegant: absolute convergence is exactly the dividing line between order-independent (\"finite-like\") and order-dependent behavior.\n"
"\n"
"## A Complete Dichotomy\n"
"\n"
"We now have half of a stunning dichotomy:\n"
"- **This level**: Absolute convergence → rearrangement invariance\n"
"- **Next level**: Conditional convergence → complete chaos (any sum is possible!)\n"
"\n"
"Together, these theorems show that there's no middle ground. A series either has an order-independent sum, or its sum can be manipulated to be anything we want by choosing the right rearrangement.\n"
"\n"
"## The Power of Absolute Convergence\n"
"\n"
"This theorem explains why absolute convergence is so important throughout analysis:\n"
"- It's the condition needed for term-by-term integration and differentiation\n"
"- It's required for multiplying infinite series (Cauchy product)\n"
"- It guarantees that double sums can be computed in either order (Fubini's theorem)\n"
"\n"
"Absolute convergence is the \"gold standard\" that makes infinite series behave like finite sums.\n"
"\n"
"## What's Next?\n"
"\n"
"In Level 4, we'll see the shocking flip side: Riemann's Rearrangement Theorem. For conditionally convergent series, rearrangements can make the sum equal to *any* real number. The contrast couldn't be more dramatic!"
msgstr ""

#: Game.Levels.L20PsetIntro
msgid "Pset 20"
msgstr ""

#: Game.Levels.L23Levels.L03
msgid "A `Type` is an arbitrary mathematical object."
msgstr ""

#: Game.Levels.L1RealAnalysisStory.L07_specialize
msgid "Now write `specialize hf t_pos` feed in the proof that `t > 0`; then you should be able to finish it yourself."
msgstr ""

#: Game.Levels.L11Levels.L02_IsCauchyOfSum
msgid "Level 2 : Sums of Cauchy sequences"
msgstr ""

#: Game.Levels.L1RealAnalysisStory.L08_choose
msgid "Excellent! You've learned the `choose` tactic for working with existence in hypotheses.\n"
"\n"
"Notice the complete pattern:\n"
"1. `choose c hc using h` unpacked the hypothesis into a specific value `c` and proof `hc : f c = 2`\n"
"2. `use c` provided this same value as our witness for the goal\n"
"3. `rewrite [hc]` rewrote `f c` as `2` in the goal, changing it to `2^2 = 4`\n"
"4. `ring_nf` verified that `2 ^ 2 = 4`\n"
"\n"
"The symmetry is beautiful:\n"
"- `use` when you have `∃` in the goal (\"here's my specific example\")\n"
"- `choose` when you have `∃` in a hypothesis (\"let me unpack this existence claim\")\n"
"\n"
"This completes your basic logical toolkit! In real analysis, you'll use `choose` constantly when working with:\n"
"- Limit definitions (\"given ε > 0, there exists δ > 0...\")\n"
"- Intermediate Value Theorem (\"there exists c such that f(c) = 0\")\n"
"- Existence theorems throughout analysis\n"
"\n"
"You're now ready to tackle real mathematical proofs!"
msgstr ""

#: Game.Levels.L12Lecture
msgid "# Lecture 12: Cauchy Sequences II"
msgstr ""

#: Game.Levels.L3Pset.L3Pset3
msgid "Determine what the limit of the sequence `1 / n ^ 2` is, and prove it."
msgstr ""

#: Game.Levels.L1RealAnalysisStory.L00_the_problem
msgid "Perfect! You've completed your first Lean proof involving real numbers.\n"
"\n"
"Remember: the `apply` tactic is used when you have what you need to prove the goal. Look at the top right: your list of tactics now includes `apply`, and if you forget how it works or what it does, just click on it for a reminder."
msgstr ""

#: Game.Levels.L17Levels.L02
msgid "# Level 2: Leibniz Series — Convergence\n"
"\n"
"In the previous level, you proved that the partial sums have an explicit formula:\n"
"`∑ k ∈ range n, a k = 1 - 1 / (n + 1)`\n"
"\n"
"Now it's time to prove rigorously that the infinite series **converges**.\n"
"\n"
"## What We Need to Show\n"
"\n"
"To prove `SeriesConv a`, we need to show that the sequence of partial sums converges to some limit `L`.\n"
"\n"
"From the formula, it's clear that the limit should be `L = 1`, since:\n"
"`lim (n → ∞) [1 - 1/(n+1)] = 1 - 0 = 1`\n"
"\n"
"But we need to prove this using the **ε-N definition** of convergence!\n"
"\n"
"## The ε-N Challenge\n"
"\n"
"We must show: for every `ε > 0`, there exists `N` such that for all `n ≥ N`:\n"
"`|∑ k ∈ range n, a k - 1| < ε`\n"
"\n"
"Using the partial sum formula, this becomes:\n"
"`|(1 - 1/(n+1)) - 1| < ε`\n"
"\n"
"Simplifying: `|−1/(n+1)| = 1/(n+1) < ε`\n"
"\n"
"So we need: **given ε > 0, find N such that for all n ≥ N, we have 1/(n+1) < ε**.\n"
"\n"
"## The Key Tool: Archimedean Property\n"
"\n"
"This is exactly what the **Archimedean Property** gives us! It says that for any `ε > 0`, there exists `N` such that `1/N < ε`.\n"
"\n"
"Then for all `n ≥ N`, we have:\n"
"`1/(n+1) ≤ 1/n ≤ 1/N < ε`\n"
"\n"
"## Your Task\n"
"\n"
"Prove that `SeriesConv a` using:\n"
"- The explicit formula from Level 1 (`LeibnizSeriesFinite`)\n"
"- The Archimedean Property (`ArchProp`)\n"
"- Careful inequality reasoning to show `1/(n+1) < ε`\n"
"\n"
"**Hint:** After using `ArchProp` to get your `N`, you'll need to do some work showing that `1/(n+1) ≤ 1/n ≤ 1/N < ε`. The tactics `field_simp` and `bound` will be your friends!"
msgstr ""

#: Game.Levels.L22Levels.L03
msgid "Integration"
msgstr ""

#: Game.Levels.L1RealAnalysisStory.L05_use
msgid "There exists a real number that makes this binomial expansion work."
msgstr ""

#: Game.Levels.L10PsetIntro
msgid "Pset 10"
msgstr ""

#: Game.Levels.L20Levels.L01
msgid "# Level 1: Introduction to Function Limits\n"
"\n"
"Welcome to Lecture 20! We now shift our focus from sequences to **functions**. Just as we studied limits of sequences, we can study limits of functions as the input approaches a particular point.\n"
"\n"
"## The Definition\n"
"\n"
"**Definition (`FunLimAt`):** We say that `f` has limit `L` at `x = c` if:\n"
"```\n"
"∀ ε > 0, ∃ δ > 0, ∀ x ≠ c, |x - c| < δ → |f x - L| < ε\n"
"```\n"
"\n"
"This is written `FunLimAt f L c`. (First the function, then the limit, then \"at\" `x = c`.)\n"
"\n"
"**Reading the definition:** For *every* tolerance `ε` around the output value `L`, there exists a distance `δ` around the input value `c` such that whenever `x` is within `δ` of `c` (but not equal to `c`), the function value `f(x)` is within `ε` of `L`.\n"
"\n"
"## The Intuition\n"
"\n"
"The key difference from sequence limits is the condition `x ≠ c`. We care about what happens *near* c, but not at all about what happens *at* c. The function might not even be defined at `c`!\n"
"\n"
"This is exactly what happens with the classic example:\n"
"\n"
"`f(x) = (x² - 1)/(x - 1)`\n"
"\n"
"At `x = 1`, the function is \"undefined\" (because it's `0/0`; in Lean, this is equal to `0`). But for `x ≠ 1`, we can factor:\n"
"\n"
"`f(x) = (x² - 1)/(x - 1) = (x - 1)(x + 1)/(x - 1) = x + 1`\n"
"\n"
"So as x approaches 1, `f(x)` approaches some constant `L`. Your job: figure out `L`, and prove that it's the limit!\n"
"\n"
"## Your Challenge\n"
"\n"
"Prove that there exists a limit `L` such that:\n"
"\n"
"`FunLimAt (fun x ↦ (x^2 - 1)/(x - 1)) L 1`\n"
"\n"
"In other words, prove that the function `f(x) = (x² - 1)/(x - 1)` has *some* limit as `x` approaches `1`."
msgstr ""

#: Game.Levels.L21Levels.L07
msgid "The Derivative Function"
msgstr ""

#: Game.Levels.L17Pset.L05'
msgid "# Level 2: Monotone Limit Bound\n"
"\n"
"Prove the theorem `MonotoneLimitBound`:\n"
"Suppose that a sequence `a : ℕ → ℝ` is `Monotone` and has limit `L`. Then\n"
"for every `n`, `a n ≤ L`."
msgstr ""

#: Game.Levels.L1RealAnalysisStory.L03_rw
msgid "The `rewrite` tactic replaces the left-hand side of an equality with the right-hand side in the goal. The syntax is `rewrite [hypothesis_name1, hypothesis_name2, etc]`."
msgstr ""

#: Game.Levels.L2NewtonsCalculationOfPi.L01_SeqConvDef
msgid "The `norm_num` tactic can normalize numerical constants and functions of them."
msgstr ""

#: Game.Levels.L19Levels.L04
msgid "# Congratulations!\n"
"\n"
"You've reached the pinnacle of our journey through series and rearrangements—Riemann's Rearrangement Theorem!\n"
"\n"
"## The Complete Picture\n"
"\n"
"We now have the full story about infinite summation and commutativity:\n"
"\n"
"**Level 3 (Rearrangement Theorem)**: Absolute convergence → rearrangement invariance\n"
"- The sum never changes, no matter how we reorder\n"
"- Infinite series behave like finite sums\n"
"\n"
"**Level 4 (Riemann's Theorem)**: Conditional convergence → complete chaos\n"
"- The sum can be *anything* we want by choosing the right rearrangement\n"
"- Order is everything; the series has no \"true\" sum independent of ordering\n"
"\n"
"There is no middle ground. Every convergent series falls into exactly one of these two categories.\n"
"\n"
"## Why Both Subseries Must Diverge\n"
"\n"
"A key insight: if `∑ a_n` converges but `∑ |a_n|` diverges, then both the series of positive terms and the series of negative terms must diverge to infinity. If either converged, we could show absolute convergence, a contradiction. This dual divergence is what gives us the freedom to hit any target—we never run out of positive or negative terms to adjust the sum.\n"
"\n"
"## The Greedy Algorithm\n"
"\n"
"The construction is elegant: alternately add positive terms (to push the sum up) and negative terms (to pull it back down), always staying close to our target `L`. Since `a_n → 0`, we need fewer and fewer terms for each adjustment, the oscillations shrink, and we converge exactly to `L`. Every term appears exactly once, making this a genuine rearrangement.\n"
"\n"
"## Philosophical Implications\n"
"\n"
"This theorem reveals a profound truth about infinity: our finite intuitions can fail dramatically. In finite arithmetic, addition is always commutative. But in the infinite realm, commutativity is a *privilege*, not a given—it requires absolute convergence.\n"
"\n"
"Conditionally convergent series are delicate balances between positive and negative contributions. The terms go to zero, but not fast enough to make the series absolutely convergent. This creates a twilight zone where order determines everything.\n"
"\n"
"## Historical Impact\n"
"\n"
"When Riemann proved this in 1854, it revolutionized analysis. Mathematicians realized that:\n"
"- Convergence alone is insufficient to guarantee good behavior\n"
"- Absolute convergence is the \"right\" condition for most theorems\n"
"- Infinite processes are more subtle and treacherous than previously thought\n"
"\n"
"This theorem helped establish the modern rigorous foundations of analysis, showing that careful definitions and proofs are essential when dealing with infinity.\n"
"\n"
"## The Bigger Lesson\n"
"\n"
"The contrast between Levels 3 and 4 teaches us that mathematical phenomena often exhibit sharp dichotomies. There's no \"mostly commutative\" or \"almost absolutely convergent\"—you either have the property or you have complete chaos. This all-or-nothing behavior appears throughout mathematics and is part of its austere beauty.\n"
"\n"
"## Looking Forward\n"
"\n"
"These ideas extend far beyond series:\n"
"- Fubini's theorem (changing order of integration) requires absolute convergence\n"
"- Products of series (Cauchy product) require absolute convergence\n"
"- Term-by-term operations on series require absolute convergence\n"
"\n"
"The distinction between absolute and conditional convergence is one of the most important concepts in all of analysis. You now understand it at the deepest level!\n"
"\n"
"## A Final Thought\n"
"\n"
"You've just completed one of the most beautiful and surprising journeys in mathematics. From the simple question \"does rearranging terms change the sum?\" we've uncovered a rich theory that distinguishes two fundamentally different types of convergence and reveals the subtle nature of infinity.\n"
"\n"
"This is real analysis at its finest—unexpected, profound, and ultimately satisfying. Well done!"
msgstr ""

#: Game.Levels.L4PsetIntro
msgid "Pset 4"
msgstr ""

#: Game.Levels.L3Levels.L01_ArchProp
msgid "Try `use ⌈1 / ε⌉₊ + 1`. Of course you can use other values of `N`, but then I won't be able to give you more hints..."
msgstr ""

#: Game.Levels.L19Lecture
msgid "Lecture 19: Rearrangements"
msgstr ""

#: Game
msgid "A First Course in Real Analysis"
msgstr ""

#: Game.Levels.L24Levels.L03
msgid "`(S : Set ℝ) (L : ℝ) : Prop := IsUB S L ∧ ∀ M, IsUB S M → L ≤ M`\n"
"\n"
"The point `L` is a least upper bound (supremum) of the set `S` if `L` is an upper bound of `S`, and for any other upper bound `M` of `S`, we have `L ≤ M`."
msgstr ""

#: Game.Levels.L10Levels.L07_Order
msgid "# Level 2: Order Limit Theorem\n"
"\n"
"So far we've focused on algebraic operations with limits. Now we explore how limits interact with **inequalities**.\n"
"\n"
"**The Question:** If every term of a sequence satisfies `a n ≤ K`, does the limit also satisfy `L ≤ K`?\n"
"\n"
"The answer is **YES**! Limits preserve weak inequalities. This is intuitive: if a sequence is always below some ceiling `K`, it can't suddenly jump above `K` in the limit.\n"
"\n"
"**New Definition: `SeqBddBy`**\n"
"\n"
"We say a sequence `a` is **bounded by** `M` if `a n ≤ M` for all `n`.\n"
"\n"
"Note the difference:\n"
"- `SeqBdd a`: sequence is bounded (both above and below), i.e., `|a n| ≤ M`\n"
"- `SeqBddBy a M`: sequence is bounded **above** by `M`, i.e., `a n ≤ M`\n"
"\n"
"**The Theorem:** If `a n → L` and `a n ≤ K` for all `n`, then `L ≤ K`.\n"
"\n"
"**Proof Strategy: Contradiction!**\n"
"\n"
"Assume `L > K`. Then `L - K > 0`. Use this as your `ε` in the definition of convergence:\n"
"- There exists `N` such that `|a N - L| < L - K`\n"
"- This means `a N > L - (L - K) = K`\n"
"- But we know `a N ≤ K` by hypothesis\n"
"- **Contradiction!**\n"
"\n"
"The key insight: if the limit were strictly above `K`, then eventually the terms would have to be above `K` too (by convergence). But they're not!\n"
"\n"
"**Warning:** Strict inequalities are NOT preserved! If `a n < K` for all `n`, we can only conclude `L ≤ K`, not `L < K`.\n"
"\n"
"Example: `a n = 1/n` satisfies `a n > 0` for all `n`, but `lim a n = 0`, which is not strictly positive.\n"
"\n"
"This theorem can also be used to prove the **Squeeze Theorem** (which we already did directly)."
msgstr ""

#: Game.Levels.L12Levels.L00_SubseqIterate
msgid "For a function `σ : ℕ → ℕ`, we have that: `σ (σ^[k]) = σ^[k+1]`."
msgstr ""

#: Game.Levels.L7Levels.L03_SeqInvLim
msgid "## Congratulations, Big Boss Defeated!\n"
"\n"
"You've just completed one of the most challenging proofs in elementary analysis! The\n"
"reciprocal limit theorem is a major milestone—you've proven that reciprocals preserve\n"
"convergence (when the limit is nonzero).\n"
"\n"
"## What You Accomplished\n"
"\n"
"This proof required you to orchestrate multiple sophisticated techniques:\n"
"- Using `EventuallyGeHalfLim` to ensure denominators stay bounded away from zero\n"
"- Choosing a carefully calibrated epsilon (`ε · |L|² / 2`) to make the algebra work\n"
"- Manipulating complex fractional expressions with common denominators\n"
"- Applying `abs_div` to separate absolute values across division\n"
"- Chaining together a sequence of inequalities to reach the final bound\n"
"\n"
"Each step built on the previous levels, showing how mathematical proofs are constructed\n"
"from carefully assembled building blocks.\n"
"\n"
"## Applications and Extensions\n"
"\n"
"With this theorem in hand, you now have a complete toolkit for limits of **rational\n"
"functions**. Combined with earlier results on sums and products, you can now prove:\n"
"\n"
"**If `a n → L` and `c n → M` with `M ≠ 0`, then `a n / c n → L / M`.**\n"
"\n"
"The proof is straightforward: first show `1/c n → 1/M` using the reciprocal theorem you\n"
"just proved, then use the product theorem to show `a n · (1/c n) → L · (1/M) = L/M`.\n"
"\n"
"This completes the fundamental arithmetic of limits: sums, products, and quotients. These\n"
"are the building blocks for analyzing limits of polynomials, rational functions, and much\n"
"more complex expressions throughout calculus and analysis.\n"
"\n"
"## Mastery of Technique\n"
"\n"
"The reciprocal theorem showcases a crucial lesson in mathematical proof: sometimes the\n"
"\"right\" epsilon isn't the obvious choice. The expression `ε · |L|² / 2` might seem\n"
"mysterious at first, but it's precisely engineered to make the final inequalities work out.\n"
"This kind of strategic thinking—working backwards from what you need to figure out what\n"
"you should assume—is at the heart of mathematical problem-solving.\n"
"\n"
"You've now mastered the essential techniques for proving limit theorems. Well done!"
msgstr ""

#: Game.Levels.L3Levels.L02_OneOverN
msgid "Presumably you know that you\n"
"should `choose N hN using f1` at this stage. But maybe you'd like to give `hN` a more descriptive name (so that I can keep giving you hints). Try `choose N eps_inv_lt_N using f1`."
msgstr ""

#: Game.Levels.L23Levels.L02
msgid "# Level 2: Integration Converges!\n"
"\n"
"**The Big Question**: We know that continuous functions *should* be integrable, but proving this rigorously is surprisingly subtle. The key insight is that we need *uniform* continuity, not just pointwise continuity.\n"
"\n"
"**What We're Proving**: If `f` is uniformly continuous on `[a,b]`, then the sequence of Riemann sums `{RiemannSum f a b n}` converges as `n → ∞`. This means the integral exists!\n"
"\n"
"**The Strategy**: We'll prove convergence by showing the Riemann sum sequence is Cauchy. For any `ε > 0`:\n"
"1. Use uniform continuity to get a `δ` that works everywhere on `[a,b]`\n"
"2. Choose `N` large enough so that partitions with `≥ N` subintervals are all fine enough\n"
"3. For any `m, n ≥ N`, compare `RiemannSum f a b m` and `RiemannSum f a b n` by using their common multiple `m * n` as an intermediate step\n"
"4. Apply your Level 1 theorem twice to bound the total error\n"
"\n"
"**New Definition - Uniform Continuity**:\n"
"\n"
"`def UnifContOn (f : ℝ → ℝ) (S : Set ℝ) : Prop :=\n"
"  ∀ ε > 0, ∃ δ > 0, ∀ x ∈ S, ∀ y ∈ S, |x - y| < δ → |f x - f y| < ε`\n"
"\n"
"**Key Insight**: Notice the quantifier order! Unlike pointwise continuity where `δ` can depend on the specific point `x`, uniform continuity requires a single `δ` that works for *all* pairs of points simultaneously. This seemingly small change makes all the difference for integration theory."
msgstr ""

#: Game.Levels.L1RealAnalysisStory.L08_choose
msgid "The choose tactic"
msgstr ""

#: Game.Levels.L24Levels.L01
msgid "A finite list has a maximum element."
msgstr ""

#: Game
msgid "An Introduction to (Formal) Real Analysis"
msgstr ""

#: Game.Levels.L14Levels.L01_BolzanoWeierstrass
msgid "# Level 1 **Big Boss:**  Bolzano-Weierstrass\n"
"\n"
"This is it. The crown jewel. One of the most celebrated theorems in all of real analysis.\n"
"\n"
"**The Bolzano-Weierstrass Theorem:** Every bounded sequence has a Cauchy subsequence.\n"
"\n"
"Think about what this says. Take *any* sequence confined to a bounded region—no matter how wildly it oscillates, no matter how chaotic its behavior—and this theorem *guarantees* you can extract from it a subsequence that converges (is Cauchy). Boundedness alone is enough to ensure hidden convergent behavior exists somewhere within.\n"
"\n"
"This theorem is the foundation for:\n"
"- Proving continuous functions on closed intervals attain their max and min\n"
"- Understanding compactness in metric spaces\n"
"- Existence proofs throughout optimization and differential equations\n"
"- Sequential compactness arguments everywhere in analysis\n"
"\n"
"And here's the beautiful part: **you've already done all the hard work.** This lecture is about watching the pieces fall into place.\n"
"\n"
"## The Architecture\n"
"\n"
"Over the past few lectures, you've been building a cathedral. Today, we place the capstone:\n"
"\n"
"**Lecture 12:** Bounded monotone sequences are Cauchy (you proved this)\n"
"\n"
"**Pset 12:** Bounded antitone sequences are Cauchy (dual by negation)\n"
"\n"
"**Lecture 13:** Sequences without unbounded peaks → have monotone subsequences (you proved this)\n"
"\n"
"**Pset 13:** Sequences with unbounded peaks → have antitone subsequences (you'll prove this)\n"
"\n"
"**Today:** We combine everything. Any bounded sequence either has unbounded peaks or doesn't. In either case, we extract a monotone (or antitone) bounded subsequence, which must be Cauchy by our earlier results.\n"
"\n"
"The proof is short—maybe the shortest \"big theorem\" proof you'll see—precisely because we've built the right machinery. Every complex proof should feel like this at the end: inevitable.\n"
"\n"
"## New Theorems (From Your Work)\n"
"\n"
"**abs_le:** The companion to `abs_lt` for non-strict inequalities. Says `|x| ≤ y ↔ -y ≤ x ≤ y`, letting us split absolute value bounds into simultaneous one-sided inequalities.\n"
"\n"
"**IsCauchy_of_AntitoneBdd:** From Pset 12. If a sequence is antitone (non-increasing) and bounded below, it's Cauchy. Dual to the monotone result.\n"
"\n"
"**AntitoneSubseq_of_UnBddPeaks:** From Pset 13. If a sequence has unbounded peaks, we can extract an antitone (non-increasing) subsequence by picking the peaks themselves.\n"
"\n"
"## The Strategy\n"
"\n"
"The proof uses **case analysis** with the dichotomy from Lecture 13:\n"
"\n"
"**Case 1: Unbounded peaks exist**\n"
"- Extract an antitone subsequence (by `AntitoneSubseq_of_UnBddPeaks`)\n"
"- It's bounded below (inherits from the original sequence)\n"
"- Therefore it's Cauchy (by `IsCauchy_of_AntitoneBdd`)\n"
"\n"
"**Case 2: Unbounded peaks don't exist**\n"
"- Extract a monotone subsequence (by `MonotoneSubseq_of_BddPeaks`)\n"
"- It's bounded above (inherits from the original sequence)\n"
"- Therefore it's Cauchy (by `IsCauchy_of_MonotoneBdd`)\n"
"\n"
"Either way, we get a Cauchy subsequence. The theorem falls out from the law of excluded middle plus our carefully constructed library of results.\n"
"\n"
"## What You'll Learn\n"
"\n"
"Beyond the theorem itself, this lecture teaches you:\n"
"\n"
"1. **Proof architecture:** How to structure a theory so that major theorems become natural consequences of well-chosen lemmas\n"
"\n"
"2. **Case analysis:** Using `by_cases` to split on a proposition and handle each case separately\n"
"\n"
"3. **Duality:** How proving one direction (monotone) often gives you the other (antitone) almost for free\n"
"\n"
"4. **Synthesis:** Combining multiple prior results into something greater than the sum of its parts\n"
"\n"
"## Historical Note\n"
"\n"
"Bernard Bolzano (1781-1848) and Karl Weierstrass (1815-1897) were pioneers of rigorous analysis. They understood a profound insight:\n"
"\n"
"**Boundedness + Infinity → Accumulation**\n"
"\n"
"If you have infinitely many values trapped in a bounded region, they *must* cluster somewhere. There's nowhere else to go. This theorem makes that intuition precise and constructive.\n"
"\n"
"## The Payoff\n"
"\n"
"With Bolzano-Weierstrass in hand, a vast landscape of analysis opens up:\n"
"- Extreme Value Theorem (continuous functions on closed intervals attain bounds)\n"
"- Intermediate Value Theorem (continuous functions hit all intermediate values)\n"
"- Heine-Borel Theorem (characterizing compact sets in ℝⁿ)\n"
"- Sequential compactness arguments throughout topology\n"
"- Fixed point theorems\n"
"- And so much more...\n"
"\n"
"This isn't just a theorem. It's a *key* that unlocks doors throughout mathematics.\n"
"\n"
"## Let's Do This\n"
"\n"
"You've climbed the mountain. The summit is in sight. Time to prove one of the most important theorems in real analysis.\n"
"\n"
"The proof is elegant, almost anticlimactic. That's how you know you've done mathematics right: when the final step feels obvious because you've laid the groundwork so carefully.\n"
"\n"
"**Ready? Let's prove Bolzano-Weierstrass.**"
msgstr ""

#: Game.Levels.L1Pset.L1Pset2
#: Game.Levels.L2Pset.L2Pset2
#: Game.Levels.L3Pset.L3Pset2
#: Game.Levels.L6Pset.L6Pset2
#: Game.Levels.L7Pset.L7Pset2
#: Game.Levels.L8Pset.L8Pset2
#: Game.Levels.L9Pset.L9Pset2
#: Game.Levels.L10Pset.L10Pset3
#: Game.Levels.L12Pset.L12Pset2
#: Game.Levels.L16Pset.L16Pset2
msgid "Problem 2"
msgstr ""

#: Game.Levels.L8Levels.L03_Induction'
msgid "# Level 1: Induction\n"
"\n"
"In this level, you'll prove your first theorem by mathematical induction: for all natural numbers `n`, we have `n < 2^n`. This captures the fundamental fact that exponential functions grow faster than linear functions.\n"
"\n"
"## Proof Strategy\n"
"\n"
"The proof follows the standard induction template:\n"
"\n"
"**Base Case (`n = 0`):** Show that `0 < 2^0 = 1`. This is straightforward.\n"
"\n"
"**Inductive Step:** Assume `k < 2^k` (the inductive hypothesis `hk`). Prove that `k + 1 < 2^(k+1)`.\n"
"\n"
"The key challenge is connecting `k + 1` to `2^(k+1) = 2 · 2^k`. While the inductive hypothesis gives us `k < 2^k`, we need to show `k + 1 < 2 · 2^k`.\n"
"\n"
"If we can show that `k + 1 ≤ 2k`, then we'd have:\n"
"\n"
"`k + 1 ≤ 2k < 2 · 2^k = 2^(k+1)`\n"
"\n"
"However, `k + 1 ≤ 2k` is only true when `k ≥ 1`. This means you'll need to handle two cases in the inductive step:\n"
"- When `k = 0`: Check directly that `1 < 2`\n"
"- When `k ≠ 0`: Use the inequality `k + 1 ≤ 2k`\n"
"\n"
"## New Tools You'll Need\n"
"\n"
"### `induction'`\n"
"The syntax for induction is: `induction' n with k hk`\n"
"- Apply induction on the variable `n`\n"
"- Use `k` as the dummy variable in the inductive step\n"
"- Use `hk` as the name for the induction hypothesis\n"
"\n"
"This creates two goals:\n"
"1. **Base case:** Prove the statement for `n = 0`\n"
"2. **Inductive step:** With hypothesis `hk : (statement for k)`, prove the statement for `k + 1`\n"
"\n"
"### `ge_one_of_nonzero`\n"
"If `n : ℕ` and `n ≠ 0`, then `1 ≤ n`. Apply this with `apply ge_one_of_nonzero` when you have a hypothesis that `n ≠ 0`.\n"
"\n"
"## Hints\n"
"\n"
"- Use `induction' n with k hk` to begin\n"
"- The base case should be handled with `norm_num`\n"
"- In the inductive step, use `by_cases hk0 : k = 0` to split into two cases\n"
"- When `k = 0`, use `rewrite [hk0]` and `norm_num`\n"
"- When `k ≠ 0`, use `ge_one_of_nonzero` to get `1 ≤ k`, then build a chain of inequalities with `bound` and `linarith`\n"
"- Use `ring_nf` to simplify `2 * 2^k = 2^(k+1)`"
msgstr ""

#: Game.Levels.L18Levels.L01
msgid "Absolute Convergence Implies Convergence"
msgstr ""

#: Game.Levels.L21Levels.L07
msgid "# Outstanding Achievement!\n"
"\n"
"You've just proved the **power rule** from first principles! This is one of the most fundamental results in calculus, and you've established it rigorously using limit definitions.\n"
"\n"
"## What You Accomplished\n"
"\n"
"You proved that for `f(x) = x² - 1`, the derivative function is `f'(x) = 2x` **everywhere**. This means:\n"
"- At any point `x`, the instantaneous rate of change is `2x`\n"
"- The slope of the tangent line at `(x, x² - 1)` is exactly `2x`\n"
"- The function has a well-defined derivative at every real number\n"
"\n"
"## From Specific to General\n"
"\n"
"Notice the beautiful progression:\n"
"- **Level 2:** Derivative at one point (`x = 2` gives `f'(2) = 4`)\n"
"- **Level 3:** Derivative everywhere (`f'(x) = 2x` for all `x`)\n"
"\n"
"Your Level 2 result now emerges as a special case: `f'(2) = 2(2) = 4` ✓\n"
"\n"
"## The Power Rule Emerges\n"
"\n"
"You've discovered a fundamental pattern:\n"
"- `f(x) = x²` has `f'(x) = 2x = 2x¹`\n"
"- This suggests the general rule: `d/dx[xⁿ] = n·xⁿ⁻¹`\n"
"\n"
"The constant `-1` disappeared because constants have derivative zero—another fundamental rule you've implicitly used!\n"
"\n"
"## The Algebraic Magic\n"
"\n"
"The key insight was recognizing that for **any** `x`:\n"
"`(x + h)² - x² = 2xh + h²`\n"
"\n"
"This factorization:\n"
"- Makes the `h` in the denominator cancel cleanly\n"
"- Leaves `2x + h`, which approaches `2x` as `h → 0`\n"
"- Works regardless of the value of `x`\n"
"\n"
"## Universal vs. Particular\n"
"\n"
"This level demonstrated the power of **universal quantification** (`∀ x`). Instead of proving the result for each individual point, you proved it holds for **every** point simultaneously. This is the essence of mathematical generality!\n"
"\n"
"## Looking Ahead\n"
"\n"
"You now have the tools to understand **continuity everywhere**. Just as we moved from point derivatives to derivative functions, we can move from point continuity to global continuity. Can you guess what comes next?\n"
"\n"
"The derivative function `f'(x) = 2x` you just found is itself a function—is it continuous? Spoiler alert: absolutely!"
msgstr ""

#: Game.Levels.L13PsetIntro
msgid "# Problem Set 13\n"
"\n"
"Good luck!"
msgstr ""

#: Game.Levels.L24Levels.L02
msgid "A compact set is closed."
msgstr ""

#: Game.Levels.L3Levels.L02_OneOverN
msgid "Combine everything with `linarith [eps_inv_lt_N, f4]`"
msgstr ""

#: Game.Levels.L18PsetIntro
msgid "Pset 18"
msgstr ""

#: Game.Levels.L20Levels.L04
msgid "## What We've Learned\n"
"\n"
"This theorem is a **bridge between two worlds**: sequences and functions!\n"
"\n"
"### Why This Matters\n"
"\n"
"The Sequential Criterion gives us two powerful tools:\n"
"\n"
"1. **Testing function limits with sequences**: Instead of wrestling with `ε`-`δ`, we can use specific sequences\n"
"2. **Connecting different areas of analysis**: Sequence convergence and function limits are deeply related\n"
"\n"
"### The Proof Strategy: Composing Guarantees\n"
"\n"
"The proof elegantly chains together two limit definitions:\n"
"\n"
"1. **Function limit** gives us: `ε → δ` (tolerance on output gives tolerance on input)\n"
"2. **Sequence limit** gives us: `δ → N` (tolerance on distance from `c` gives a threshold index)\n"
"3. **Composition**: `ε → δ → N` (tolerance on output gives threshold for the sequence `f(xₙ)`)\n"
"\n"
"This is a beautiful example of **modular reasoning**: we use the guarantees from each definition without re-proving them!\n"
"\n"
"### Looking Ahead\n"
"\n"
"There's a converse to this theorem (the backward direction): if `f(xₙ) → L` for **every** sequence `xₙ → c` with `xₙ ≠ c`, then `FunLimAt f L c`.\n"
"\n"
"Together, these give us a complete equivalence:\n"
"\n"
"`FunLimAt f L c ⟺ (for all sequences xₙ → c with xₙ ≠ c, we have f(xₙ) → L)`\n"
"\n"
"This means we can choose our weapon: use `ε`-`δ` when convenient, or use sequences when that's easier!\n"
"\n"
"**Key insight:** Different formulations of the same concept give us flexibility in proofs. The sequential characterization often provides better intuition than the abstract `ε`-`δ` definition."
msgstr ""

#: Game.Levels.L18Lecture
msgid "# Lecture 18: Infinite Addition\n"
"\n"
"**SIMPLICIO:** Does rearranging the terms of a series change its sum?\n"
"\n"
"**SOCRATES:** Great question! Here's the way I like to illustrate this idea (that I learned from Walter Rudin's books). Imagine a massive\n"
"matrix, $M$, infinite in both directions, to the right, and down. It is upper triangular, has $-1$s on the diagonal, and at\n"
"position $(i, j)$ for $i < j$ its entry is $1/ 2 ^ {(j - i + 1)}$. So $M$ looks like this:\n"
"\n"
"$\n"
"\\begin{pmatrix}\n"
"-1 & 1/2 & 1/4 & 1/8 & 1/16 & \\cdots \\\\\n"
"0 & -1 & 1/2 & 1/4 & 1/8 & \\cdots \\\\\n"
"0 & 0 & -1 & 1/2 & 1/4 & \\cdots \\\\\n"
"0 & 0 & 0 & -1 & 1/2 & \\cdots \\\\\n"
"\\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\ddots\n"
"\\end{pmatrix}\n"
"$\n"
"\n"
"What is the sum of the elements in $M$?\n"
"\n"
"**SIMPLICIO:** Ok let's see if we can work this out. Hmm this isn't so hard, I'll sum the rows, and\n"
"then add those up.\n"
"\n"
"The first row sums to $-1 + 1/2 + 1/4 + 1/8 + \\cdots = 0$.\n"
"\n"
"The second row sum is $0 + -1 + 1/2 + 1/4 + \\cdots = 0$ as well.\n"
"\n"
"In fact, every row obviously sums to $0$. So the sum of all the elements in $M$ is $0$.\n"
"\n"
"**SOCRATES:** Very good. What will my next question be?\n"
"\n"
"**SIMPLICIO:** I bet you're going to ask me to sum the columns instead of the rows...?\n"
"\n"
"**SOCRATES:** You bet! :)\n"
"\n"
"**SIMPLICIO:** Alright, let's do that. The first column sums to $-1 + 0 + 0 + 0 + \\cdots = -1$.\n"
"\n"
"The second column sums to $1/2 + -1 + 0 + 0 + \\cdots = -1/2$.\n"
"\n"
"The third column sums to $1/4 + 1/2 + -1 + 0 + \\cdots = -1/4$.\n"
"\n"
"Ok, I see the pattern. The $n$th column sums to $-1 / 2^{n-1}$. So the sum of all the elements in $M$ is\n"
"$-1 - 1/2 - 1/4 - 1/8 - \\cdots = -2$.\n"
"\n"
"Uh oh. So what *is* the sum?\n"
"\n"
"**SOCRATES:** Well that's just it! There is *no* 'the sum', because it depends on in what order you add the terms up!\n"
"\n"
"**Infinite summation is not commutative!**\n"
"\n"
"A *lot* of analysis is devoted to the study of this problem.\n"
"A sequence is called 'conditionally convergent' if it converges, but not when you add absolute values.\n"
"That is, the matrix $|M|$ would look like this:\n"
"\n"
"$\n"
"\\begin{pmatrix}\n"
"1 & 1/2 & 1/4 & 1/8 & 1/16 & \\cdots \\\\\n"
"0 & 1 & 1/2 & 1/4 & 1/8 & \\cdots \\\\\n"
"0 & 0 & 1 & 1/2 & 1/4 & \\cdots \\\\\n"
"0 & 0 & 0 & 1 & 1/2 & \\cdots \\\\\n"
"\\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\ddots\n"
"\\end{pmatrix}\n"
"$\n"
"\n"
"and hopefully it's clear (just from the diagonal!) that the sum of all its elements diverges (to infinity).\n"
"\n"
"People like Euler and Ramanujan were absolute wizards with divergent series, getting out of them all\n"
"kinds of bizarre results, like $1 + 2 + 3 + 4 + \\cdots$ '`=`' $-1/12$. As the great\n"
"Oliver Heaviside supposedly once said, 'This series is divergent, therefore we may be able to do something with it!'\n"
"\n"
"**SIMPLICIO:** I like it! Let's go."
msgstr ""

#: Game.Levels.L8Lecture
msgid "# Lecture 8: Mathematical Induction\n"
"\n"
"**SIMPLICIO:** Hey Socrates, I've been thinking about something that's been bothering me. When we prove things in mathematics, we usually prove a specific statement. But what if I want to prove something is true for *all* natural numbers? Like, how do I prove a statement for 0, 1, 2, 3, 4, and so on... forever?\n"
"\n"
"**SOCRATES:** Ah, an excellent question! You're right that we can't just check each case one by one—that would take infinitely long. Tell me, Simplicio, have you ever climbed a ladder?\n"
"\n"
"**SIMPLICIO:** Of course! What does that have to do with anything?\n"
"\n"
"**SOCRATES:** Well, imagine an infinitely tall ladder reaching up to the sky. If I wanted to convince you that you *could* climb to any rung on this ladder, what would I need to show you?\n"
"\n"
"**SIMPLICIO:** Hmm... I guess you'd need to show me that I can reach the bottom-most rung?\n"
"\n"
"**SOCRATES:** Good start! And what else?\n"
"\n"
"**SIMPLICIO:** Well, if I'm standing on any particular rung, I'd need to know I can reach the next one up. So if I can always step from one rung to the next...\n"
"\n"
"**SOCRATES:** Exactly! So if you can reach the first rung, and you can always step from rung `k` to rung `k+1`, then what can you conclude?\n"
"\n"
"**SIMPLICIO:** Oh! Then I can reach *any* rung I want! If I want to reach rung 100, I just start at rung 0, step to rung 1, then to rung 2, and keep going until I reach rung 100. And the same works for any number!\n"
"\n"
"**SOCRATES:** Precisely! This is the essence of **mathematical induction**. To prove something is true for all natural numbers `n`, you need exactly two things:\n"
"- A **base case**: prove it's true for `n = 0`\n"
"- An **inductive step**: prove that *if* it's true for `n = k`, *then* it's true for `n = k + 1`\n"
"\n"
"**SIMPLICIO:** Wait, but in the inductive step, aren't we assuming what we're trying to prove? Isn't that circular reasoning?\n"
"\n"
"**SOCRATES:** An astute observation! But no, it's not circular. We're not assuming the statement is true for all `n`. We're only assuming it's true for one particular value `k`, and using that assumption to prove that it's true for `k + 1`. We're proving an implication: \"if `P(k)` then `P(k+1)`\". Combined with the base case, this creates a chain reaction that reaches any natural number.\n"
"\n"
"**SIMPLICIO:** Hmm, I think I see. So the assumption \"it's true for `k`\" is called the inductive hypothesis?\n"
"\n"
"**SOCRATES:** Exactly! And that hypothesis is your most powerful tool. It's like having a foothold on rung `k` that you can push off from to reach rung `k + 1`.\n"
"\n"
"**SIMPLICIO:** But why does this work? I mean, why should I believe this principle?\n"
"\n"
"**SOCRATES:** Ah, a deep question! It comes from the very definition of the natural numbers themselves. How do you think the natural numbers are constructed?\n"
"\n"
"**SIMPLICIO:** Well... I guess we start with 0. And then we have 1, which is 0 + 1. And 2 is 1 + 1. So each number is the \"successor\" of the previous one?\n"
"\n"
"**SOCRATES:** Beautiful! The natural numbers are defined by exactly this process:\n"
"- Zero is a natural number\n"
"- If `k` is a natural number, then `k + 1` is also a natural number\n"
"- These are the *only* natural numbers\n"
"\n"
"Do you see how this mirrors the structure of induction?\n"
"\n"
"**SIMPLICIO:** Oh wow! The base case corresponds to \"zero is a natural number,\" and the inductive step corresponds to \"if `k` is a natural number, then so is `k + 1`.\" Induction is just the construction of the natural numbers turned into a proof technique!\n"
"\n"
"**SOCRATES:** Precisely! There are no \"gaps\" in the natural numbers—no number that can't be reached by starting at 0 and repeatedly adding 1. This is why induction works.\n"
"\n"
"In fact, this is not just a philosophical observation—this is *literally* how the natural numbers are implemented in Lean! In Lean's type theory, a natural number is defined inductively as either:\n"
"- `zero : ℕ`, the base case, or\n"
"- `succ n : ℕ`, the successor of another natural number `n`\n"
"\n"
"Here's how this looks in the core of Lean:\n"
"\n"
"`inductive Nat where`\n"
"- `| zero : Nat`\n"
"- `| succ (n : Nat) : Nat`\n"
"\n"
"You simply declare the existence of a natural number called `zero`, and then we declare that, given any natural number `n`, there's another one called `succ n`. (The word `succ` is here just a name for this constructor; we could have called it `Alice` instead. The important thing is that we're giving a way to construct a new natural number from a previously existing one.)\n"
"\n"
"So the number 3, for instance, is literally represented as `succ (succ (succ zero))`. The principle of induction doesn't just *resemble* this construction, it directly exploits it! When you prove something by induction in Lean, you're working with the actual computational structure of how natural numbers exist in the system.\n"
"\n"
"**SIMPLICIO:** That's amazing! So induction isn't just a proof technique—it's baked into the very fabric of how Lean understands numbers?\n"
"\n"
"**SOCRATES:** Exactly. The principle of mathematical induction is a theorem in many mathematical frameworks, but in type theory, it's a fundamental consequence of how the natural numbers are defined.\n"
"\n"
"**SIMPLICIO:** Okay, I'm convinced this is a legitimate proof technique. Can you give me an example?\n"
"\n"
"**SOCRATES:** Certainly."
msgstr ""

#: Game.Levels.L21Levels.L06
msgid "# Excellent Work!\n"
"\n"
"You've just computed your first derivative using the formal limit definition! This is a foundational skill that connects the abstract world of limits to the concrete world of rates of change.\n"
"\n"
"## What You Accomplished\n"
"\n"
"You proved that the derivative of `f(x) = x² - 1` at `x = 2` is exactly `4`. This means:\n"
"- The **instantaneous rate of change** of `f` at `x = 2` is `4`\n"
"- The **slope of the tangent line** to the graph at `(2, 3)` is `4`\n"
"- If you zoom in very close to the point `(2, 3)`, the function looks like the line `y = 4x - 5`\n"
"\n"
"## The Power of Algebraic Simplification\n"
"\n"
"Your proof showcased a key technique: **algebraic manipulation before taking limits**.\n"
"\n"
"Instead of wrestling with the indeterminate form `0/0`, you:\n"
"1. **Expanded:** `(2 + h)² = 4 + 4h + h²`\n"
"2. **Simplified:** `(4h + h²)/h = h(4 + h)/h = 4 + h`\n"
"3. **Applied the limit:** `lim[h→0] (4 + h) = 4`\n"
"\n"
"This \"simplify first, then limit\" approach is essential for derivative computations!\n"
"\n"
"## The Beautiful Result: δ = ε\n"
"\n"
"Notice how clean the final step was: to prove `|h| < ε`, you simply chose `δ = ε`. This perfect correspondence happens because the simplified difference quotient `4 + h` has slope exactly `1` near the limit point.\n"
"\n"
"This won't always be so simple, but it's a beautiful example of how algebra can make limit proofs elegant.\n"
"\n"
"## Connection to Calculus\n"
"\n"
"In traditional calculus, you might have computed this as:\n"
"- `d/dx[x²] = 2x`, so at `x = 2` we get `2(2) = 4`\n"
"- The constant `-1` has derivative `0`\n"
"\n"
"You've now proven this rigorously from first principles! Every time you use the power rule, you're implicitly using the kind of limit argument you just mastered.\n"
"\n"
"## Looking Ahead\n"
"\n"
"In the next level, we'll generalize this computation to find the derivative at **every** point, not just `x = 2`. You'll discover the famous **power rule** emerging naturally from limit definitions!"
msgstr ""

#: Game.Levels.L18Levels.L01
msgid "`(a : ℕ → ℝ) := SeriesConv (fun n ↦ |a n|)`\n"
"\n"
"We say that a sequence `a : ℕ → ℝ` converges absolutely if `∑ |a n|` converges."
msgstr ""

#: Game.Levels.L20Levels.L04
msgid "Sequential Criterion for Limits (Forward Direction)"
msgstr ""

#: Game.Levels.L3Pset.L3Pset1
msgid "# Problem 1\n"
"\n"
"The \"full\" Archimedean Property is this:\n"
"Take two positive real numbers `x` and `y`. No matter\n"
"how large `y` may be, and how small `x` may be,\n"
"if we add `x` to itself enough times (that is, multiply it by some natural number), we can always get that to exceed `y`."
msgstr ""

#: Game.Levels.L15Levels.L01_check
msgid "If a sequence `a : ℕ → ℚ` is Cauchy, then it converges (that is, `SeqLim` holds)\n"
"to the real number defined in `Real_of_CauSeq`."
msgstr ""

#: Game.Levels.L3Pset.L3Pset4
msgid "Usage: given hypothesis `h : 0 ≤ X`, you can prove: `have : |X| = X := by apply abs_of_nonneg h`"
msgstr ""

#: Game.Levels.L6Levels.L06_Squeeze
msgid "If `a c : ℕ → ℝ`, with `a` and `c` both converging to `L`,\n"
"and `b` is another sequence, squeezed between `a` and `c`, then `b` also converges to `L`."
msgstr ""

#: Game.Levels.L13Pset.L13Pset1
msgid "# Problem 1:\n"
"\n"
"Prove `AntitoneSubseq_of_UnBddPeaks`\n"
"\n"
"## New theorem: `Antitone_of_succ`"
msgstr ""

#: Game.Levels.L3Levels.L02_OneOverN
msgid "Start by converting to the definition of sequential convergence using `change`."
msgstr ""

#: Game.Levels.L15Pset.L15Pset1
msgid "# Problem 1:\n"
"\n"
"Prove that $0.999... = 1.0000$. Better yet, let's do it in binary.\n"
"That is, you have two **rational** (Cauchy) sequences, `a n = 1 - 1 / 2^n` and `b n = 1`.\n"
"The two sequences are equivalent if `a n - b n` goes to zero, that is, if for all `ε > 0, ∃ N, ∀ n ≥ N, |a n - b n| < ε`.\n"
"\n"
"Hint: In Lecture 8, we proved a theorem (now) called `IdLeTwoPow`..."
msgstr ""

#: Game.Levels.L18Levels.L02
msgid "Given `a : ℕ → ℝ`, if `a (2 n) → L` and `a (2n+1) → L`, then `a → L`."
msgstr ""

#: Game.Levels.L21Levels.L05
msgid "If for every sequence `(xₙ)` converging to `c` with `xₙ ≠ c`, the sequence `f(xₙ)` converges to `L`, then the function `f` has limit `L` at point `c`."
msgstr ""

#: Game.Levels.L21Levels.L08
msgid "`∀ x, FunContAt f x`\n"
"\n"
"The function `f` is continuous on all of `ℝ`."
msgstr ""

#: Game.Levels.L19Levels.L03
msgid "If `Series a` converges absolutely, then any rearrangement of `a` also converges, and to the same sum."
msgstr ""

#: Game.Levels.L1RealAnalysisStory.L00_the_problem
msgid "Write `apply h` since the hypothesis `h` is  what we want to prove."
msgstr ""

#: Game.Levels.L11Levels.L02_IsCauchyOfSum
msgid "# Level 2: Sums of Cauchy Sequences\n"
"\n"
"Now that we know convergent sequences are Cauchy, let's explore how Cauchy sequences behave under arithmetic operations. Just like we proved that sums of convergent sequences converge, we'll show that sums of Cauchy sequences are Cauchy.\n"
"\n"
"This theorem is important because it shows that the Cauchy property is preserved by addition—a crucial fact we'll need when we eventually define the real numbers!\n"
"\n"
"## The Setup\n"
"\n"
"Given:\n"
"- `a : ℕ → ℝ` is Cauchy\n"
"- `b : ℕ → ℝ` is Cauchy\n"
"\n"
"Prove: `a + b` is Cauchy\n"
"\n"
"## Strategy\n"
"\n"
"This proof follows a familiar pattern from the sum of limits theorem:\n"
"\n"
"1. **Split epsilon**: Apply the Cauchy property to both `a` and `b` using `ε/2`\n"
"2. **Take the maximum N**: Use `N₁ + N₂` to ensure both Cauchy conditions hold\n"
"3. **Change the goal**: Express `|(a + b)ₘ - (a + b)ₙ|` as `|(aₘ - aₙ) + (bₘ - bₙ)|`\n"
"4. **Triangle inequality**: Split the sum into two pieces\n"
"5. **Combine estimates**: Each piece is less than `ε / 2`, so the total is less than `ε`\n"
"\n"
"## Key Insight\n"
"\n"
"The beauty of the Cauchy property is that we don't need to know *where* the sequences converge—we only need to know that their terms get close to *each other*. This self-referential definition makes the proof very similar to the sum of limits, but without ever mentioning a limit!\n"
"\n"
"Let's prove it!"
msgstr ""

#: Game.Levels.L1RealAnalysisStory.L04_ring_nf
msgid "# Algebraic manipulations\n"
"\n"
"Now let's learn about algebraic simplification. Suppose you need to prove that $(x + y)^3 = x^3 + 3x^2y + 3xy^2 + y^3$.\n"
"\n"
"This is true by the basic laws of algebra - expanding the left side using the distributive law, commutativity, associativity, etc. But doing this by hand would be extremely tedious.\n"
"\n"
"Fortunately, Lean has a powerful tactic called `ring_nf` (\"ring normal form\") that can automatically perform algebraic manipulations like:\n"
"- Expanding products\n"
"- Collecting like terms\n"
"- Rearranging using commutativity and associativity\n"
"- Applying the distributive law\n"
"\n"
"When you have an algebraic identity involving addition, subtraction, and multiplication, `ring_nf` can often prove it automatically.\n"
"\n"
"Try it out on this classic binomial expansion!"
msgstr ""

#: Game.Levels.L8Levels.L03_Induction'
msgid "For all `n`, `n < 2 ^ n`."
msgstr ""

#: Game.Levels.L7Levels.L02_SeqOfAbs
msgid "Sequences of Absolute Values"
msgstr ""

#: Game.Levels.L18PsetIntro
msgid "# Problem Set 18"
msgstr ""

#: Game.Levels.L18Levels.L01
msgid "If `n ≤ m`, then `Series a m - Series a n = ∑ k ∈ Ico n m, a k`."
msgstr ""

#: Game.Levels.L1RealAnalysisStory.L03_rw
msgid "Type `rewrite [Bob]` to replace `x` with `2` in the goal. Then what?"
msgstr ""

#: Game.Levels.L19Levels.L02
msgid "A function `f : X → Y` called `Surjective` if: for all `y : Y`, `∃ x : X` so that `f x = y`."
msgstr ""

#: Game.Levels.L17Levels.L02
msgid "Excellent work! You've rigorously proven that the Leibniz series converges to 1.\n"
"\n"
"## What You've Accomplished\n"
"\n"
"**Theorem (LeibnizSeries):** The series `∑ k, 1/((k+1)(k+2))` converges.\n"
"\n"
"More precisely, you've shown that `SeriesConv a` holds, meaning the partial sums converge to the limit `L = 1`.\n"
"\n"
"## The Proof Structure\n"
"\n"
"Your proof had three main ingredients:\n"
"\n"
"1. **The explicit formula** from Level 1: `∑ k ∈ range n, a k = 1 - 1/(n+1)`\n"
"\n"
"2. **The Archimedean Property:** Given `ε > 0`, there exists `N` with `1/N < ε`\n"
"\n"
"3. **Inequality chaining:** For `n ≥ N`:\n"
"   `1/(n+1) ≤ 1/n ≤ 1/N < ε`\n"
"\n"
"The combination of these three ingredients gave you the ε-N proof that the partial sums approach 1!\n"
"\n"
"## Understanding the Convergence\n"
"\n"
"The series converges quite quickly. After `n` terms, the partial sum differs from the limit by only `1/(n+1)`:\n"
"\n"
"- After 10 terms: error ≈ 0.091\n"
"- After 100 terms: error ≈ 0.0099\n"
"- After 1000 terms: error ≈ 0.001\n"
"\n"
"This `O(1/n)` convergence rate is typical for telescoping series.\n"
"\n"
"## The Role of the Archimedean Property\n"
"\n"
"The Archimedean Property was crucial! It guaranteed that `1/N` can be made smaller than any positive `ε`, no matter how tiny. This is what allowed us to control the tail `1/(n+1)`.\n"
"\n"
"Without completeness and the Archimedean property, we couldn't have this guarantee. In fact, this property fails in non-Archimedean ordered fields!\n"
"\n"
"## From Formula to Convergence\n"
"\n"
"This level demonstrated a powerful two-step strategy:\n"
"1. **First**, find an explicit formula for partial sums (often via telescoping, induction, or other techniques)\n"
"2. **Then**, use the formula to prove convergence rigorously\n"
"\n"
"This approach is cleaner than trying to prove convergence directly without knowing what the limit is!\n"
"\n"
"## Historical Context\n"
"\n"
"Leibniz studied this and similar series in the 1670s as part of his groundbreaking work on infinite series. He didn't have our modern ε-N definition (that came 150 years later with Cauchy), but his intuition about these sums was remarkably accurate.\n"
"\n"
"---\n"
"\n"
"**Next level:** We'll prove a comparison theorem that lets us bound one series by another, setting up powerful convergence tests!"
msgstr ""

#: Game.Levels.L22Levels.L02
msgid "Uniform Convergence"
msgstr ""

#: Game.Levels.L1RealAnalysisStory
msgid "Lecture 1: The Story of Real Analysis"
msgstr ""

#: Game.Levels.L2Pset.L2Pset1
#: Game.Levels.L2Pset.L2Pset2
msgid "Find the correct constant."
msgstr ""

#: Game.Levels.L12Levels.L00_SubseqIterate
msgid "Iterated Subsequence"
msgstr ""

#: Game.Levels.L1RealAnalysisStory.L03_rw
msgid "Great! You've learned the `rewrite` tactic.\n"
"\n"
"Notice what happened: after you typed `rewrite [Bob]`, the goal changed from `x + y = 2 + y` to `2 + y = 2 + y`. Then you needed to type `rfl` to finish the proof, since both sides were now identical.\n"
"\n"
"So far you've learned:\n"
"- `apply hypothesis_name` when a hypothesis matches your goal\n"
"- `rfl` when you need to prove something equals itself\n"
"- `rewrite [hypothesis_name]` when you want to use an equality to rewrite your goal\n"
"\n"
"The `rewrite` tactic is incredibly powerful and you'll use it constantly in real analysis!"
msgstr ""

#: Game.Levels.L24Levels.L03
msgid "# You've Just Proved ℝ is Complete!\n"
"\n"
"Congratulations! You've just established one of the most fundamental properties of the real numbers: the **Least Upper Bound Property**. This is\n"
"another way to say that `ℝ` is \"complete\" - it has no gaps.\n"
"\n"
"**What Made This Proof Special**:\n"
"- **Dependent Types Power**: Your proof showcased Lean's dependent type system at its best. The type `ℕ → {p : ℝ × ℝ // ...}` didn't just give you pairs of reals - it gave you pairs *with built-in proofs* that they satisfy all your constraints, and depend on the `n : ℕ`.\n"
"- **Constructive Algorithm**: Your bisection method doesn't just prove a supremum exists - it gives you an algorithm to compute it to arbitrary precision!\n"
"- **Induction on Steroids**: You weren't just proving a property for all `n` - you were constructing a sequence where each element depends on satisfying complex constraints involving the previous ones.\n"
"\n"
"**Why This Property is Profound**:\n"
"- **`ℚ` Fails Here**: The rationals are missing \"limit points\" like √2. Your proof shows ℝ has no such gaps.\n"
"- **Topology Connection**: Completeness (LUB property) is what makes compact sets in ℝ so well-behaved.\n"
"- **Analysis Foundation**: Virtually every major theorem in real analysis depends on this completeness property.\n"
"\n"
"**The Nested Interval Magic**: Your proof created intervals `[aₙ, bₙ]` with three beautiful properties:\n"
"1. Each `aₙ ∈ S` (reachable from below)\n"
"2. Each `bₙ` is an upper bound (unreachable from `S`)\n"
"3. `bₙ - aₙ → 0` (they squeeze together)\n"
"\n"
"The limit of this squeeze is exactly the supremum!\n"
"\n"
"**What's Coming**: Armed with the LUB property, you're now ready for the hard part of Heine-Borel. In Level 4, you'll prove that closed intervals `[a,b]` are compact. This will use your LUB property in a sophisticated way to show that any open cover can be reduced to a finite subcover.\n"
"\n"
"**Historical Note**: This property was one of the last pieces needed to make calculus rigorous. Weierstrass, Dedekind, and Cantor all worked on different ways to construct ℝ with this completeness property in the 1870s.\n"
"\n"
"You've just proved one of the crown jewels of real analysis! 👑"
msgstr ""

#: Game.Levels.L9Lecture
msgid "Lecture 9: Algebraic Limit Theorem, Part IV"
msgstr ""

#: Game.Levels.L11Levels.L03_IsBddOfCauchy
msgid "# Outstanding! You've proven that Cauchy sequences are bounded!\n"
"\n"
"This was a challenging proof involving case analysis, finite sums, and careful bookkeeping—but you did it! You've shown that the self-referential Cauchy property is powerful enough to guarantee boundedness.\n"
"\n"
"## What you've accomplished\n"
"\n"
"You've now proven that Cauchy sequences share two key properties with convergent sequences:\n"
"1. **They're bounded** (this level)\n"
"2. **They're closed under addition** (previous level)\n"
"\n"
"And you did all this **without ever mentioning where they converge**!\n"
"\n"
"## Why this matters\n"
"\n"
"This theorem is absolutely crucial for the theory of real numbers:\n"
"\n"
"- In the rationals `ℚ`, there are Cauchy sequences that don't converge (like the decimal approximations to `√2`)\n"
"- But they're still *bounded*, which means they're not escaping to infinity\n"
"- This boundedness will be essential when we prove the **Bolzano-Weierstrauss theorem**: every bounded sequence has a convergent subsequence\n"
"- Eventually, we'll use these facts to show that in `ℝ` (but not in `ℚ`), every Cauchy sequence *does* converge—this is called **completeness**\n"
"\n"
"## The technique you mastered\n"
"\n"
"The key technique here was splitting into cases:\n"
"- **Finitely many terms** (`m < N`): Handled by taking a maximum\n"
"- **Infinitely many terms** (`m ≥ N`): Handled by the Cauchy property\n"
"\n"
"This \"finite + infinite\" splitting technique appears throughout analysis!\n"
"\n"
"## Looking ahead\n"
"\n"
"You've now built up the basic theory of Cauchy sequences. Next, we'll start connecting this back to the real numbers and exploring what it means for ℝ to be **complete**—the property that makes real analysis work!\n"
"\n"
"Congratulations on completing this lecture!"
msgstr ""

#: Game.Levels.L19Levels.L01
msgid "If `Series a` converges absolutely, then for any `ε > 0`, there is an `N`, so that,\n"
"  for any finite set `S` whose elements are all at least `N`, `∑ k ∈ S, |a k| < ε`."
msgstr ""

#: Game.Levels.L10Pset.L10Pset3
msgid "If sequences `a b : ℕ → ℝ` converge with `a` going to `L` and `b` going to `M`, then `a n * b n` converges to `L * M`."
msgstr ""

#: Game.Levels.L19Levels.L04
msgid "# Level 4 **Bigger Boss**: Conditional Convergence Theorem\n"
"\n"
"Prepare yourself for one of the most shocking and counterintuitive theorems in all of mathematics!\n"
"\n"
"## The Astounding Theorem\n"
"\n"
"**Theorem (Riemann's Rearrangement Theorem)**: If a series `∑ a_n` converges but does *not* converge absolutely (i.e., it is *conditionally convergent*), then for **any** real number `L`, there exists a rearrangement `σ` such that the rearranged series `∑ a_(σ(n))` converges to `L`.\n"
"\n"
"In fact (though we won't prove it here), there also exist rearrangements that diverge to `+∞`, diverge to `-∞`, or oscillate without converging at all!\n"
"\n"
"## What This Means\n"
"\n"
"If a series is only conditionally convergent, then:\n"
"\n"
"**Infinite summation is as non-commutative as possible!!!**\n"
"\n"
"By cleverly rearranging the terms, we can make the series converge to *literally any value we want*. The sum depends entirely on the order in which we add the terms. There are no restrictions—pick any target `L ∈ ℝ`, and we can rearrange to hit it exactly.\n"
"\n"
"## A Concrete Example\n"
"\n"
"Consider the alternating harmonic series:\n"
"`∑_{k=1}^∞ (-1)^(k+1)/k = 1 - 1/2 + 1/3 - 1/4 + 1/5 - 1/6 + ... = ln 2`\n"
"\n"
"This converges to `ln 2 ≈ 0.693` but not absolutely (the harmonic series diverges).\n"
"\n"
"By Riemann's theorem, we can rearrange it to converge to:\n"
"- `π` (or any other positive number)\n"
"- `0` (or any negative number)\n"
"- `1000000` (or any huge number)\n"
"- `-1/137` (or any specific target you want)\n"
"\n"
"The same terms, but a different order, give a completely different answer!\n"
"\n"
"## The Complete Dichotomy\n"
"\n"
"Combined with Level 3, we now have a stunning dichotomy:\n"
"- **Absolute convergence** → rearrangement invariance (sum never changes)\n"
"- **Conditional convergence** → complete chaos (sum can be anything)\n"
"\n"
"There is no middle ground! Either order doesn't matter at all, or order is everything.\n"
"\n"
"## Why You Can't Just Use Positive Terms\n"
"\n"
"Note that we cannot simply take all the positive terms and ignore the negative terms—that wouldn't be a rearrangement at all, since a rearrangement must include every term of the original series exactly once. The challenge is to interleave positive and negative terms cleverly so that all terms appear while still hitting our target.\n"
"\n"
"## The Proof Strategy (Sketch)\n"
"\n"
"The proof uses a greedy algorithm:\n"
"1. Separate positive and negative terms (both subseries diverge—key lemma!)\n"
"2. Add positive terms until the sum exceeds `L`\n"
"3. Add negative terms until the sum drops below `L`\n"
"4. Repeat, oscillating around `L` with decreasing amplitude\n"
"5. Since `a_n → 0`, the oscillations shrink and we converge to `L`\n"
"\n"
"The formal proof (which we leave as `sorry`) requires careful bookkeeping to define `σ` and verify all terms appear exactly once.\n"
"\n"
"## Historical Impact\n"
"\n"
"Discovered by Bernhard Riemann in 1854, this theorem shocked the mathematical world. It showed that convergence alone is insufficient—*how* a series converges (absolutely vs. conditionally) fundamentally determines its properties.\n"
"\n"
"This result helped establish modern standards of rigor in analysis and revealed the subtle, sometimes treacherous, nature of infinite processes.\n"
"\n"
"Your task: Appreciate the statement of this magnificent theorem (the full proof is beyond our scope, but the ideas are accessible)!"
msgstr ""

#: Game.Levels.L21Levels.L06
msgid "# Level 2: The Derivative at a Point\n"
"\n"
"We've studied limits of functions extensively. Now we apply this knowledge to one of the most important concepts in calculus: the **derivative**!\n"
"\n"
"## The Definition\n"
"\n"
"**Definition (`FunDerivAt`):** We say that `f` has derivative `L` at `c` if:\n"
"\n"
"`FunLimAt (fun h ↦ (f (c + h) - f c) / h) L 0`\n"
"\n"
"This is written `FunDerivAt f L c`.\n"
"\n"
"**Reading the definition:** The derivative is the limit of the **difference quotient** as `h → 0`:\n"
"\n"
"`f'(c) = lim[h→0] (f(c + h) - f(c)) / h`\n"
"\n"
"## The Geometric Interpretation\n"
"\n"
"The difference quotient `(f(c + h) - f(c)) / h` is the **slope of the secant line** through the points `(c, f(c))` and `(c + h, f(c + h))`.\n"
"\n"
"As `h → 0`, these secant lines approach the **tangent line** at `x = c`, and the derivative is the slope of this tangent line!\n"
"\n"
"## Computing a Derivative\n"
"\n"
"Let's compute the derivative of `f(x) = x² - 1` at `x = 2`.\n"
"\n"
"We need to find the limit:\n"
"\n"
"`lim[h→0] (f(2 + h) - f(2)) / h`\n"
"\n"
"`     = lim[h→0] ((2 + h)² - 1 - (2² - 1)) / h`\n"
"\n"
"`     = lim[h→0] ((2 + h)² - 1 - 3) / h`\n"
"\n"
"`     = lim[h→0] (4 + 4h + h² - 4) / h`\n"
"\n"
"`     = lim[h→0] (4h + h²) / h`\n"
"\n"
"`     = lim[h→0] (h(4 + h)) / h`\n"
"\n"
"`     = lim[h→0] (4 + h)`\n"
"\n"
"`     = 4`\n"
"\n"
"So the derivative is `4`!\n"
"\n"
"## Your Challenge\n"
"\n"
"Prove that the function `f(x) = x² - 1` has derivative `4` at `x = 2`:\n"
"\n"
"`FunDerivAt (fun x ↦ x^2 - 1) 4 2`\n"
"\n"
"**Hint:** You need to prove `FunLimAt (fun h ↦ ((2 + h)^2 - 1 - 3) / h) 4 0`.\n"
"\n"
"Given `ε > 0`, you need to find `δ > 0` such that for `h ≠ 0` with `|h| < δ`, we have:\n"
"\n"
"`|((2 + h)² - 1 - 3) / h - 4| < ε`\n"
"\n"
"Simplify the difference quotient algebraically:\n"
"- `(2 + h)² - 1 - 3 = 4 + 4h + h² - 4 = 4h + h²`\n"
"- So `((2 + h)² - 1 - 3) / h = (4h + h²) / h = 4 + h` (for `h ≠ 0`)\n"
"- Thus `|((2 + h)² - 1 - 3) / h - 4| = |4 + h - 4| = |h|`\n"
"\n"
"Therefore, taking `δ = ε` works perfectly!"
msgstr ""

#: Game.Levels.L18Pset.L10
msgid "Prove `DiffGoesToZero`"
msgstr ""

#: Game.Levels.L7Levels.L01_Eventually
msgid "# Level 2: Eventually—Convergent Sequences Stay Near Their Limits\n"
"\n"
"When a sequence converges to a nonzero limit, it doesn't just get arbitrarily close to\n"
"that limit—it **eventually stays away from zero** as well. This \"eventually bounded away\n"
"from zero\" property is crucial for many theorems involving quotients and reciprocals.\n"
"\n"
"The intuition is straightforward: if a sequence is converging to some nonzero value `L`,\n"
"then eventually the sequence terms must be at least half as large (in absolute value) as\n"
"`L` itself. They can't simultaneously be approaching `L` and shrinking toward zero.\n"
"\n"
"## What We're Proving\n"
"\n"
"**Theorem:** If `a : ℕ → ℝ` converges to `L` with `L ≠ 0`, then there exists `N` such\n"
"that for all `n ≥ N`, we have `|a (n)| ≥ |L| / 2`.\n"
"\n"
"In other words, once `n` is large enough, the sequence stays at least half as far from\n"
"zero as the limit is.\n"
"\n"
"## The Strategy\n"
"\n"
"The key is to use the convergence condition with `ε = |L| / 2`:\n"
"\n"
"1. Since `L ≠ 0`, we have `|L| > 0`, so `ε = |L| / 2` is a valid positive epsilon\n"
"2. Convergence gives us `N` such that `|a (n) - L| < |L| / 2` for all `n ≥ N`\n"
"3. This means `a (n)` is within distance `|L| / 2` of `L`\n"
"4. By the reverse triangle inequality, this forces `|a (n)| ≥ |L| / 2`\n"
"\n"
"The algebraic key is recognizing that:\n"
"$$|L| = |a (n) + (L - a (n))| \\leq |a (n)| + |L - a (n)| < |a (n)| + \\frac{|L|}{2}$$\n"
"\n"
"Rearranging gives us `|a (n)| > |L| / 2`.\n"
"\n"
"## Why This Matters\n"
"\n"
"This result is essential for the next level, where we'll prove that reciprocals of\n"
"convergent sequences converge. We need to know that the denominators don't approach zero,\n"
"which would cause the reciprocals to blow up. This theorem provides exactly that guarantee!"
msgstr ""

#: Game.Levels.L18Pset.L08
msgid "`∑ k ∈ range (m + 1), f k = f 0 + ∑ k ∈ range m, f (k+1)`. This pulls out the first\n"
"term in the sum instead of `sum_range_succ`, which pulls out the last term."
msgstr ""

#: Game.Levels.L6Lecture
msgid "# More on sequences\n"
"\n"
"Welcome to Lecture 6, where we continue our deep dive into the fundamental theorems of real analysis.\n"
"\n"
"This lecture focuses on two essential aspects of mathematical reasoning: **logical structure** and **practical techniques**. You'll master the fundamental logical operations that appear everywhere in mathematics—working with \"and\" statements, \"or\" statements, and the connections between them. These aren't just abstract logical exercises; they're the building blocks that make complex proofs manageable and clear.\n"
"\n"
"**What You'll Accomplish:**\n"
"\n"
"First, you'll develop fluency with Lean's logical tactics: constructing conjunctions with `split_ands`, making strategic choices with `left` and `right`, extracting information with dot notation, and handling case analysis with `cases'`. These form a complete toolkit for navigating the logical landscape of mathematical proof.\n"
"\n"
"Then you'll apply these tools to prove one of the most elegant and powerful results in analysis: the **Squeeze Theorem**. This theorem beautifully demonstrates how logical reasoning and analytical insight combine to create mathematical magic. When you trap a sequence between two others that converge to the same limit, the trapped sequence has no choice but to converge there too!\n"
"\n"
"**The Mathematical Journey:**\n"
"\n"
"You'll see how the abstract logical operations you learn connect directly to concrete analytical reasoning. The same `split_ands` technique that helps you break down complex goals will help you extract bounds from convergence conditions. The `abs_lt` theorem will bridge the gap between absolute value statements and ordinary inequalities, giving you the tools to work with epsilon-N definitions effectively.\n"
"\n"
"By the end of this lecture, you'll have not just learned individual techniques, but gained the ability to orchestrate them in sophisticated mathematical arguments. You're building the foundation for all of real analysis—and developing the logical clarity that distinguishes excellent mathematical reasoning from merely correct calculations.\n"
"\n"
"Let's begin this journey from logical fundamentals to analytical mastery!"
msgstr ""

#: Game.Levels.L8Lecture
msgid "Lecture 8: Induction"
msgstr ""

#: Game.Levels.L1RealAnalysisStory.L05_use
msgid "Perfect! You've learned the `use` tactic for existence proofs.\n"
"\n"
"Notice what happened:\n"
"1. `use 6` told Lean that $c = 6$ is our proposed value\n"
"2. The goal changed to proving $(x + y)^4 = x^4 + 4x^3y + 6x^2y^2 + 4xy^3 + y^4$\n"
"3. `ring_nf` verified that this algebraic identity is correct\n"
"\n"
"The `use` tactic is fundamental in real analysis. You'll need it to:\n"
"- Find specific values of $\\varepsilon$ and $\\delta$ in limit proofs\n"
"- Construct witnesses for existence theorems\n"
"- Provide counterexamples\n"
"\n"
"Your growing toolkit:\n"
"- `apply`, `rfl`, `rewrite` for basic equality reasoning\n"
"- `ring_nf` for algebraic manipulation\n"
"- `use` for existence proofs"
msgstr ""

#: Game.Levels.L22Pset.L04
msgid "# Level 4: Integral Exercise\n"
"\n"
"As you may imagine, the proof that `f(x) = x ^ 2` is integrable will involve the following formula for the sum of squares:\n"
"\n"
"`∑ i ∈ Finset.range n, (i + 1) ^ 2 = (n * (n + 1) * (2 * n + 1)) / 6`.\n"
"\n"
"(All as real numbers.) Prove it. Then in natural language, prove that `f(x) = x ^ 2` is integrable on `[a,b]`."
msgstr ""

#: Game.Levels.L24Levels.L02
msgid "`(S : Set ℝ) : Prop := IsOpen Sᶜ`\n"
"\n"
"A set is closed if its complement is open."
msgstr ""

#: Game.Levels.L18Levels.L02
msgid "If `a : ℕ → ℝ` is `Antitone` and `∀ n, 0 ≤ a n`, then the odd alternating series `n ↦ ∑ k ∈ range (2n+1), (-1)^k * a k` is bounded below by `0`."
msgstr ""

#: Game.Levels.L8PsetIntro
msgid "Pset 8"
msgstr ""

#: Game.Levels.L18Pset.L05
msgid "SeqEvenOdd"
msgstr ""

#: Game.Levels.L24Levels.L02
msgid "# Level 2: Heine-Borel Theorem: Part 1b\n"
"\n"
"**The Goal**: Complete the first direction of Heine-Borel by proving that every compact set is closed.\n"
"\n"
"**New Topology Vocabulary**:\n"
"- **Open Set**: `IsOpen S := ∀ x ∈ S, ∃ δ > 0, Ball x δ ⊆ S`\n"
"  - Translation: \"Around every point in `S`, there's a whole ball that stays inside `S`\"\n"
"  - Think: \"No boundary points belong to the set\"\n"
"- **Closed Set**: `IsClosed S := IsOpen Sᶜ`\n"
"  - Translation: \"The complement is open\"\n"
"  - Think: \"All boundary points belong to the set\"\n"
"\n"
"**The Challenge**: To prove `S` is closed, we need to prove `Sᶜ` is open. That means: for any point `y ∉ S`, we need to find a ball around `y` that stays completely outside `S`.\n"
"\n"
"**The Strategy - Separation by Compactness**:\n"
"1. **Local Separation**: For each point `x ∈ S`, the distance `|y - x|` is positive (since `y ∉ S`). Create a ball around `x` of radius `|y - x|/2` - this ball contains `x` but can't reach `y`.\n"
"\n"
"2. **Covering**: These balls cover `S`, so by compactness, finitely many suffice.\n"
"\n"
"3. **Uniform Separation**: Take the minimum of the finitely many separating distances. This gives you a uniform `δ > 0` such that `Ball(y, δ)` stays away from all of `S`.\n"
"\n"
"**Why This Works**: You're using compactness to convert \"local separation\" (each point in `S` is some positive distance from `y`) into \"uniform separation\" (there's a single `δ` that works everywhere).\n"
"\n"
"**Your Mission**: Formalize this separation argument to show that `Sᶜ` is open!"
msgstr ""

#: Game.Levels.L8Levels.L03_Induction'
msgid "## Your First Induction Proof Complete!\n"
"\n"
"You've successfully proven that `n < 2^n` for all natural numbers using mathematical induction. This demonstrates a fundamental principle: exponential functions grow faster than linear functions.\n"
"\n"
"## What You Learned\n"
"\n"
"This proof introduced several key techniques:\n"
"\n"
"**Combining Proof Methods:** You used `induction'` as the overall structure, but within the inductive step, you needed `by_cases` to handle different scenarios. This is a common pattern: induction provides the framework, but you often need other tactics to complete the argument.\n"
"\n"
"**Handling Edge Cases:** The `k = 0` case required separate treatment because the inequality `k + 1 ≤ 2k` doesn't hold when `k = 0`. Recognizing when to split cases is an essential skill in mathematical proof.\n"
"\n"
"**Building Inequality Chains:** In the `k ≠ 0` case, you constructed a chain of inequalities: `k + 1 ≤ 2k < 2 · 2^k = 2^(k+1)`. Using the inductive hypothesis `k < 2^k` along with `1 ≤ k` allowed you to bridge from `k + 1` to `2^(k+1)`.\n"
"\n"
"## The Power of Induction\n"
"\n"
"Mathematical induction is one of the most versatile proof techniques. It's essential for:\n"
"- Proving formulas like `∑(i=1 to n) i = n(n+1)/2`\n"
"- Establishing inequalities involving factorials, exponentials, and recursive sequences\n"
"- Verifying properties of recursively defined structures\n"
"- Proving algorithm correctness in computer science\n"
"\n"
"## Key Insight\n"
"\n"
"The key insight to remember: induction transforms an infinite problem (proving something for all `n`) into two finite problems (the base case and the inductive step). Master this technique, and you'll have access to a vast collection of provable theorems."
msgstr ""

#: Game.Levels.L23Levels.L01
msgid "# What You've Just Proved\n"
"\n"
"You've just established a crucial bridge between uniform continuity and integration theory! Here's why this result matters:\n"
"\n"
"**The Big Picture**: To prove that Riemann sums converge (i.e., that integrals exist), we need to show the Riemann sum sequence is Cauchy. But Riemann sums with different numbers of partitions seem hard to compare directly. Your theorem solves this by showing that if one partition count is a multiple of another, and both are fine enough, then their Riemann sums are close.\n"
"\n"
"**The Uniform Continuity Connection**: Notice how the proof relied crucially on having a *single* `δ` that works for all points in `[a,b]`. If we only had pointwise continuity (where `δ` depends on the specific point), we couldn't make this argument work. This is why uniform continuity is the 'right' condition for integration.\n"
"\n"
"**Next Steps**: In the next level, we'll use this result to prove the fundamental theorem that uniformly continuous functions are integrable. The strategy will be:\n"
"1. Given any two large partition counts `m` and `n`\n"
"2. Consider their common multiple `m * n`\n"
"3. Use your theorem twice: once to compare `m` with `m * n`, and once to compare `n` with `m * n`\n"
"4. Apply the triangle inequality to conclude that the Riemann sums for `m` and `n` are close\n"
"\n"
"This is a beautiful example of how the 'right' mathematical framework (uniform continuity) makes difficult problems tractable!"
msgstr ""

#: Game.Levels.L3Lecture
msgid "Lecture 3: More fun with Sequences"
msgstr ""

#: Game.Levels.L22Pset.L03
msgid "Differentiability Exercise"
msgstr ""

#: Game.Levels.L18Levels.L01
msgid "If `n ≤ m`, then `|∑ k ∈ Ico n m, a k| ≤ ∑ k ∈ Ico n m, |a k|`."
msgstr ""

#: Game.Levels.L18Pset.L02
msgid "# Level 2: `Series_abs_add`\n"
"\n"
"Prove `Series_abs_add`:"
msgstr ""

#: Game.Levels.L5Lecture
msgid "Lecture 5: Algebraic Limit Theorem, Part I"
msgstr ""

#: Game.Levels.L1RealAnalysisStory.L07_specialize
msgid "Write `specialize hf t` to apply the universal statement to the specific value t."
msgstr ""

#: Game.Levels.L4Levels.L01_NonConverge
msgid "# A Great Debate\n"
"\n"
"In the 19th century, when people were still confused about limits in general, there was a specific sequence that they fought over:\n"
"\n"
"1, -1, 1, -1, 1, -1, ...\n"
"\n"
"Does this converge or not???\n"
"\n"
"Some people said, well, you go up one then down one, so on average, it's around zero. So the limit should be 0.\n"
"\n"
"Other people said: look at the partial sums of the sequence:\n"
"\n"
"1 = 1\n"
"\n"
"1 + (-1) = 0\n"
"\n"
"1 + (-1) + 1 = 1\n"
"\n"
"1 + (-1) + 1 + (-1) = 0\n"
"\n"
"Ah so the partial sums alternate between 1 and 0, so maybe the limit is 1/2!\n"
"\n"
"This is the kind of trouble you get into if you don't have a community consensus on what the definitions of things are, namely, if you don't have a rigorous definition of limit. Luckily, we now do!\n"
"\n"
"With that definition, this sequence .... does not have a limit (\"diverges\").\n"
"\n"
"In order to express that formally, let's make a new definition:\n"
"\n"
"`def SeqConv (a : ℕ → ℝ) : Prop := ∃ L, SeqLim a L`\n"
"\n"
"That is, a sequence `a` \"converges\" (without specifying to what), if there indeed exists some real number `L`\n"
"so that `a` converges to that number.\n"
"\n"
"In this level, then, our goal is to prove:\n"
"\n"
"`Goal : ¬ SeqConv a`,\n"
"\n"
"given the assumption `ha : ∀ n, a n = (-1 : ℝ) ^ n`. (Note that the \"not\" symbol, `¬`, is obtained by typing\n"
"`\\not`.)\n"
"\n"
"How do you prove the negation of something? Logically speaking, you would say, well, if that thing did happen, then we'd have a contradiction. Technically, `¬ P` is definitionally equivalent to: `P → False`.\n"
"\n"
"So we could start our proof by reminding ourselves of this fact, by typing:\n"
"\n"
"`change SeqConv a → False`\n"
"\n"
"That will change the Goal to: `SeqConv a → False`.\n"
"\n"
"In general, I would recommend the following protocol:\n"
"\n"
"1) Think. Do scratchwork, get a vague sense of how to piece the argument together.\n"
"\n"
"2) Then prove it formally. You're NOT done! Just because you proved it formally doesn't *necessarily* mean that you really understand what's going on! The goal of mathematics is *not* that it just works, but rather that you **understand** exactly what's going on. So step 3 is:\n"
"\n"
"3) Give a natural language proof that explains (to yourself, as much as to anyone else, including me) what's going on and why.\n"
"\n"
"Using only knee jerk reactions (if you see `P → Q` in the Goal, write `intro`. If you see `∃` in a hypothesis, write `choose`. If you see a definition in the Goal or a hypothesis, write `change`), we got as far as:\n"
"\n"
"**Objects:** `a : ℕ → ℝ`, `L : ℝ`\n"
"\n"
"**Assumptions:** `ha : ∀ (n : ℕ), a n = (-1) ^ n`, `hL : ∀ ε > 0, ∃ N, ∀ n ≥ N, |a n - L| < ε`\n"
"\n"
"**Goal:** `False`\n"
"\n"
"Remember the Engineer and Mechanic: the Engineer gets to specify any tolerance, and the Mechanic has to guarantee that we'll be within that tolerance \"eventually\", that is, for all large enough `n`, as measured by the lower bound `N`.\n"
"\n"
"**Key Idea:** Find an `ε` that is too tight a tolerance, and the Mechanic will never be able to get within that specification. Because the sequence alternates between `1` and `-1`, which differ by `2`, the tolerance `ε = 1` would already be enough, but just to be safe, let's give ourselves a little more room, and set `ε = 1/2`.\n"
"\n"
"Note: Had we set `ε = 1.5`, that would *not* work. We can't rule out the possibility that `L= 0`, and both values `1` and `-1` *are* indeed within that tolerance. So we won't find a contradiction that way.\n"
"\n"
"\n"
"After a bunch of computation, we reached the following:\n"
"\n"
"`|1 - L| < 1/2`\n"
"\n"
"and\n"
"\n"
"`|-1 - L| < 1/2`\n"
"\n"
"Let's try to come up with a contradiction from that.\n"
"\n"
"`2 = |2| = |1 - (-1)| = |(1 - L) + (L - (-1))|`\n"
"\n"
"`≤|(1 - L)| + |(L - (-1))| = |(1 - L)| + |-((-1) - L)|`\n"
"\n"
"`= |(1 - L)| + |((-1) - L)| < 1/2 + 1/2 = 1`\n"
"\n"
"And that get us the desired contradiction.\n"
"\n"
"\n"
"## New Tools You'll Need\n"
"\n"
"- **Negation**: If `P` is some `Prop`, then `¬ P` is definitionally equivalent to `P → False`. So you can write `change P → False`, either at the Goal, or `at` a hypothesis.\n"
"\n"
"\n"
"- **The triangle inequality**: To add the fact that `|x + y| ≤ |x| + |y|` to our list of hypotheses, invoke the `abs_add` theorem:\n"
"\n"
"`have factName : |x + y| ≤ |x| + |y| := by apply abs_add`\n"
"\n"
"- **Negation inside an absolute value**: You may also find useful the theorem `abs_neg`, which can be called via:\n"
"\n"
"`have factName : |-x| = |x| := by apply abs_neg`\n"
"\n"
"Warning! Make sure the pattern `|-Something|` is on the left hand side. If Lean doesn't see an absolute value\n"
"followed by a minus sign, `abs_neg` won't work!"
msgstr ""

#: Game.Levels.L24Levels.L05
msgid "# Level 5: Heine-Borel Theorem: Part 2b\n"
"\n"
"**The Grand Finale**: We'll complete Heine-Borel by proving that any closed, bounded set is compact. The strategy is elegant: show that closed subsets of compact sets are compact, then use Level 4.\n"
"\n"
"**New Lean Technology - Sum Types** 📦\n"
"\n"
"Before diving into the proof, you need to master Lean's **disjoint union** (sum type):\n"
"\n"
"**What is `α ⊕ β`?**: It's the \"either `α` or `β`\" type - every element is either from type `α` or from type `β`, but not both. Think of it as two boxes labeled \"Left\" and \"Right\":\n"
"\n"
"`α ⊕ β = {Sum.inl a : a ∈ α} ∪ {Sum.inr b : b ∈ β}`\n"
"\n"
"**Note**:\n"
"- `Sum.inl a` puts element `a : α` into the \"left\" side\n"
"- `Sum.inr b` puts element `b : β` into the \"right\" side\n"
"\n"
"**Pattern Matching with `match`**: To make a function on a sum type, use `match`:\n"
"\n"
"`let f : α ⊕ β → γ := fun x ↦\n"
"  match x with\n"
"  | Sum.inl a => ... -- handle the α case\n"
"  | Sum.inr b => ... -- handle the β case`\n"
"\n"
"**Case Analysis with `cases`**: When arguing about where an element of a sum type came from, use `cases`:\n"
"\n"
"`cases x with\n"
"| inl a => ... -- when x came from α\n"
"| inr b => ... -- when x came from β`\n"
"\n"
"**Extracting Components**: If `s : Finset (α ⊕ β)`, then:\n"
"- `s.lefts : Finset α` extracts all the \"left\" elements\n"
"- `a ∈ s.lefts ↔ Sum.inl a ∈ s`\n"
"\n"
"**Why Sum Types for This Proof?**\n"
"\n"
"We need to handle TWO kinds of balls simultaneously:\n"
"1. **Original balls** (type `ι`) that cover our closed set `S`\n"
"2. **Avoidance balls** (type `Sᶜ`) that cover points outside `S`\n"
"\n"
"The sum type `ι ⊕ Sᶜ` lets us create a unified covering system!\n"
"\n"
"**The Strategy**:\n"
"1. Start with any covering of closed set `S ⊆ T` where `T` is compact\n"
"2. Since `S` is closed, `Sᶜ` is open - so each point in `Sᶜ` has a ball staying in `Sᶜ`\n"
"3. Use sum types to combine: original balls + avoidance balls = covering of all `T` (in fact, all of `ℝ`)\n"
"4. Apply compactness of `T` to get finite subcover\n"
"5. Extract just the \"left\" (original) balls to cover `S`, since avoidance balls don't touch `S`\n"
"\n"
"**Your Mission**: Master sum types and use them to extend any covering of a closed subset to a covering of the whole compact set. This completes the Heine-Borel theorem!"
msgstr ""

#: Game.Levels.L7Levels.L01_Eventually
msgid "If `a : ℕ → ℝ` converges to `L` and `L ≠ 0`, then there is an `N` so that\n"
"for all `n ≥ N`, `|a (n)| ≥ |L| / 2`."
msgstr ""

#: Game.Levels.L5Levels.L01_DoubleSeqConv
msgid "# 🎉 Brilliant Work! 🎉\n"
"\n"
"You've mastered your first true theorem of analysis! Let's celebrate what you accomplished and understand the deeper patterns.\n"
"\n"
"**What you just proved:**\n"
"If a sequence converges to a limit, then any constant multiple of that sequence converges to the constant multiple of the limit. In factory terms: 'If I can meet quality standards, I can also meet those same standards when scaling my output—I just need to be more precise with my inputs!'\n"
"\n"
"**The Elegant Strategy:**\n"
"Your proof used the **inverse scaling** principle:\n"
"1. **Tolerance inversion**: To achieve tolerance ε for doubled output, demand tolerance ε/2 for original input\n"
"2. **Algebraic factoring**: `2 * a n - 2 * L = 2 * (a n - L)` revealed the structure\n"
"3. **Absolute value scaling**: `|2 * x| = |2| * |x|`, followed by `norm_num`, converted the factored form to the needed bound\n"
"4. **Linear arithmetic**: The final `linarith [hN]` combined `2 * |a n - L| < 2 * (ε / 2) = ε`\n"
"\n"
"## Check in, in Natural Language\n"
"\n"
"Let's again step back from the formal Lean proof and understand what we just proved in plain English.\n"
"\n"
"**Theorem (in natural language):** If a sequence of real numbers converges to some limit, then the sequence formed by doubling each term converges to double the original limit.\n"
"\n"
"**Proof:** Suppose sequence $a_n$ converges to $L$, and we want to show that $b_n = 2 \\cdot a_n$ converges to $2L$.\n"
"\n"
"By definition, we need to show that for any tolerance $\\varepsilon > 0$, we can find a point $N$ such that for all $n \\geq N$, we have $|b_n - 2L| < \\varepsilon$.\n"
"\n"
"Here's the key insight: Since $a_n$ converges to $L$, we can make $|a_n - L|$ arbitrarily small. Specifically, we can find an $N$ such that $|a_n - L| < \\varepsilon/2$ for all $n \\geq N$.\n"
"\n"
"Now, for any $n \\geq N$:\n"
"$$|b_n - 2L| = |2a_n - 2L| = |2(a_n - L)| = 2|a_n - L| < 2 \\cdot \\frac{\\varepsilon}{2} = \\varepsilon$$\n"
"\n"
"Therefore, $b_n$ converges to $2L$, completing the proof.\n"
"**QED**\n"
"\n"
"So what do you think? Do you prefer the natural langauge version, or the formal version? (It's a real question! Please tell me.)"
msgstr ""

#: Game.Levels.L1RealAnalysisStory.L09_big_boss
msgid "Big Boss: The Ultimate Tactic Challenge"
msgstr ""

#: Game.Levels.L6Levels.L00_SumOfSeqs
msgid "For two sequences `a b : ℕ → ℝ` and real numbers `L M : ℝ`, with the hypotheses that `SeqLim a L` and `SeqLim b M`, the theorem `SumLim` says that if\n"
"there is a third sequence `c : ℕ → ℝ` so that for all `n`, `c n = a n + b n` (that is, `c` is the sum of the sequences), then `SeqLim c (L + M)` holds."
msgstr ""

#: Game.Levels.L1Pset.L1Pset4
msgid "# Problem 4\n"
"\n"
"This problem looks very similar to the previous one, but without a few hints, it\n"
"may cause great difficulty. The issue is that, last time, you likely called `specialize h1 0`, and turned `h1` into:\n"
"\n"
"`h1 : g (0 + 1) = g (0) + 3`\n"
"\n"
"If you do that now, the original `h1` will be *gone*, and you won't have a way of accessing it *again* to bootstrap from `g (1)` to `g (2)`. So what should you do?\n"
"\n"
"Observe that `have` can perform the same\n"
"role as `specialize` (and much more)! Try starting your solution with:\n"
"\n"
"`have h3 : g (0 + 1) = g (0) + 3 := by apply h1 0`\n"
"\n"
"This will not affect the original statement\n"
"of `h1`, but will instead add a *new* hypothesis, `h3`, which amounts to the\n"
"desired fact that `g (0 + 1) = g (0) + 3`.\n"
"Notice what's happening in the proof: `h1` says: for all `x`, `g (x + 1) = g (x) + 3`.\n"
"So `h1` is really a *function* whose input\n"
"is a real number `x`, and whose output is a\n"
"*proof* of the fact that, for this value of `x`, `g (x + 1) = g (x) + 3` holds. So when\n"
"we feed `0` into `h1`, it has the same effect\n"
"as it did when we `specialize`d, thus giving a proof of\n"
" exactly what was claimed in the `have` statement.\n"
"\n"
"Now you should be able to solve this problem."
msgstr ""

#: GameServer.RpcHandlers
msgid "level completed with warnings… 🎭"
msgstr ""

#: Game.Levels.L12Levels.L01_Choose
msgid "Enhanced Choose"
msgstr ""

#: Game.Levels.L11Levels.L02_IsCauchyOfSum
msgid "If sequences `a` and `b` are Cauchy, then so is their sum."
msgstr ""

#: Game.Levels.L22Levels.L03
msgid "Summation of a constant: `∑ i ∈ s, c = c * s.card`."
msgstr ""

#: Game.Levels.L20Levels.L03
msgid "The sum of continuous functions is continuous."
msgstr ""

#: Game.Levels.L11Levels.L03_IsBddOfCauchy
msgid "If a sequence `a` is Cauchy, then it is eventually bounded."
msgstr ""

#: Game.Levels.L24Levels.L05
msgid "`(s : Finset (α ⊕ β)) : Finset α`\n"
"\n"
"The `lefts` of a finite set `s` of elements from the disjoint union `α ⊕ β` is the finite set of all elements from `α` that appear in `s`."
msgstr ""

#: Game.Levels.L12Pset.L12Pset1
msgid "Prove `IsCauchy_of_AntitoneBdd`"
msgstr ""

#: Game.Levels.L18Pset.L05
msgid "Prove `SeqEvenOdd`"
msgstr ""

#: Game.Levels.L7Levels.L00_Uniqueness
msgid "Prove that limits are unique."
msgstr ""

#: Game.Levels.L24Levels.L04
msgid "Any closed interval `[a, b]` (which is closed and bounded) is compact."
msgstr ""

#: Game.Levels.L6Levels.L05_AbsLt
msgid "AbsLe"
msgstr ""

#: Game.Levels.L1RealAnalysisStory.L02_rfl
msgid "Write `rfl` since we're proving that something equals itself."
msgstr ""

#: Game.Levels.L12Levels.L01_MonotoneBdd
msgid "# Level 3: Monotone and Bounded Implies Cauchy\n"
"\n"
"Now we tackle one of the fundamental theorems of real analysis: every bounded monotone sequence is Cauchy. This result provides a powerful convergence criterion that doesn't require knowing the limit beforehand.\n"
"\n"
"## The Intuitive Picture\n"
"\n"
"Why should this be true? If a sequence is monotone (that is, non-decreasing) and bounded above, then it can't \"escape to infinity\" - there's a ceiling it can't break through. But it also can't have persistent gaps, because each gap would push it a bit higher, and eventually these accumulated jumps would break through the ceiling. So the sequence must \"settle down\" and become Cauchy.\n"
"\n"
"Making this intuition rigorous requires the orbit technique you just mastered.\n"
"\n"
"## A Question of Generality\n"
"\n"
"Before diving in, let's address an important design choice. What type should our sequence have? We could work with `a : ℕ → ℝ` (real sequences), but we're building up to constructing the real numbers, so we shouldn't presuppose their existence. We could use `a : ℕ → ℚ` (rational sequences), but then we'd need to reprove everything for real sequences later.\n"
"\n"
"The elegant solution: work with an abstract type `X` that has just the properties we need. We'll assume `X` has:\n"
"- A linear order (so we can say `x ≤ y`)\n"
"- A norm (so we can say `|x|`)\n"
"- Field operations (so we can add, subtract, multiply, divide)\n"
"- A few other technical properties for the proof to work\n"
"\n"
"Then this theorem automatically applies to both rational and real sequences - Lean will verify that ℚ and ℝ satisfy all our assumptions about `X`.\n"
"\n"
"## Strategic Overview\n"
"\n"
"The proof uses contradiction. We'll assume a bounded monotone sequence is not Cauchy, which means there are persistent gaps of size `ε`. Using the `choose` tactic (as in the previous level), we'll extract subsequences that witness these gaps. Then we'll apply your orbit result to show these gaps accumulate without bound, contradicting the boundedness.\n"
"\n"
"**Your goal:** Prove that if `a : ℕ → X` is monotone and bounded above by `M`, then `a` is Cauchy.\n"
"\n"
"Note: This level uses a \"black box\" helper lemma `IterateGap` that we'll prove in the next level. For now, trust that it captures how gaps accumulate under iteration.\n"
"\n"
"## New Tools\n"
"\n"
"### Definition: `Monotone`\n"
"A sequence `a : ℕ → X` is monotone if `a n ≤ a m` whenever `n ≤ m`.\n"
"\n"
"### Theorem: `Monotone_of_succ`\n"
"To prove monotonicity, it's enough to check consecutive terms: if `a m ≤ a (m+1)` for all `m`, then `a` is `Monotone`.\n"
"\n"
"### Tactic: `push_neg`\n"
"Pushes negations through quantifiers: `¬∀` becomes `∃¬`, `¬∃` becomes `∀¬`, etc. Essential for proof by contradiction with complex statements.\n"
"\n"
"### The Helper Lemma: `IterateGap`\n"
"Given a monotone sequence with persistent gaps of size `ε` between subsequences `τ` and `σ`, the orbit `σ^[k] 0` accumulates at least `k * ε` growth from the starting point. This will be proven in Level 3.\n"
"\n"
"`theorem IterateGap (a : ℕ → X) (ha : Monotone a) (ε : X)\n"
"  (εpos : ε > 0)\n"
"  (τ : ℕ → ℕ) (hτ : ∀ n, τ n ≥ n)\n"
"  (σ : ℕ → ℕ) (hσ : ∀ n, σ n ≥ τ n)\n"
"  (hgap : ∀ n, ε ≤ |a (σ n) - a (τ n)|)\n"
"  : ∀ (k : ℕ), k * ε ≤ a (σ^[k] 0) - a 0\n"
"`"
msgstr ""

#: Game.Levels.L1RealAnalysisStory.L02_rfl
msgid "The rfl tactic"
msgstr ""

#: Game.Levels.L17Levels.L04
msgid "The Basel Problem"
msgstr ""

#: Game.Levels.L15Levels.L01_check
msgid "# Level 1 **Big Boss:** Completeness!\n"
"\n"
"We now know that Cauchy sequences of rational numbers converge to real numbers. In fact, they **are** real numbers—that's how we constructed ℝ! Let's make this official:\n"
"\n"
"## New theorem: `Conv_of_IsCauchy`\n"
"If a sequence `a : ℕ → ℚ` satisfies `IsCauchy a`, then `SeqConv a` holds—the sequence converges.\n"
"\n"
"Given that such a limit exists, we can name it:\n"
"\n"
"## New definition: `Real_of_CauSeq`\n"
"This takes a proof `ha : IsCauchy a` (for `a : ℕ → ℚ`) and returns the real number that `a` converges to.\n"
"\n"
"This real number behaves exactly as we'd hope:\n"
"\n"
"## New theorem: `SeqLim_of_Real_of_Cau`\n"
"If `ha : IsCauchy a` for `a : ℕ → ℚ`, then `SeqLim a (Real_of_CauSeq ha)`.\n"
"\n"
"---\n"
"\n"
"## The Big Question: What About Cauchy Sequences of Reals?\n"
"\n"
"We've completed the rationals by adding limits of Cauchy sequences, creating ℝ. But now we can ask: do Cauchy sequences of **real** numbers converge to real numbers? Or do we need yet another number system (the \"hyperreals\" or \"surreals\" for the Conway fans out there...)?\n"
"\n"
"**The answer:** No! The reals are **complete**.\n"
"\n"
"This is a general phenomenon: when you \"complete\" a space by adding equivalence classes of Cauchy sequences, the resulting space is automatically complete—all Cauchy sequences in the completed space converge within that same space.\n"
"\n"
"**Our goal:** Prove that any Cauchy sequence of real numbers converges to a real number.\n"
"\n"
"---\n"
"\n"
"## Unpacking the Problem: Cauchy Sequences of Cauchy Sequences\n"
"\n"
"Here's where things get interesting. Real numbers **are** Cauchy sequences of rationals (or rather, equivalence classes thereof). So what does it mean for `x : ℕ → ℝ` to be a Cauchy sequence of reals?\n"
"\n"
"Let's write `x = (x₀, x₁, x₂, ...)` as our sequence of reals.\n"
"\n"
"Each real `xₙ` is secretly a Cauchy sequence of rationals:\n"
"- `x₀` is represented by the Cauchy sequence `(q₀₀, q₀₁, q₀₂, ...)`\n"
"- `x₁` is represented by the Cauchy sequence `(q₁₀, q₁₁, q₁₂, ...)`\n"
"- `x₂` is represented by the Cauchy sequence `(q₂₀, q₂₁, q₂₂, ...)`\n"
"- and so on...\n"
"\n"
"Each `xₙ` is itself a function `ℕ → ℚ`, so the entire setup is really a **double-indexed array** of rationals:\n"
"\n"
"`q : ℕ → ℕ → ℚ`\n"
"\n"
"Visualized:\n"
"```\n"
"       j=0    j=1    j=2    j=3    ...\n"
"i=0:   q₀₀    q₀₁    q₀₂    q₀₃    ...   ← represents x₀\n"
"i=1:   q₁₀    q₁₁    q₁₂    q₁₃    ...   ← represents x₁\n"
"i=2:   q₂₀    q₂₁    q₂₂    q₂₃    ...   ← represents x₂\n"
"i=3:   q₃₀    q₃₁    q₃₂    q₃₃    ...   ← represents x₃\n"
" ⋮      ⋮      ⋮      ⋮      ⋮\n"
"```\n"
"\n"
"Each **row** `(qₙ₀, qₙ₁, qₙ₂, ...)` is a Cauchy sequence converging to `xₙ`.\n"
"\n"
"Let `hq : ∀ n, IsCauchy (q n)` denote the fact that each row is Cauchy.\n"
"\n"
"To say that `x` itself is Cauchy means:\n"
"```lean\n"
"∀ ε > 0, ∃ N, ∀ n ≥ N, ∀ m ≥ n,\n"
"  |Real_of_CauSeq (hq m) - Real_of_CauSeq (hq n)| < ε\n"
"```\n"
"\n"
"**Our task:** Given this Cauchy sequence `x` of reals, construct a single Cauchy sequence `y : ℕ → ℚ` of rationals such that:\n"
"- `hy : IsCauchy y`\n"
"- `SeqLim (fun n ↦ Real_of_CauSeq (hq n)) (Real_of_CauSeq hy)`\n"
"\n"
"In other words, prove that `xₙ → Real_of_CauSeq hy`.\n"
"\n"
"---\n"
"\n"
"## The Key Idea: Diagonalization (But Carefully!)\n"
"\n"
"We need to extract a **single sequence of rationals** from this infinite double array. This is reminiscent of Cantor's famous **diagonalization** arguments.\n"
"\n"
"### Naive Attempt: The Diagonal\n"
"\n"
"Why not just take the diagonal sequence `(q₀₀, q₁₁, q₂₂, q₃₃, ...)`?\n"
"\n"
"**Problem:** Each row converges at its **own rate**!\n"
"- Row `k` might need to reach index `1000k` before getting within `ε` of its limit\n"
"- Row `k+1` might need to reach index `k²` before converging\n"
"- The diagonal only samples row `k` at position `k`, which could be way too early!\n"
"\n"
"The diagonal doesn't respect the different convergence rates of each row.\n"
"\n"
"### The Solution: Choose Convergence Points Wisely\n"
"\n"
"**Strategy:** For each row `k`, pick an index `N(k)` where row `k` has \"converged well enough.\" Then define:\n"
"\n"
"`y k = q k (N k)`\n"
"\n"
"This way, we sample each row at a point where it's already close to its limit.\n"
"\n"
"**How to choose `N(k)`?**\n"
"\n"
"Use the fact that `xₖ = Real_of_CauSeq (hq k)`, so row `k` converges to `xₖ`. For any tolerance—say `1/(k+1)` to keep things strictly positive—there exists an index `N(k)` such that:\n"
"\n"
"`∀ m ≥ N(k), |q k m - xₖ| < 1/(k+1)`\n"
"\n"
"**That's our `N(k)`!**\n"
"\n"
"---\n"
"\n"
"## Your Mission\n"
"\n"
"Construct the sequence `y`, prove it's Cauchy, and prove that the sequence of reals `x` converges to `Real_of_CauSeq hy`.\n"
"\n"
"This will require:\n"
"1. **Choosing the convergence points:** Use `SeqLim_of_Real_of_Cau (hq n)` with tolerance `1/(n+1)` to get `N(n)` for each row\n"
"2. **Proving `y` is Cauchy:** Use a triangle inequality argument splitting `|yₘ - yₙ|` into three manageable pieces\n"
"3. **Proving convergence:** Show `|xₙ - Real_of_CauSeq hy|` gets arbitrarily small\n"
"\n"
"The proof involves careful bookkeeping with multiple `N` values (from the Cauchy property of `x`, from the Archimedean property, and from the convergence of `y`), all orchestrated via triangle inequalities and the `linarith` tactic.\n"
"\n"
"Good luck! This is the capstone result that shows the reals are truly complete."
msgstr ""

#: Game.Levels.L22Levels.L03
msgid "# Level 3: Integration!\n"
"\n"
"Welcome to the grand finale of our uniformity journey! After mastering function composition and uniform convergence, we're ready to tackle one of calculus's crown jewels: **integration**. But this isn't your typical calculus course—we're going to build integration from the ground up using the rigorous foundations you've been developing.\n"
"\n"
"## From Continuous Functions to Areas\n"
"\n"
"You've spent this lecture understanding how functions behave under various kinds of limits. Now we're going to use sequences in a completely different way: to define what it means to find the area under a curve.\n"
"\n"
"The beautiful connection? Integration is fundamentally about taking a limit of approximations—and everything you've learned about when limits preserve nice properties will be crucial here.\n"
"\n"
"## The Riemann Revolution\n"
"\n"
"In the 1850s, Bernhard Riemann formalized what we intuitively think of as \"area under a curve.\" His insight was brilliant: approximate the area using rectangles, make the rectangles thinner and thinner, and take the limit.\n"
"\n"
"But here's the key question: **does this limit always exist?** And when it does exist, **is it unique?**\n"
"\n"
"These questions connect directly to everything you've been learning about convergence!\n"
"\n"
"## Our Approach: Right Endpoints\n"
"\n"
"We'll use **Riemann sums with right endpoints**:\n"
"\n"
"`RiemannSum (f : ℝ → ℝ) (a b : ℝ) (N : ℕ) : ℝ :=\n"
"  (b - a) / N * ∑ i ∈ range N, f (a + (i + 1) * (b - a) / N)`\n"
"\n"
"**Translation**: We divide $[a,b]$ into $N$ equal pieces of width $(b-a)/N$. For each piece, we make a rectangle whose height is the function value at the **right endpoint** of that piece. The Riemann sum is the total area of all these rectangles.\n"
"\n"
"## The Fundamental Definitions\n"
"\n"
"**HasIntegral**: A function has integral $I$ if the sequence of Riemann sums converges to $I$:\n"
"\n"
"`HasIntegral (f : ℝ → ℝ) (a b : ℝ) (I : ℝ) : Prop :=\n"
"  SeqLim (fun N ↦ RiemannSum f a b N) I`\n"
"\n"
"**IntegrableOn**: A function is integrable on $[a,b]$ if *some* integral exists:\n"
"\n"
"`IntegrableOn (f : ℝ → ℝ) (a b : ℝ) : Prop :=\n"
"  ∃ I, SeqLim (fun N ↦ RiemannSum f a b N) I`\n"
"\n"
"Notice the beautiful parallel to our earlier work: we're asking when a sequence (of Riemann sums) has a limit!\n"
"\n"
"## Your Mission: Compute $\\int_a^b x \\, dx$\n"
"\n"
"You're going to prove that $f(x) = x$ is integrable on $[a,b]$, and find the exact value of its integral. From calculus, you expect this to be $\\frac{b^2 - a^2}{2}$, but now you'll **prove** it rigorously using the definition.\n"
"\n"
"## The Summation Toolkit\n"
"\n"
"To work with Riemann sums, you'll need several key identities about finite sums:\n"
"\n"
"- `sum_add_distrib`: $\\sum_{i \\in s} (f(i) + g(i)) = \\sum_{i \\in s} f(i) + \\sum_{i \\in s} g(i)$\n"
"- `sum_const`: $\\sum_{i \\in s} c = c \\cdot |s|$\n"
"- `card_range`: $|\\{0, 1, \\ldots, n-1\\}| = n$\n"
"- `sum_div`: $\\sum_{i \\in s} (f(i) / c) = (\\sum_{i \\in s} f(i)) / c$\n"
"- `sum_mul`: $\\sum_{i \\in s} (f(i) \\cdot c) = (\\sum_{i \\in s} f(i)) \\cdot c$\n"
"\n"
"And the crucial identity you'll need:\n"
"- `sum_range_add_one`: $\\sum_{i=0}^{n-1} (i + 1) = \\frac{n(n+1)}{2}$\n"
"\n"
"## The Strategy: Exact Computation\n"
"\n"
"Unlike our previous proofs where we estimated errors, here you'll compute the Riemann sums **exactly**. You'll show that:\n"
"\n"
"$$\\text{RiemannSum}(f, a, b, n) = \\frac{b^2 - a^2}{2} + \\frac{(b-a)^2}{2n}$$\n"
"\n"
"As $n \\to \\infty$, the error term $\\frac{(b-a)^2}{2n}$ vanishes, giving you the integral $\\frac{b^2 - a^2}{2}$.\n"
"\n"
"## The Connection to Earlier Work\n"
"\n"
"This integration problem brings together everything you've learned:\n"
"- **Sequence limits**: The integral is defined as a limit\n"
"- **Careful estimation**: You need to show the error term approaches zero\n"
"- **Algebraic precision**: The summation identities must be applied carefully\n"
"- **Archimedean property**: To show you can make the error arbitrarily small\n"
"\n"
"## Why This Matters\n"
"\n"
"You're not just computing one integral—you're seeing how the entire theory of integration is built on the foundation of limits. Every time you integrate a function in calculus, you're implicitly using this limiting process.\n"
"\n"
"Moreover, the question of **when** functions are integrable connects deeply to continuity, and ultimately to the uniform convergence concepts you've mastered.\n"
"\n"
"## A Historical Note\n"
"\n"
"In 1675, Leibniz conceived of integration as the sum of infinitely many infinitesimally thin rectangles. His insight was profound, but his methods lacked the rigorous foundation we need today. In the 1850s, Riemann formalized Leibniz's intuitive idea using the theory of limits, giving us the precise definition we now use.\n"
"Before Riemann, integration was largely based on \"obvious\" geometric intuition—but Riemann showed how to make the notion of \"area\" precise using limits.\n"
"\n"
"Your proof will follow in Riemann's footsteps, showing that even something as \"simple\" as $\\int x \\, dx$ requires careful analysis when done rigorously.\n"
"\n"
"## Your Challenge\n"
"\n"
"Prove that $f(x) = x$ is integrable on $[a,b]$ for $a < b$:\n"
"\n"
"**Lean signature**: `IntegrableOn (fun x ↦ x) a b`\n"
"\n"
"Ready to compute your first rigorous integral? The Riemann sums are waiting, and the arithmetic (while intricate) will lead you to a beautiful conclusion!\n"
"\n"
"*Hint*: Use $(b^2-a^2)/2$ as your proposed integral value, and be prepared for some satisfying algebraic manipulations! 📐"
msgstr ""

#: Game.Levels.L4Lecture
#: Game.Levels.L7Lecture
#: Game.Levels.L9Lecture
msgid "# More on sequences"
msgstr ""

#: Game.Levels.L6Levels.L03_DotNotation
msgid "# 🔍 Information Extraction Mastered! 🔍\n"
"\n"
"Perfect! You've just learned one of the most practical and time-saving techniques in Lean. Dot notation might seem like a small detail, but it's the kind of efficiency that makes complex proofs much more readable and manageable.\n"
"\n"
"**Why This Matters:**\n"
"As mathematical statements become more complex, they often involve multiple conditions or properties. Being able to quickly extract the specific piece of information you need is essential for maintaining clarity in your proofs.\n"
"\n"
"**The Power of Precision:**\n"
"Notice how `h.2` gave us exactly what we needed—no more, no less. This precision is crucial in mathematics, where we want to use exactly the right tool for each step of our argument.\n"
"\n"
"**Looking Forward:**\n"
"As we dive deeper into analysis, you'll encounter hypotheses with multiple convergence conditions, boundedness properties, and continuity requirements all bundled together. Dot notation will be your key to navigating these rich mathematical structures efficiently.\n"
"\n"
"Elegant mathematics isn't just about reaching the right conclusion—it's about getting there with style and clarity. You're building that elegance, one notation at a time."
msgstr ""

#: Game.Levels.L17Pset.L05
msgid "# Level 1: Monotonicity of Series\n"
"\n"
"Prove `Monotone_of_NonNegSeries`:\n"
"If `0 ≤ a n`, then `Series a` is Monotone."
msgstr ""

#: Game.Levels.L13Lecture
msgid "# Lecture 13: Monotone Subsequence"
msgstr ""

#: Game.Levels.L22Levels.L01
msgid "# Level 1 Conclusion: The Power of Chaining Estimates\n"
"\n"
"Congratulations! You've just completed one of the most elegant proofs in real analysis. Let's take a moment to appreciate what you've accomplished and what it teaches us about mathematical reasoning.\n"
"\n"
"## What You Just Proved\n"
"\n"
"You proved that **composition preserves continuity**—a fundamental building block that underlies much of calculus and analysis. Every time you differentiate $\\sin(x^2)$ or integrate $e^{\\sqrt{x}}$, you're relying on this theorem.\n"
"\n"
"## The Beauty of the Method\n"
"\n"
"Notice how the proof worked through a beautiful chain of estimates:\n"
"- We **decomposed** the problem: instead of directly controlling $|f(g(x)) - f(g(c))|$, we introduced an intermediate step\n"
"- We **chained** two separate continuity arguments: first $g$'s continuity, then $f$'s continuity\n"
"- We **controlled** the error propagation by carefully choosing our intermediate tolerance $\\varepsilon_1$\n"
"\n"
"This \"intermediate variable\" technique is a fundamental proof strategy that appears throughout analysis.\n"
"\n"
"## The Deeper Lesson\n"
"\n"
"Compare this success to the failure we saw with pointwise convergence in the introduction. Why does composition work so cleanly while pointwise limits of continuous functions can be discontinuous?\n"
"\n"
"**The key difference**: In function composition, we have **uniform control** over both levels of approximation. When we use $g$'s continuity to get $|g(x) - g(c)| < \\varepsilon_1$, this bound works the same way regardless of which specific values $x$ and $c$ take. There's no \"rate of convergence\" that varies from point to point.\n"
"\n"
"This is a preview of why **uniform convergence** (coming next!) is so much more powerful than pointwise convergence.\n"
"\n"
"## Looking Ahead: The Plot Thickens\n"
"\n"
"You might be thinking: \"That was straightforward! Continuous functions behave nicely after all.\"\n"
"\n"
"Well, not so fast. In the next level, you'll see that even though individual continuous functions compose nicely, **sequences** of continuous functions can behave in surprising ways. The very fact that we needed to introduce \"uniform convergence\" as a concept hints that pointwise convergence—which seems natural—is somehow insufficient.\n"
"\n"
"## A Technical Note\n"
"\n"
"In your proof, you likely used the `choose` tactic to extract the $\\varepsilon_1$ and $\\delta$ values from the continuity hypotheses. This is exactly the right approach! The `choose` tactic is perfect for extracting witnesses from existential statements, and continuity definitions are full of such statements.\n"
"\n"
"## Mathematical Maturity Milestone\n"
"\n"
"By completing this proof, you've demonstrated several key aspects of mathematical maturity:\n"
"- **Strategic thinking**: You planned a multi-step proof approach\n"
"- **Technical precision**: You managed multiple quantifiers and logical dependencies\n"
"- **Conceptual understanding**: You see how continuity at one level enables continuity at another level\n"
"\n"
"## Final Thought\n"
"\n"
"Function composition works because continuous functions \"play nicely\" with each other in a very precise sense. This harmony doesn't always extend to infinite processes, as we'll see. But when it does work, as here, the mathematics has an almost musical quality—each step flowing naturally into the next.\n"
"\n"
"Ready for the next challenge? The uniform convergence theorem awaits, and it's going to test everything you've learned about the delicate relationship between limits and continuity.\n"
"\n"
"Well done! 🎯"
msgstr ""

#: Game.Levels.L1RealAnalysisStory.L07_specialize
msgid "The `specialize` tactic applies a universal statement in a hypothesis to a specific value."
msgstr ""

#: Game.Levels.L6Levels.L01_SplitAnds
#: Game.Levels.L6Levels.L02_LeftRight
#: Game.Levels.L6Levels.L03_DotNotation
#: Game.Levels.L6Levels.L04_Cases'
#: Game.Levels.L6Levels.L05_AbsLt
#: Game.Levels.L6Levels.L06_Squeeze
#: Game.Levels.L7Levels.L01_Eventually
#: Game.Levels.L7Levels.L02_SeqOfAbs
#: Game.Levels.L7Levels.L03_SeqInvLim
#: Game.Levels.L8Levels.L03_Induction'
#: Game.Levels.L9Levels.L04_FiniteSums
#: Game.Levels.L9Levels.L05_BddOfConv
#: Game.Levels.L10Levels.L06_Prod
#: Game.Levels.L10Levels.L07_Order
#: Game.Levels.L10Levels.L08_Mono
#: Game.Levels.L10Levels.L09_Subseq
#: Game.Levels.L10Pset.L10Pset2
#: Game.Levels.L10Pset.L10Pset3
#: Game.Levels.L10Pset.L10Pset4
#: Game.Levels.L10Pset.L10Pset5
#: Game.Levels.L10Pset.L10Pset6
#: Game.Levels.L10Pset.L10Pset7
#: Game.Levels.L11Levels.L01_IsCauchyOfLim
#: Game.Levels.L11Levels.L02_IsCauchyOfSum
#: Game.Levels.L11Levels.L03_IsBddOfCauchy
#: Game.Levels.L11Pset.L11Pset1
#: Game.Levels.L12Levels.L00_SubseqIterate
#: Game.Levels.L12Levels.L01_Choose
#: Game.Levels.L12Levels.L01_MonotoneBdd
#: Game.Levels.L12Pset.L12Pset2
#: Game.Levels.L13Levels.L03_MonotoneSubseq
#: Game.Levels.L14Levels.L01_BolzanoWeierstrass
#: Game.Levels.L15Pset.L15Pset1
#: Game.Levels.L16Pset.L16Pset1
#: Game.Levels.L16Pset.L16Pset2
#: Game.Levels.L16Pset.L16Pset3
#: Game.Levels.L20Pset.L01
#: Game.Levels.L20Pset.L02
#: Game.Levels.L22Pset.L01
#: Game.Levels.L22Pset.L02
#: Game.Levels.L22Pset.L03
#: Game.Levels.L22Pset.L04
#: Game.Levels.L24Pset.L01
msgid "Prove this"
msgstr ""

#: Game.Levels.L20Lecture
msgid "# Lecture 20: Function Limits\n"
"\n"
"**SIMPLICIO:** FUNCTIONS!!!\n"
"\n"
"**SOCRATES:** Oh please don't shout, I'm standing right here.\n"
"\n"
"**SIMPLICIO:** Sorry! I just got a little over excited that we're moving on to functions.\n"
"Please tell me about them!\n"
"\n"
"**SOCRATES:** Ah, right. Very good. Let's start at the beginning. What's the first thing you\n"
"learn in Calculus?\n"
"\n"
"**SIMPLICIO:** Hmmm. The derivative?\n"
"\n"
"**SOCRATES:** Ok, we can see about starting there. Tell me, what does it mean to\n"
"compute the derivative of a function $f : \\R \\to \\R$ at some point $x = c$.\n"
"\n"
"**SIMPLICIO:** Well, it's the slope of the tangent line.\n"
"\n"
"**SOCRATES:** Yes, of course; I mean, what expression are you trying to evaluate?\n"
"\n"
"**SIMPLICIO:** Oh! I remember: it's the limit as $h \\to 0$ of\n"
"$(f(x+h)-f(x)) / h$.\n"
"\n"
"**SOCRATES:** Which word there is problematic?\n"
"\n"
"**SIMPLICIO:** Ah, of course; \"limit\"! We don't know yet what limits are for functions. And I already know from experience that\n"
"you can't just stick in $h=0$, since both the numerator and denominator vanish.\n"
"\n"
"**SOCRATES:** Right. So we need to figure out what it means for a limit of a *function* to exist. Let's think about this carefully. What do we want to be true when we write $\\lim_{x \\to c} f(x) = L$?\n"
"\n"
"**SIMPLICIO:** Well, we want $f(x)$ to get close to $L$ when $x$ gets close to $c$.\n"
"\n"
"**SOCRATES:** Exactly! Now, do you remember our Engineer and Machinist from when we discussed sequence limits?\n"
"\n"
"**SIMPLICIO:** Yes! The Engineer specified a tolerance $\\varepsilon > 0$ for how close the output needed to be, and the Machinist replied with how many steps $N$ were needed to guarantee that tolerance.\n"
"\n"
"**SOCRATES:** Perfect! Now with functions, there's a beautiful twist. The Engineer still specifies a tolerance $\\varepsilon > 0$ for the output—that is, we want $|f(x) - L| < \\varepsilon$. But what do you think the Machinist's response should be this time?\n"
"\n"
"**SIMPLICIO:** Hmm. With sequences, the Machinist said \"run the process for at least $N$ steps.\" But with functions, we don't have \"steps\"... we have values of $x$.\n"
"\n"
"**SOCRATES:** Precisely! So instead of saying \"wait $N$ steps,\" how should the Machinist respond?\n"
"\n"
"**SIMPLICIO:** Oh! So the Machinist needs to give a tolerance on the *input* side, not a number of steps. So he needs to say something like: \"make sure your input $x$ is within distance $\\delta$ of the target point $c$\"?\n"
"\n"
"\n"
"**SOCRATES:** Exactly! The conversation goes like this:\n"
"\n"
"- **Engineer:** \"I need $f(x)$ to be within $\\varepsilon$ of $L$.\"\n"
"- **Machinist:** \"No problem! Just make sure your input $x$ is within distance $\\delta$ of $c$, and I'll guarantee your output tolerance.\"\n"
"\n"
"And just like with sequences, we say the limit exists if this conversation can continue for *any* tolerance $\\varepsilon > 0$ the Engineer demands—the Machinist can always respond with some appropriate $\\delta > 0$.\n"
"\n"
"**SIMPLICIO:** So the definition would be: for every $\\varepsilon > 0$, there exists a $\\delta > 0$ such that if $|x - c| < \\delta$, then $|f(x) - L| < \\varepsilon$?\n"
"\n"
"**SOCRATES:** Beautifully stated! Yes, that's *almost* it. Let's write out what you said formally:\n"
"\n"
"$$\\lim_{x \\to c} f(x) = L \\text{ means: } \\forall \\varepsilon > 0, \\exists \\delta > 0, \\forall x, |x - c| < \\delta \\Rightarrow |f(x) - L| < \\varepsilon$$\n"
"\n"
"This is called an $\\varepsilon$-$\\delta$ definition. There's only one problem with this definition.\n"
"\n"
"**SIMPLICIO:** Hmm. I really don't see, what's wrong?\n"
"\n"
"**SOCRATES:** Well, think again back to informal calculus. What does it mean for a function\n"
"$f : \\R \\to \\R$\n"
" to be\n"
"*continuous* at $x=c$.\n"
"\n"
"**SIMPLICIO:** Ok, that's when $\\lim_{x \\to c}f(x)$ exists, and is actually equal to the value of\n"
"$f(c)$.\n"
"\n"
"**SOCRATES:** Yes, exactly! Remember when we spoke of derivatives, we don't want to evaluate\n"
"the limit when $h$ is literally equal to zero, where we get $0 / 0$. But look\n"
"again at your definition. Where do you ensure that?\n"
"\n"
"**SIMPLICIO:** Oh, I see! So we have to update the definition of a limit\n"
"to make sure that we don't actually allow $x = c$. So does this work?\n"
"\n"
"$$\\lim_{x \\to c} f(x) = L \\text{ means: } \\forall \\varepsilon > 0, \\exists \\delta > 0, \\forall x \\ne c, |x - c| < \\delta \\Rightarrow |f(x) - L| < \\varepsilon$$\n"
"\n"
"**SOCRATES:** That's the ticket! Some people write $0 < |x - c| < \\delta$, but I think\n"
"it'll be easier to just record $x \\ne c$ separately.\n"
"The set of such $x$ is called a *punctured neighborhood* of $c$—we've removed the center point. This way, the limit only cares about the behavior of $f$ *near* $c$, not *at* $c$.\n"
"\n"
"**SIMPLICIO:** So this means $f(c)$ doesn't even need to be defined for the limit to exist?\n"
"\n"
"**SOCRATES:** Correct! Remember when you started learning calculus and had to do things like find the limit of $f(x) = \\frac{x^2 - 1}{x - 1}$ as $x$ goes to $1$?\n"
"\n"
"\n"
"**SIMPLICIO:** Yes! This function is undefined at $x = 1$ (actually in Lean, as I've learned, it's perfectly well defined, since $0/0 = 0$ -- which means that it's certainly *not* continuous there...). But for $x \\neq 1$, we can factor: $f(x) = \\frac{(x-1)(x+1)}{x-1} = x + 1$. So $\\lim_{x \\to 1} f(x) = 2$, even though $f(1)$ doesn't exist!\n"
"\n"
"And this is exactly like the derivative situation. The difference quotient $\\frac{f(x+h) - f(x)}{h}$ is undefined at $h = 0$, but we can still take the limit as $h \\to 0$.\n"
"\n"
"**SOCRATES:** Precisely! You've understood the key point. The limit tells us about the *tendency* of a function as we approach a point, not necessarily what happens *at* that point.\n"
"\n"
"**SIMPLICIO:** So to summarize:\n"
"- For limits, we assume $|x - c| < \\delta$ **and**  $x \\ne 0$ (punctured neighborhood)\n"
"- For continuity, we only need $|x - c| < \\delta$; this is equivalent to:\n"
"the limit exists AND equals $f(c)$.\n"
"\n"
"**SOCRATES:** You've got it! Let's go."
msgstr ""

#: Game.Levels.L18Pset.L02
msgid "Prove `Series_abs_add`"
msgstr ""

#: Game.Levels.L7Levels.L00_Uniqueness
msgid "# Level 1: Uniqueness of Limits\n"
"\n"
"One of the fundamental properties of convergent sequences is that they converge to a\n"
"**unique** limit. This might seem obvious at first glance—after all, how could a sequence\n"
"be getting arbitrarily close to two different numbers? But as with many intuitive facts\n"
"in analysis, the rigorous proof requires careful reasoning with our epsilon-N definitions.\n"
"\n"
"The key to proving uniqueness is **proof by contradiction**. We'll assume a sequence\n"
"converges to two different limits `L` and `M`, and show this leads to an impossibility.\n"
"The strategy involves choosing epsilon to be half the distance between `L` and `M`, then\n"
"showing the sequence can't simultaneously stay that close to both limits.\n"
"\n"
"## New Tools You'll Need\n"
"\n"
"### Proof by Contradiction: `by_contra`\n"
"\n"
"The `by_contra` tactic allows us to prove a statement by assuming its negation and deriving\n"
"a contradiction. The syntax is `by_contra h`, which adds a hypothesis `h` containing the\n"
"negation of the current goal and changes the goal to `False`.\n"
"\n"
"### `abs_pos_of_nonzero`\n"
"\n"
"If `x ≠ 0`, then `0 < |x|`. This theorem is essential for working with distances between\n"
"distinct points.\n"
"\n"
"## The Strategy\n"
"\n"
"Here's how the proof works:\n"
"\n"
"1. Assume for contradiction that `L ≠ M`\n"
"2. Then `|L - M| > 0`, so we can use `ε := |L - M| / 2` as our tolerance\n"
"3. Apply the convergence condition to get `N₁` and `N₂` for sequences converging to `L` and `M`\n"
"4. Take `N = N₁ + N₂` and evaluate at `n = N`\n"
"5. Use the triangle inequality to show `|L - M| ≤ |a N - L| + |a N - M| < ε + ε = |L - M|`\n"
"6. This gives the contradiction: `|L - M| < |L - M|`\n"
"\n"
"The algebra in step 5 is the key: we write `L - M = (L - a(N)) + (a(N) - M)` and apply\n"
"the triangle inequality to get the impossible conclusion."
msgstr ""

#: Game.Levels.L2NewtonsCalculationOfPi
msgid "# The Mathematical Revolution of 1666\n"
"\n"
"**SIMPLICIO:** I heard that Newton had a really cool way of calculating π. Can you tell me about it?\n"
"\n"
"**SOCRATES:** Certainly. It begins around 1665-1666, when Newton was turning 23 years old. Anything significant about that year?\n"
"\n"
"**SIMPLICIO:** Isn't that Newton's  \"annus mirabilis\",  year of miracles? If I recall correctly, he was forced to leave Cambridge due to an outbreak of  the Great Plague, and made his most groundbreaking discoveries (calculus, optics, gravitation, etc) while quarantining in isolation at his family home in Woolsthorpe.\n"
"\n"
"**SOCRATES:** Exactly right. And one of the first things he discovered in that year was a  new version of\n"
"the Binomial Theorem. Tell me, please,  what can one say about\n"
"$(1 + x) ^ n$?\n"
"\n"
"**SIMPLICIO:** Sure thing, if you multiply $(1+x)^n$ all out, you get\n"
"$ \\binom{n}{0} + \\binom{n}{1}x + \\binom{n}{2}x^2 + \\cdots + \\binom{n}{n}x^n$. Here $\\binom{n}{k}$ is the \"binomial coefficient\", the number of ways of choosing $k$ things from a bag of $n$ things. Explicitly, $\\binom{n}{k} = \\frac{n!}{k! (n-k)!}$. These are just the numbers in Pascal’s Triangle, and you can easily read off the $n$-th row.\n"
"[![Pascal's Triangle](images/Yanghui_triangle.jpg)](https://en.wikipedia.org/wiki/Pascal%27s_triangle)\n"
"\n"
"\n"
"**SOCRATES:** Excellent! And do you know sigma notation?\n"
"\n"
"**SIMPLICIO:** I think so. I could’ve written  that same thing as $\\sum_{k=0}^{n} \\binom{n}{k} x^k$. In general, if you have some function $f: \\mathbb{N} \\to \\mathbb{R}$, and you want express $f(a)+f(a+1)+…+f(b)$, that is, the sum of $f(k)$ as $k$ ranges from some integer $a$ up to some other integer $b$, you can write it as $\\sum_{k=a}^{b} f(k)$.\n"
"\n"
"**SOCRATES:** Very good.  So we have $(1+x)^n = \\sum_{k=0}^{n} \\binom{n}{k} x^k$. Now, would you allow me to write this as a sum going all the way out to infinity?\n"
"$(1+x)^n = \\sum_{k=0}^{\\infty} \\binom{n}{k} x^k$\n"
"\n"
"**SIMPLICIO:** Hmm. Ok, I think I see what you’re getting at: Pascal’s Triangle has implied zeros everywhere outside, so $\\binom{n}{k}$ is just zero once $k>n$. So you’ve written it as an infinite sum, even though it secretly terminates after finitely many terms. But what purpose does extending it serve?\n"
"\n"
"**SOCRATES:** Well, let me ask you this: can you think of any way of making sense of this formula when $n=-1$?\n"
"\n"
"**SIMPLICIO:** Huh? You can’t use binomial coefficients. How do you choose 3 things from -1 things, that makes no sense!\n"
"\n"
"**SOCRATES:** Ok, sure, but so many great discoveries in mathematics occur when you realize a way to **break the rules**, and follow some pattern **past** its intended... limit (no pun intended…). Put yourself in Newton’s shoes, if you can; what might a genius like him come up with?\n"
"\n"
"**SIMPLICIO:** Well, we do have this other formula for binomial coefficients, not in terms of combinatorics, but just as factorials, $\\binom{n}{k} = \\frac{n!}{k! (n-k)!}$. That still doesn’t help because what the heck is $(-1)!$ supposed to be?! Oh, but wait! We can also write this as:\n"
"\n"
" $\\binom{n}{k} = \\frac{n(n-1)(n-2)\\cdots(n-k+1)}{k!}$\n"
"\n"
"And in this way, we “bypass” the issue of dealing with $(-1)!$, and just go straight to “normal” numbers.\n"
"\n"
"**SOCRATES:** Can you please write this using product notation?\n"
"\n"
"**SIMPLICIO:** Sure, it's just like summation notation but with a $\\Pi$:\n"
"\n"
" $\\binom{n}{k} = \\frac{1}{k!}\\prod_{\\ell=1}^{k}(n-\\ell)$.\n"
"\n"
"**SOCRATES:** Whoops, are you sure about those bounds in the product?\n"
"\n"
"**SIMPLICIO:** Argh! It's so easy to make a silly mistake.\n"
"After writing down the formula, I should have\n"
"checked that I got the right start and end values;\n"
"the counter $\\ell$ should go from $0$ to $k-1$, not from $1$ to $k$.  Is this better?\n"
"\n"
"$\\binom{n}{k} = \\frac{1}{k!}\\prod_{\\ell=0}^{k-1}(n-\\ell)$.\n"
"\n"
"**SOCRATES:** Perfect. Go on.\n"
"\n"
"**SIMPLICIO:** Ok, so if we agree to follow this pattern, then we get:\n"
"\n"
"- $\\binom{-1}{0} = 1$, which makes sense because any row of Pascal's triangle starts with at $1=\\binom{c}{0}$; then\n"
"\n"
"- $\\binom{-1}{1} = (-1)/1! = -1$, which also makes sense because the next term in the \"$c$th row\" of Pascal's triangle is always\n"
"$\\binom{c}{1} = c$; then we get:\n"
"\n"
"- $\\binom{-1}{2} = (-1)(-2)/2! = +1$,\n"
"\n"
"- $\\binom{-1}{3} = (-1)(-2)(-3)/3!=-1$.\n"
"\n"
"Ok so I see the pattern:\n"
"it just alternates between $+1$ and $-1$, so the series goes:\n"
"\n"
" $(1+x)^{-1} = 1 - x + x^2 - x^3+x^4-x^5+\\cdots$.\n"
"\n"
"**SOCRATES:** Very good! But does this formula make any actual\n"
"*sense*? How might you test it?\n"
"\n"
"**SIMPLICIO:** Ok, if that series is supposed to \"represent\"\n"
"$1/(1+x)$, then if I multiply the whole thing by\n"
"$(1+x)$, I should just get $1$. Let's try it:\n"
"\n"
"$(1+x)(1 - x + x^2 - x^3+x^4-x^5+\\cdots) = ?$\n"
"\n"
"I'll first multiply everything by $1$, then by $x$, and add them all up.\n"
"\n"
"$(1 - x + x^2 - x^3+x^4-x^5+\\cdots) + (x - x^2 + x^3- x^4+x^5\\cdots)$\n"
"\n"
"Ok, so if I rearrange terms, then everything cancels out, and only the leading $1$ remains. Great!\n"
"\n"
"**SOCRATES:** Interesting. And are you \"allowed\" to rearrange terms like that?\n"
"\n"
"**SIMPLICIO:** Well.... why not?\n"
"\n"
"**SOCRATES:** Ok, nevermind that for now,\n"
"you seem to be satisfied that it makes sense to say\n"
"that the series\n"
"$1 - x + x^2 - x^3+x^4-x^5+\\cdots$ \"converges\" (again, whatever that means) to $(1+x)^{-1}$.\n"
"\n"
"**SIMPLICIO:** Come to think of it, I knew this already;\n"
"it's just the geometric series! I know that\n"
"\n"
"$1+\\lambda + \\lambda^2+\\lambda^3+\\cdots$\n"
"\n"
"adds up to $1/(1-\\lambda)$, and the series we have just replaces $\\lambda$ with $-x$.\n"
"\n"
"**SOCRATES:** Yes, very good.\n"
"And where might this \"belong\" in Pascal’s triangle?\n"
"\n"
"**SIMPLICIO:**\n"
"Holy cow! Did we just discover an extension of the triangle, going “up”?!\n"
"[![Pascal's Triangle, Extended](images/PascalM1.jpg)](https://en.wikipedia.org/wiki/Pascal%27s_triangle)\n"
"\n"
"**SOCRATES:**\n"
"Indeed, and we can in fact continue this pattern for $n=-2,\n"
"-3, -4,$ and so on. I'll let you work it out yourself, but we actually\n"
"get a *whole other* Pascal's triangle (with some negative signs) *above* the standard one!\n"
"[![Pascal's Triangle, Extended](images/PascalMn.jpg)](https://en.wikipedia.org/wiki/Pascal%27s_triangle)\n"
"See how it still follows the usual rule, that the two numbers above and to the left or right add to the value just below them?\n"
"\n"
"But let's try something even more exotic. Can you make\n"
"the Binomial Theorem work when $n=1/2$?\n"
"\n"
"\n"
"**SIMPLICIO:** Whoa, $n = 1/2$? That's... really pushing it! But let me try using the same formula. So $\\binom{1/2}{k} = \\frac{1}{k!}\\prod_{\\ell=0}^{k-1}(1/2-\\ell)$. Let me work out the first few terms:\n"
"\n"
"- $\\binom{1/2}{0} = 1$ (as always)\n"
"\n"
"- $\\binom{1/2}{1} = (1/2)/1! = 1/2$ (again, matches the pattern we already knew)\n"
"\n"
"- $\\binom{1/2}{2} = (1/2)(-1/2)/2! = -1/8$\n"
"\n"
"- $\\binom{1/2}{3} = (1/2)(-1/2)(-3/2)/3! = 1/16$\n"
"\n"
"- $\\binom{1/2}{4} = \\frac{(1/2)(-1/2)(-3/2)(-5/2)}{4!} =  -\\frac{5}{128}$\n"
"\n"
"So $(1+x)^{1/2} = 1 + \\frac{1}{2}x - \\frac{1}{8}x^2 + \\frac{1}{16}x^3 -\n"
"\\frac{5}{128}x^4+\\cdots$\n"
"\n"
"But wait -- this is supposed to be $\\sqrt{1+x}$?!\n"
"\n"
"**SOCRATES:** Again, go into Newton's thinking: how might he go about justifying whether this formula makes any sense?\n"
"\n"
"**SIMPLICIO:** Oh, ok, I think I see! If we square the formula and multiply everything out, I guess we're supposed to get $1+x$ -- that would justify calling the series $\\sqrt{1+x}$.\n"
"\n"
"**SOCRATES:** Go for it!\n"
"\n"
"**SIMPLICIO:** Ok, so I want\n"
"\n"
"$\\left(1 + \\frac{1}{2}x - \\frac{1}{8}x^2 + \\frac{1}{16}x^3 -\n"
"\\frac{5}{128}x^4+\\cdots\\right)^2$\n"
"\n"
"That means squaring every term, and also adding twice every product of distinct pairs of terms.\n"
"\n"
"**SOCRATES:** Right. Can you think of a good way of keeping track of everything?\n"
"\n"
"**SIMPLICIO:** Oh, I know! Let's group things by the power of $x$ involved. The first one is easy: $x^0=1$, which you only get from squaring the first term. So that coefficient is $1$.\n"
"\n"
"For the coefficient of $x^1$, I can't square anything involving $x$'s, so I\n"
"can only multiply the $x$ term by the constant term, and of course double it.\n"
"That's just $2 \\times 1 \\times \\frac{1}{2}x = x$. So the coefficient of $x$ is $1$.\n"
"\n"
"For $x^2$, I get two contributions  from constant times quadratic: $2 \\times 1 \\times \\left(-\\frac{1}{8}x^2\\right) = -\\frac{1}{4}x^2$ and also from the square of the linear term: $\\left(\\frac{1}{2}x\\right)^2 = \\frac{1}{4}x^2$. So the total coefficient is $-\\frac{1}{4} + \\frac{1}{4} = 0$.\n"
"\n"
"Let's try a few more. To get $x^3$, I need:\n"
"- $2 \\times 1 \\times \\frac{1}{16}x^3 = \\frac{1}{8}x^3$ (constant times the $x^3$ term)\n"
"- $2 \\times \\frac{1}{2}x \\times \\left(-\\frac{1}{8}x^2\\right) = -\\frac{1}{8}x^3$ (the $x$ term times the $x^2$ term)\n"
"\n"
"So the total coefficient of $x^3$ is $\\frac{1}{8} - \\frac{1}{8} = 0$.\n"
"\n"
"This is amazing! It really seems like all the higher-order terms are canceling out perfectly. I bet that will keep happening, and we'll just get the square to come out to exactly $1+x$; the formula really works!\n"
"\n"
"So wait, now we get a whole other row in Pascal's triangle, *between* rows $0$ and $1$?!\n"
"\n"
"[![Pascal's Triangle](images/PascalM12.jpg)](https://en.wikipedia.org/wiki/Pascal%27s_triangle)\n"
"\n"
"**SOCRATES:** Beautiful, isn't it!\n"
"\n"
"**SIMPLICIO:** Wait, this is all much simpler than I'm making it. Isn't this just the same thing as the Taylor expansion about $x=0$ of the function $f(x)=\\sqrt{1+x}$?\n"
"I already know how to do this from Calculus.\n"
"\n"
"**SOCRATES:** Yes, very good; but Brook Taylor (of Taylor series) did not prove his general theorem until 1715, a few decades after\n"
"Newton's computation of $\\pi$.\n"
"\n"
"Now, suppose you wanted to compute something like $\\sqrt 3$ -- can you think of a way of doing it using this formula?\n"
"\n"
"**SIMPLICIO:** Hmm the function is $\\sqrt {1+x}$, so I guess I want to set $x=2$. Then I get:\n"
"\n"
"$\\sqrt {1+2} = 1 + \\frac{1}{2}(2) - \\frac{1}{8}(2)^2 + \\frac{1}{16}(2)^3 -\n"
"\\frac{5}{128}(2)^4 + \\cdots$\n"
"\n"
"Adding up these five terms comes out to $11/8 = 1.375$, not so close to $\\sqrt3\\approx1.73$. And the individual terms\n"
"are not so small, for instance, the last one, $\\frac{5}{128}(2)^4 = 5/8 = 0.625$.\n"
"\n"
"**SOCRATES:** Well, sure, if you set $x$ to be large, like $x > 1$, then the powers of $x$ are also larger and larger (and exponentially so!)... Can you think of something else you could do?\n"
"\n"
"**SIMPLICIO:**\n"
"Ah, I think I see! I know that\n"
"$3$ is near $4$, which is a perfect square. So what if we write\n"
"\n"
"$\\sqrt 3 = \\sqrt{4-1} = \\sqrt{4(1-\\frac14)}=2\\sqrt{1-\\frac14}$\n"
"\n"
"So now if I apply our formula with $x=-1/4$ (which is less than one!), I guess I'll get:\n"
"\n"
"$\\sqrt3 \\approx 2\\left(\n"
"1 + \\frac{1}{2}(-1/4) - \\frac{1}{8}(-1/4)^2 + \\frac{1}{16}(-1/4)^3 -\n"
"\\frac{5}{128}(-1/4)^4+\\cdots\n"
"\\right)$\n"
"\n"
"Taking just these five terms, the fraction on the right comes out to $28379/16384\\approx 1.73212$, which is impressively close to $\\sqrt3\\approx1.7320508$.\n"
"We got 3 decimal places of accuracy, nice!\n"
"\n"
"**SOCRATES:** Great! Now you see the power of Newton's Binomial Theorem. Ok, so then let's return all the way back to your original question, about Newton's estimate for $\\pi$.\n"
"\n"
"**SIMPLICIO:** Hmmm, $\\pi$ is the ratio of circumference to diameter in a circle. So where am I supposed to find a length.\n"
"\n"
"**SOCRATES:** Ah, but what did we learn from Archimedes?\n"
"\n"
"**SIMPLICIO:** Oh, that $\\pi$ is also an *area*, not just a length. It's the area of a unit circle $\\pi r^2$ where $r=1$.\n"
"\n"
"**SOCRATES:** Beautiful. And could you find a circle's area lurking somewhere?\n"
"\n"
"**SIMPLICIO:**  I think I see it! Thanks to Descartes, and \"Cartesian\" coordinates, we can express the  circle as the graph of $x^2+y^2=1$, or to make it a function, $y=\\sqrt{1-x^2}$. So we just have to replace $x$ in our series with $-x^2$.\n"
"\n"
"$\n"
"\\sqrt{1-x^2}\n"
"= 1 + \\frac{1}{2}(-x^2) - \\frac{1}{8}(-x^2)^2 + \\frac{1}{16}(-x^2)^3 - \\frac{5}{128}(-x^2)^4+\\cdots\n"
"$\n"
"\n"
"$\n"
"= 1 - \\frac{x^2}{2} - \\frac{x^4}{8} - \\frac{x^6}{16} - \\frac{5x^8}{128} - \\cdots\n"
"$\n"
"\n"
"And the area under the curve $y=\\sqrt{1-x^2}$ from $x=0$ to $x=1$ is\n"
"a quarter circle.\n"
"[![Quarter Circle](images/PiOver4.jpg)](https://en.wikipedia.org/wiki/Area_of_a_circle)\n"
"\n"
"\n"
"**SOCRATES:** Luckily, Newton had just invented calculus! So how else\n"
"could he compute the area under this curve?\n"
"\n"
"**SIMPLICIO:** With an integral! So:\n"
"\n"
"$\\frac{\\pi}4 = \\int_0^1 \\sqrt{1-x^2} \\, dx =\n"
"\\int_0^1 \\left(1 - \\frac{x^2}{2} - \\frac{x^4}{8} - \\frac{x^6}{16} - \\frac{5x^8}{128} - \\cdots\\right) dx$\n"
"\n"
"I'll just integrate term by term,...\n"
"\n"
"**SOCRATES:** Whoa, hang on! Why are you allowed... You know what, nevermind, sorry.\n"
"Just go ahead.\n"
"\n"
"**SIMPLICIO:** Ok, weirdo. Anyway. So integrating term by term, I get:\n"
"\n"
"$\\frac{\\pi}4 = \\left[x - \\frac{x^3}{6} - \\frac{x^5}{40} - \\frac{x^7}{112} - \\frac{5x^9}{1152} - \\cdots\\right]_0^1$\n"
"\n"
"$= 1 - \\frac{1}{6} - \\frac{1}{40} - \\frac{1}{112} - \\frac{5}{1152} - \\cdots $\n"
"\n"
"Wow! So Newton got an infinite series for $\\pi$!\n"
"If I evaluate just these five terms, and cross multiply by the factor of $4$, I get the fraction\n"
"$32057/10080\\approx 3.180$, not bad!\n"
"\n"
"**SOCRATES:** Not bad indeed. You know, Simplicio, many math papers have roughly zero new ideas; they're just\n"
"doing something nobody bothered to do before in a slightly\n"
"newer context. A really good math paper can have one or two genuinely new ideas. Newton is already on new idea number five, and he's still not done!\n"
"\n"
"**SIMPLICIO:** Ok, so what's new idea number six?\n"
"\n"
"**SOCRATES:** Well, remember how you integrated all the way up to $x=1$? In your series,\n"
"\n"
"$\\frac{\\pi}4 = \\left[x - \\frac{x^3}{6} - \\frac{x^5}{40} - \\frac{x^7}{112} - \\frac{5x^9}{1152} - \\cdots\\right]_0^1$\n"
"\n"
"you have all these high powers of $x$ but they're being \"wasted\" because you're setting $x$ to $1$. What if instead  you only integrated up to, say, $x=1/2$?\n"
"\n"
"**SIMPLICIO:** Ooh, cool! Then the series will converge much more rapidly. But wait, that changes the geometry. Instead of a quarter-circle, we now have... a 30 degree sector, which has area $\\pi/12$, plus a 30-60-90 triangle -- ah that must be why you suggested $x=1/2$ -- with area $\\frac12\\times\\frac12\\times\\frac{\\sqrt3}2$.\n"
"\n"
"[![Integrating to x=1/2](images/PiOver12.jpg)](https://en.wikipedia.org/wiki/Area_of_a_circle)\n"
"\n"
"Good thing we already know how to quickly estimate $\\sqrt3$ to high accuracy! (Ah, that's the trade-off: we could set $x$ even smaller, for faster convergence, but then we'll need to deal with ever more complicated geometric evaluations; so $x=1/2$ is a \"sweet spot\".) So now:\n"
"\n"
" $ \\frac{\\pi}{12} +  \\frac{\\sqrt3}8 =\n"
"\\left[x - \\frac{x^3}{6} - \\frac{x^5}{40} - \\frac{x^7}{112} - \\frac{5x^9}{1152} - \\cdots\\right]_0^{1/2}$\n"
"\n"
"$ = \\frac12 - \\frac{1}{6}\\left(\\frac12\\right)^3 - \\frac{1}{40}\\left(\\frac12\\right)^5 - \\frac{1}{112}\\left(\\frac12\\right)^7 - \\frac{5}{1152}\\left(\\frac12\\right)^9 - \\cdots.$\n"
"\n"
"Again evaluating just these five terms already gives the fraction $9874097/20643840$.\n"
"And now isolating $\\pi$ gives the estimate\n"
"\n"
"$\\pi \\approx 12\\times\\left(9874097/20643840 -  \\frac{\\sqrt3}8\\right) \\approx 3.14161,$\n"
"\n"
"which is off by two parts in $100,000$ from the true estimate $\\pi \\approx 3.14159$. All that with just five terms, amazing!\n"
"\n"
"\n"
"**SOCRATES:** Yes, Newton was very impressive indeed.\n"
"Here's a nice YouTube video by Veritasium that discusses this whole saga (right-click to get it to pop up in a new tab):\n"
"[![Veritasium Video](https://img.youtube.com/vi/gMlf1ELvRzc/maxresdefault.jpg)](https://youtu.be/gMlf1ELvRzc)\n"
"\n"
" In fact, a series for $\\pi$ similar to this one was discovered two centuries earlier, by the Indian mathematician Madhava of Sangamagrama.\n"
" And it would take two more centuries until mathematicians figured out how to rigorously justify Newton's work. To do so, they had to figure out:\n"
"\n"
"- What it meant for a sequence of real numbers $a_0, a_1, a_2,\\dots$ to converge?\n"
"- What it meant for a series (that is, sequence of partial sums) $a_0 + a_1 + a_2 +\\cdots$ to converge, and could we sum these numbers in any order we like,\n"
"- What it meant for a series involving a variable, like a power series $a_0 + a_1  x + a_2  x^2+\\cdots$ to converge, and if so, what kind of function it converged to,\n"
"- When can we interchange limits with integrals, like integrating term by term, $\\int(a_0 + a_1  x + a_2  x^2+\\cdots)dx \\overset{?}=\\int \\, a_0\\, dx+\\int \\, a_1  x\\, dx+\\int\\, a_2  x^2\\, dx+\\cdots$,\n"
"\n"
"Etc, etc. We have a lot of work to do!\n"
"\n"
"**SIMPLICIO:** Ok, ok; you've convinced me! On with some actual Real Analysis please."
msgstr ""

#: Game.Levels.L2Pset.L2Pset1
msgid "# Problem 1\n"
"\n"
"We found in Lecture 2 that Newton's Binomial Theorem gave the expansion\n"
"\n"
"$\n"
"\\sqrt{1+x}\\approx\n"
"1\n"
"+\\frac{1}{2}x\n"
"-\\frac{1}{8}x^2\n"
"+\\frac{1}{16}x^3\n"
"-\\frac{5 x^4}{128}+\\cdots\n"
"$\n"
"\n"
"to fourth order.\n"
"Work out the next term in the expansion. This will be a constant `c` with the property that the polynomial\n"
"\n"
"$\\left(1  +\\frac{1}{2}x\n"
"-\\frac{1}{8}x^2\n"
"+\\frac{1}{16}x^3\n"
"-\\frac{5 x^4}{128} + c \\cdot x^5 \\right)^2 - (1 + x)$\n"
"\n"
"only has terms $x ^ 6$ or higher. (We don't *yet* have a way of saying that in Lean, so I have to give you the expansion explicitly.)"
msgstr ""

#: Game.Levels.L3Levels.L02_OneOverN
msgid "As usual, compare to what's written in textbooks:\n"
"\n"
"## Natural Language Proof of `1 / n → 0`\n"
"\n"
"**Theorem**: The sequence `a(n) = 1 / n` converges to `0`.\n"
"\n"
"**Proof**:\n"
"Let `ε > 0` be given. We need to find `N : ℕ` such that for all `n ≥ N`, we have `|1 / n - 0| < ε`.\n"
"\n"
"Since `ε > 0`, we have `1 / ε > 0`. By the Archimedean Property, there exists a natural number `N` such that `1 / ε < N`. We choose this value of `N`, and use it.\n"
"\n"
"Now let `n ≥ N` be given. We need to show that `|1 / n| < ε`.\n"
"\n"
"Since `1 / ε < N` and `N ≤ n`, we have that `1 / ε < n`. Since both `1 / ε` and `n` are positive, taking reciprocals reverses the inequality: `1 / n < ε`.\n"
"\n"
"Therefore, `|1 / n - 0| = |1 / n| = 1 / n < ε`, which completes the proof. □\n"
"\n"
"## What We Just Accomplished\n"
"\n"
"This proof demonstrates several key concepts:\n"
"\n"
"1. **The power of the Archimedean Property**: Without it, we couldn't guarantee the existence of a suitable `N`.\n"
"\n"
"2. **The `ε`-`N` definition in action**: We explicitly constructed `N` in terms of `ε`, showing the quantifier structure `∀ε, ∃N, ∀n`.\n"
"\n"
"3. **Rigorous inequality manipulation**: What seems \"obvious\" requires careful attention to positivity and type casting.\n"
"\n"
"4. **The bridge between intuition and formality**: The intuitive idea that \"`1 / n` gets arbitrarily small\" becomes a precise mathematical statement."
msgstr ""

#: Game.Levels.L7Levels.L00_Uniqueness
msgid "If `a : ℕ → ℝ` converges to `L` and `M`, then `L = M`."
msgstr ""

#: Game.Levels.L24Levels.L05
msgid "Heine-Borel Theorem: Part 2b"
msgstr ""

#: Game.Levels.L24Levels.L01
msgid "# First Half Complete!\n"
"\n"
"You've just proved that **compact ⟹ bounded**! This is the first half of one direction of the Heine-Borel theorem.\n"
"\n"
"**What Made This Proof Beautiful**:\n"
"- **Infinite to Finite Magic**: You started with infinitely many balls covering all of ℝ, but compactness let you reduce to just finitely many balls covering your set `S`.\n"
"- **Constructive Bound**: Your proof doesn't just say \"a bound exists\" - it gives you an explicit bound as the maximum radius of the finite subcover.\n"
"- **Archimedean Foundation**: The proof relies on the fact that balls `Ball(0, n+1)` eventually cover any point, which is essentially the Archimedean property of ℝ.\n"
"\n"
"**The Bigger Picture**: You've shown that compactness prevents sets from \"escaping to infinity.\" No matter how a compact set tries to spread out, it must stay within some finite ball.\n"
"\n"
"**What's Next**: In Level 2, you'll prove that compact sets are also **closed**. This is trickier - you'll need to show that if a point is outside your compact set, then there's a whole ball around that point that stays outside. The key insight will be using compactness to create \"uniform separation\" between the outside point and your set.\n"
"\n"
"**Historical Note**: This direction (compact ⟹ closed and bounded) is actually the easier direction of Heine-Borel. The hard work comes later when we prove the converse: closed and bounded ⟹ compact. That's where we'll need the deep structure of ℝ!\n"
"\n"
"You're building the foundation for understanding why [a,b] intervals are so special in calculus!"
msgstr ""

#: Game.Levels.L14Levels.L01_BolzanoWeierstrass
msgid "Bolzano-Weierstrass"
msgstr ""

#: Game.Levels.L22Levels.L03
msgid "`(f : ℝ → ℝ) (a b : ℝ) (N : ℕ) :=\n"
"  (b - a) / N * ∑ i ∈ range N, f (a + (i + 1) * (b - a) / N)`\n"
"\n"
"\n"
"The Riemann sum of `f` from `a` to `b` with `N` subintervals."
msgstr ""

#: Game.Levels.L18Pset.L04
msgid "# Level 4: `CoherenceOfReals`\n"
"\n"
"Prove `CoherenceOfReals`:"
msgstr ""

#: Game.Levels.L18Pset.L10
msgid "# Level 10: `DiffGoesToZero`\n"
"\n"
"Prove `DiffGoesToZero`:"
msgstr ""

#: Game.Levels.L20Levels.L03
msgid "## What We've Learned\n"
"\n"
"This theorem marks a major milestone: we've proven that continuity is **preserved under addition**!\n"
"\n"
"### The `ε/2` Trick\n"
"\n"
"This is one of the most elegant techniques in analysis:\n"
"\n"
"- We need to make `|(f + g)(x) - (f + g)(c)| < ε`\n"
"- By the triangle inequality: `|(f + g)(x) - (f + g)(c)| ≤ |f(x) - f(c)| + |g(x) - g(c)|`\n"
"- If each piece is less than `ε/2`, the sum is less than `ε`!\n"
"\n"
"The beauty: we **split the budget**. Each function gets half the tolerance.\n"
"\n"
"### The `min(δ₁, δ₂)` Strategy\n"
"\n"
"Why take the minimum of two deltas?\n"
"\n"
"- `δ₁` works for `f`: guarantees `|f(x) - f(c)| < ε/2` when `|x - c| < δ₁`\n"
"- `δ₂` works for `g`: guarantees `|g(x) - g(c)| < ε/2` when `|x - c| < δ₂`\n"
"- `min(δ₁, δ₂)` works for **both**: it's the \"most restrictive\" requirement\n"
"\n"
"**Key insight:** When combining guarantees, take the stronger (smaller) constraint!\n"
"\n"
"### Building Up From Simple Pieces\n"
"\n"
"This is the beginning of a powerful story. We can now prove:\n"
"- Sums of continuous functions are continuous ✓\n"
"- Products of continuous functions are continuous (similar proof!)\n"
"- Compositions of continuous functions are continuous (chain rule!)\n"
"- Therefore: all polynomials, rational functions, trig functions, etc. are continuous!\n"
"\n"
"We've just laid the foundation for understanding continuity of essentially every function in calculus."
msgstr ""

#: Game.Levels.L9Levels.L04_FiniteSums
msgid "`range N`\n"
"\n"
"For a natural number `N`, `range N` represents the numbers from\n"
"`0` to `N-1` (there are `N` of them).\n"
"\n"
"Usage: `∑ k ∈ range N, k = N * (N + 1) / 2`."
msgstr ""

#: Game.Levels.L6Levels.L01_SplitAnds
msgid "Split Ands"
msgstr ""

#: Game.Levels.L3Levels.L02_OneOverN
msgid "We need to find `N`. Use the Archimedean Property: there exists `N` such that `1 / ε < N`. Try: `have f1 : ∃ (N : ℕ), 1 / ε < N := by apply ArchProp hε`"
msgstr ""

#: Game
msgid "*An Introduction to Formal Real Analysis - Interactive Edition*\n"
"\n"
"## About this Course\n"
"\n"
"This course follows the historical crises that forced mathematicians to rebuild\n"
"mathematics from the ground up in the 19th century. You'll learn why concepts\n"
"like `ε`-`δ` definitions became necessary and how to use them to do advanced calculus.\n"
"\n"
"## Credits\n"
"\n"
"* **Course Design:** By Alex Kontorovich alex.kontorovich@rutgers.edu\n"
"* **Interactive Implementation:** Lean 4 Game Engine\n"
"* **Mathematical Content:** Following Rudin, Stein-Shakarchi, Abbot, etc.\n"
"* **Many thanks to:** Jon Eugster, Heather Macbeth, Michael Stoll, and the students of 311H for a lot of technical support, encouragement, and many great suggestions for improvement!"
msgstr ""

#: Game.Levels.L12Levels.L01_MonotoneBdd
msgid "## What You've Accomplished\n"
"\n"
"You've just proven one of the cornerstone theorems of real analysis. By showing that every bounded monotone sequence is Cauchy, you've established a fundamental bridge between order properties (monotonicity and boundedness) and topological properties (convergence).\n"
"\n"
"## The Power of Contradiction\n"
"\n"
"This proof demonstrates the elegance of contradiction in analysis. By assuming the sequence wasn't Cauchy, you were able to extract concrete subsequences that witness persistent gaps. The beauty lies in how these gaps, when iterated, necessarily violate the boundedness assumption - making the contradiction inevitable rather than accidental.\n"
"\n"
"## Why This Theorem Matters\n"
"\n"
"This result is foundational because:\n"
"- It provides a practical convergence test that doesn't require knowing the limit\n"
"- It underlies the Monotone Convergence Theorem in measure theory\n"
"- It establishes that \"order + bounds = convergence\" - a principle that appears throughout analysis\n"
"\n"
"## The Role of Abstraction\n"
"\n"
"By proving this for an abstract type `X` rather than specific number systems, you've seen how mathematical abstraction pays dividends. This single proof now covers both rational and real sequences, and will work for any mathematical structure with the right properties.\n"
"\n"
"## Looking Ahead\n"
"\n"
"In the next level, you'll prove the technical helper lemma `IterateGap` that made this proof possible. You'll see exactly how the orbit construction from Level 1 combines with monotonicity to create the linear accumulation of gaps that drives the contradiction.\n"
"\n"
"The technique you've mastered - using `choose` to extract witnesses, then applying iteration to scale up local properties - is a powerful pattern that appears throughout advanced analysis."
msgstr ""

#: Game.Levels.L1RealAnalysisStory.L05_use
msgid "The use tactic"
msgstr ""

#: Game.Levels.L22Levels.L01
msgid "Continuous Composition"
msgstr ""

#: Game.Levels.L7Levels.L01_Eventually
msgid "Eventually"
msgstr ""

#: Game.Levels.L25Levels.L02
msgid "Intermediate Value Theorem"
msgstr ""

#: Game.Levels.L10Lecture
msgid "Lecture 10: Algebraic Limit Theorem, Part V"
msgstr ""

#: Game.Levels.L18Levels.L01
msgid "# Level 1: Absolute Convergence Implies Convergence\n"
"\n"
"In this level, we introduce the concept of **absolute convergence** and prove one of the fundamental theorems about series: if a series converges absolutely, then it converges.\n"
"\n"
"## New definition: `AbsSeriesConv`\n"
"\n"
"A series `Series a` is said to converge *absolutely* (`AbsSeriesConv`) if the series of absolute values\n"
"`Series (fun n ↦ |a n|)` converges.\n"
"\n"
"This is a *stronger* condition than ordinary convergence. For instance, the alternating harmonic series\n"
"$$\\sum_{k=1}^{\\infty} \\frac{(-1)^{k+1}}{k} = 1 - \\frac{1}{2} + \\frac{1}{3} - \\frac{1}{4} + \\cdots$$\n"
"converges but does *not* converge absolutely (since the harmonic series diverges).\n"
"\n"
"## The Main Result\n"
"\n"
"**Theorem** (`Conv_of_AbsSeriesConv`): If a series converges absolutely, then it converges.\n"
"\n"
"In other words: *absolute convergence implies convergence*.\n"
"\n"
"## Proof Strategy\n"
"\n"
"The key insight is that if the series of absolute values converges, then it is Cauchy, which means the tails of the series get arbitrarily small. By the triangle inequality, if $\\sum |a_k|$ is small, then $|\\sum a_k|$ is also small.\n"
"\n"
"We will use two helper lemmas (to be proved as homework):\n"
"- `DiffOfSeries`: The difference of partial sums equals the sum over the interval\n"
"- `Series_abs_add`: The triangle inequality for finite sums\n"
"\n"
"Your task: Prove `Conv_of_AbsSeriesConv` using the Cauchy criterion and these lemmas."
msgstr ""

#: Game.Levels.L6Levels.L01_SplitAnds
msgid "🎯 Tactical Mastery Achieved! 🎯\n"
"\n"
"Perfect! You've just learned one of the most practical tactics in your Lean toolkit. The `split_ands` tactic might seem simple, but it's incredibly powerful for organizing complex proofs.\n"
"\n"
"## Why This Matters:\n"
"\n"
"Many important mathematical theorems have conclusions that are conjunctions—statements of the form \"A and B and C\". Being able to break these down systematically makes proofs much more manageable and readable.\n"
"\n"
"## Looking Ahead:\n"
"\n"
"As we continue building our arsenal of proof techniques, you'll find that `split_ands` combines beautifully with the convergence arguments we've been developing. Often in analysis, we need to prove that multiple sequences converge, or that a single sequence satisfies multiple properties simultaneously.\n"
"The beauty of mathematical proof lies not just in reaching the destination, but in breaking the journey into clear, logical steps. `split_ands` is your tool for taking that first crucial step: turning one complex goal into several simpler ones."
msgstr ""

#: Game.Levels.L19Levels.L01
msgid "For `a` and `b`, `x ∈ Ico a b ↔ a ≤ x ∧ x < b`."
msgstr ""

#: Game.Levels.L12Levels.L00_SubseqIterate
msgid "For a function `σ : ℕ → ℕ`, if `σ n < σ (n+1)`, then\n"
"for any `i < j`, `σ i < σ j` -- that is, `Subseq σ` holds."
msgstr ""

#: Game.Levels.L23Levels.L03
msgid "`Ball (x : ℝ) (r : ℝ) : Set ℝ := Ioo (x - r) (x + r)`\n"
"\n"
"A ball of radius `r` centered at `x` is the open interval `(x - r, x + r)`."
msgstr ""

#: Game.Levels.L5Levels.L01_DoubleSeqConv
msgid "Apply the convergence of `a` with tolerance `ε / 2`. Try: `specialize h (ε / 2)`"
msgstr ""

#: Game.Levels.L1RealAnalysisStory.L08_choose
msgid "The `choose` tactic extracts a witness from an existence statement in a hypothesis."
msgstr ""

#: Game.Levels.L10Levels.L08_Mono
msgid "# Level 3: Subsequence Theorem\n"
"\n"
"A **subsequence** is what you get when you drop out some terms from a sequence and slide everyone left.\n"
"\n"
"**Two Perspectives on Subsequences:**\n"
"\n"
"Most textbooks write $a_{\\sigma(n)}$ and call this \"the subsequence of `a`.\" But we prefer to think of **`σ` itself as the subsequence**—it's the function `σ : ℕ → ℕ` that tells us which terms of `a` to keep. When people use the word \"of\" in mathematics, it implies multiplication, which in the case of functions means composition. So the words \"subsequence of a sequence\" should mean the composition `a ∘ σ` of a sequence `a` with a \"subsequence\" `σ`.\n"
"\n"
"**The Geometric Picture:**\n"
"\n"
"Imagine the graph of `a n`. To form a subsequence:\n"
"1. Drop out some terms (say, keep only positions 0, 2, 5, 7, 11, ...)\n"
"2. Slide everyone left so every index has a value\n"
"3. The new sequence is indexed 0, 1, 2, 3, 4, ...\n"
"\n"
"The function `σ` encodes this relabeling:\n"
"- `σ(0) = 0` (keep term 0)\n"
"- `σ(1) = 2` (skip term 1, keep term 2)\n"
"- `σ(2) = 5` (skip terms 3,4, keep term 5)\n"
"- etc.\n"
"\n"
"**Definition: `Subseq σ`**\n"
"\n"
"A function `σ : ℕ → ℕ` is a subsequence if it's **strictly monotone increasing**:\n"
"```\n"
"∀ i j, i < j → σ(i) < σ(j)\n"
"```\n"
"\n"
"This ensures we preserve the original ordering—we can't rearrange terms, only delete some!\n"
"\n"
"**Key Lemma: `SubseqGe`**\n"
"\n"
"If `σ` is a subsequence, then `n ≤ σ(n)` for all `n`.\n"
"\n"
"Intuition: as you drop terms and relabel, indices can only \"spread out,\" never compress. The new index `n` corresponds to some original index `σ(n) ≥ n`. (You already proved this in Problem Set 8, Exercise 4.)\n"
"\n"
"**The Theorem:** If `a n → L` and `σ` is a subsequence, then `(a ∘ σ) n → L`.\n"
"\n"
"Translation: **every subsequence of a convergent sequence converges to the same limit**.\n"
"\n"
"**Proof Strategy:**\n"
"\n"
"This one is surprisingly simple! Given `ε > 0`:\n"
"- Use convergence of `a` to find `N` such that `|a m - L| < ε` for all `m ≥ N`\n"
"- For any `n ≥ N`, note that `σ(n) ≥ n ≥ N` (by `SubseqGe`)\n"
"- Therefore `|a(σ(n)) - L| < ε`\n"
"\n"
"Done! The same `N` works for both the sequence and all its subsequences.\n"
"\n"
"**Powerful Consequence:**\n"
"\n"
"If a sequence has two subsequences converging to **different limits**, then the sequence itself **does not converge**! This gives us a new way to prove divergence. (See Lecture 10 Exercises.)"
msgstr ""

#: Game.Levels.L19Levels.L01
msgid "If `x ∈ s`, and `0 ≤ f i`, for all `i ∈ s`, then `f x ≤ ∑ i ∈ s, f i`."
msgstr ""

#: Game.Levels.L11Levels.L03_IsBddOfCauchy
msgid "Level 3 : Cauchy Implies Bounded"
msgstr ""

#: Game.Levels.L22Levels.L03
msgid "`(f : ℝ → ℝ) (a b : ℝ) := ∃ I, HasIntegral f a b I`\n"
"\n"
"A function `f : ℝ → ℝ` is `IntegrableOn` the interval `a` to `b` if there exists some `I` so that the integral $\\\\int_a^b f(x)dx$ converges and equals `I`."
msgstr ""

#: Game.Levels.L20Pset.L03
msgid "# Level 3: Const Times Limit\n"
"\n"
"Prove that if `f → L` as `x → c`, then `k · f → k · L`."
msgstr ""

#: Game.Levels.L6Pset.L6Pset4
msgid "# Problem 4\n"
"\n"
"You are given that a sequence `a : ℕ → ℝ` with the property that it takes arbitrarily large values exceeding 10 in absolute value.\n"
"Prove that cannot have a limit less than 5."
msgstr ""

#: Game.Levels.L12Levels.L01_MonotoneBdd
msgid "The `push_neg` tactic pushes negations through universal and existential quantifiers, inequalities, etc."
msgstr ""

#: Game.Levels.L12Levels.L02_IterateGap
msgid "# Level 4: Iterated Gaps\n"
"\n"
"Now it's time to prove the technical helper lemma that made Level 2 possible. This result captures the precise mechanism by which persistent gaps in a monotone sequence accumulate under iteration.\n"
"\n"
"## The Setup\n"
"\n"
"Recall from Level 2: we had a bounded monotone sequence that we assumed (for contradiction) was not Cauchy. This gave us:\n"
"- Some `ε > 0` representing the persistent gap size\n"
"- Subsequences `τ` and `σ` where `τ n ≥ n` and `σ n ≥ τ n`\n"
"- The gap condition: `ε ≤ |a (σ n) - a (τ n)|` for all `n`\n"
"\n"
"The question was: how do these gaps accumulate when we iterate `σ`?\n"
"\n"
"## The Goal\n"
"\n"
"**Your task:** Prove that `∀ k, k * ε ≤ a (σ^[k] 0) - a 0`\n"
"\n"
"In words: iterating `σ` exactly `k` times from `0` gives us at least `k * ε` total growth from the starting value. This linear accumulation is what drives the contradiction with boundedness.\n"
"\n"
"## Why This is Non-Trivial\n"
"\n"
"You might think: \"If we get `ε` growth each step, then after `k` steps we get `k * ε` growth - isn't that obvious?\" But there are subtle issues:\n"
"- We don't get `ε` growth from `σ^[i] 0` to `σ^[i+1] 0` directly\n"
"- Instead, we get `ε` growth from `τ(σ^[i] 0)` to `σ(σ^[i] 0)`\n"
"- We need to carefully account for the \"gaps\" between these points\n"
"\n"
"The proof requires showing that monotonicity allows us to \"telescope\" these gaps correctly.\n"
"\n"
"## The Strategy\n"
"\n"
"**Induction on k:**\n"
"- **Base case:** `k = 0` gives `0 ≤ a 0 - a 0`, which is trivial\n"
"- **Inductive step:** Assume we have `k * ε ≤ a (σ^[k] 0) - a 0`. We need to show `(k+1) * ε ≤ a (σ^[k+1] 0) - a 0`\n"
"\n"
"The key insight: apply the gap condition at the point `σ^[k] 0` to get:\n"
"`ε ≤ |a (σ (σ^[k] 0)) - a (τ (σ^[k] 0))|`\n"
"\n"
"Then use monotonicity and the `succ_iterate` theorem to connect this to the growth from `σ^[k] 0` to `σ^[k+1] 0`."
msgstr ""

#: Game.Levels.L12Pset.L12Pset1
msgid "If `a` satisfies `IsCauchy`, then `-a` does too."
msgstr ""

#: Game.Levels.L19Lecture
msgid "# Lecture 19: Rearrangements"
msgstr ""

#: Game.Levels.L12Levels.L00_SubseqIterate
msgid "Try starting your proof with `apply subseq_of_succ`."
msgstr ""

#: Game.Levels.L21Levels.L06
msgid "Computing a Derivative"
msgstr ""

#: Game.Levels.L1Pset.L1Pset1
#: Game.Levels.L8Pset.L8Pset1
msgid "# Problem 1"
msgstr ""

#: Game.Levels.L18Levels.L02
msgid "Alternating Series Test"
msgstr ""

#: Game.Levels.L3Levels.L02_OneOverN
msgid "If `a n = 1 / n`, then `SeqLim a 0`; that is, the sequence\n"
"`1 / n` converges to zero."
msgstr ""

#: Game.Levels.L22Pset.L03
msgid "# Level 3: Differentiability Exercise\n"
"\n"
"Show that `x ↦ x ^ 3` is differentiable."
msgstr ""

#: Game.Levels.L23Levels.L03
msgid "# Level 3: Compactness\n"
"\n"
"**The Final Puzzle Piece**: We've shown that uniformly continuous functions are integrable. But when is a continuous function *uniformly* continuous? The beautiful answer involves one of mathematics' most elegant concepts: **compactness**.\n"
"\n"
"**The Big Theorem**: Every continuous function on a compact set is automatically uniformly continuous on that set. Combined with Level 2, this means every continuous function on a compact set is integrable!\n"
"\n"
"**What Is Compactness?**: Intuitively, a set is compact if it's \"small enough\" that any covering by open balls can be reduced to a finite covering. Here's the key insight for uniform continuity:\n"
"\n"
"1. **Start with continuity**: At each point `x` in your set `S`, continuity gives you a ball around `x` where the function doesn't vary much\n"
"2. **Cover the set**: These balls cover your entire set `S`\n"
"3. **Apply compactness**: Extract a *finite* subcover\n"
"4. **Take the minimum**: Since you now have only finitely many balls, you can take the minimum of their radii to get a uniform `δ`!\n"
"\n"
"**New Definitions**:\n"
"\n"
"Open ball of radius `r` around `x`:\n"
"\n"
"`def Ball (x : ℝ) (r : ℝ) : Set ℝ := Ioo (x - r) (x + r)`\n"
"\n"
"Compactness (every open cover has a finite subcover):\n"
"\n"
"`def IsCompact (S : Set ℝ) : Prop :=\n"
"  ∀ (ι : Type) (xs : ι → ℝ) (δs : ι → ℝ), (∀ i, 0 < δs i) →\n"
"    (S ⊆ ⋃ i, Ball (xs i) (δs i)) →\n"
"    ∃ (V : Finset ι), S ⊆ ⋃ i ∈ V, Ball (xs i) (δs i)`\n"
"\n"
"**The Magic**: The index type `ι` can be *anything* - natural numbers, real numbers, even uncountable sets. But compactness guarantees we can always reduce to a finite subcover!\n"
"\n"
"**Key Tools**:\n"
"- `mem_Union`: `(x ∈ ⋃ i, s i) ↔ ∃ i, x ∈ s i`\n"
"- `FinMinPos`: From finitely many positive numbers, you can extract a positive lower bound\n"
"\n"
"**Your Mission**: Prove that continuous + compact = uniformly continuous!"
msgstr ""

#: Game.Levels.L7Levels.L03_SeqInvLim
msgid "For any real numbers `x` and `y`, we have `|x / y| = |x| / |y|`."
msgstr ""

#: Game.Levels.L20Pset.L03
msgid "Prove `ConstTimesLimAt`"
msgstr ""

#: Game.Levels.L1Pset.L1Pset5
msgid "# Problem 5\n"
"\n"
"You've learned about adding hypotheses with `have`, and that you can call tactics not\n"
"just to act on the Goal, but  also on hypotheses, via adding `at HypothesisName` at the end.\n"
"You also know that calling the `rewrite` tactic with a hypothesis `h : X = Y` takes the *left hand side* `X` and replaces it by `Y`. But what if you needed instead to replace `Y`'s by `X`'s? We call that \"backwards rewriting\". The syntax for that is:\n"
"\n"
"`rewrite [← h]`\n"
"\n"
"or\n"
"\n"
"`rewrite [← h] at h2`\n"
"\n"
"to do it at some other hypothesis, `h2`. You get the backwards arrow by typing \\left,\n"
"that is, the backslash, then the word `left`, and then a space.\n"
"\n"
"You may (or may not) find that useful in this problem."
msgstr ""

#: Game.Levels.L2NewtonsCalculationOfPi.L01_SeqConvDef
msgid "For any sequence `a : ℕ → ℝ` and constant `L : ℝ`, and\n"
"hypothesis `h : ∀ n, a n = L`, the theorem `ConstLim`\n"
"proves that `SeqLim a L`, that is, the (constant) sequence `a` converges to `L`."
msgstr ""

#: Game.Levels.L6Levels.L04_Cases'
msgid "# 🔄 Case Analysis Mastered! 🔄\n"
"\n"
"Excellent! You've just learned one of the most powerful proof techniques in mathematics: case analysis. The `cases'` tactic embodies a fundamental principle of logical reasoning—when you don't know which of several possibilities is true, you prove your result holds in every case.\n"
"\n"
"**Why This Matters:**\n"
"Case analysis is everywhere in mathematics. From proving that every integer is either even or odd, to showing that continuous functions on closed intervals achieve their extrema, the ability to systematically consider all possibilities is crucial for rigorous reasoning.\n"
"\n"
"**The Beauty of Completeness:**\n"
"Notice how `cases'` forced you to handle both scenarios completely. This isn't just a formal requirement—it ensures that your proof is truly bulletproof. No matter which case actually occurs, your argument will hold.\n"
"\n"
"**Strategic Insight:**\n"
"In our example, both cases led to the same algebraic manipulation (`ring_nf`), but that won't always be true. Often, different cases require entirely different approaches. Learning to adapt your strategy to each case while keeping sight of the overall goal is a key mathematical skill.\n"
"\n"
"**Looking Forward:**\n"
"As we continue with convergence proofs and other analysis topics, you'll find `cases'` invaluable for handling statements like \"either the sequence is bounded above or below\" or \"either the limit exists or the sequence diverges.\" The systematic approach you've learned here will serve you well in these more complex scenarios.\n"
"\n"
"Mathematics is about leaving no stone unturned, no possibility unconsidered. With `cases'`, you now have the tools to be completely thorough in your logical investigations."
msgstr ""

#: Game.Levels.L18Levels.L02
msgid "If `a → L` and `b → M` and `a - b → 0`, then `L = M`."
msgstr ""

#: Game.Levels.L2PsetIntro
msgid "Pset 2"
msgstr ""

#: Game.Levels.L10Levels.L07_Order
msgid "Order Limit Theorem"
msgstr ""

#: Game.Levels.L18Levels.L02
msgid "If `a : ℕ → ℝ` is `Antitone` and `∀ n, 0 ≤ a n`, then the odd alternating series `n ↦ ∑ k ∈ range (2n+1), (-1)^k * a k` is `Antitone`."
msgstr ""

#: Game.Levels.L17Levels.L01
#: Game.Levels.L17Levels.L02
msgid "Leibniz Series"
msgstr ""

#: Game.Levels.L3Levels.L02_OneOverN
msgid "Also clear denominators in our key inequality: `field_simp at eps_inv_lt_N`"
msgstr ""

#: Game.Levels.L7Levels.L04_ByCases
msgid "The `by_cases` tactic has syntax `by_cases h : fact`, where `h` is your name for a new hypothesis,\n"
"and `fact` is the fact claimed in the hypothesis. Calling `by_cases` creates two subgoals, one with\n"
"the additional hypothesis `h : fact`, and the second has the hypothesis `h : ¬ fact`."
msgstr ""

#: Game.Levels.L1RealAnalysisStory.L02_rfl
msgid "# When things are identical to themselves\n"
"\n"
"Sometimes in mathematics, we need to prove that something equals itself. For example, we might need to prove that $x ^ 2 + 2 * y = x ^ 2 + 2 * y$.\n"
"\n"
"This isn't quite the same as our previous exercise. There, we had a hypothesis `h` that told us `x = 5`, and we used `apply h` to prove the goal `x = 5`.\n"
"\n"
"But now we don't have any hypothesis that says `x ^ 2 + 2 * y = x ^ 2 + 2 * y`. We're just being asked to prove that some expression equals itself. We can't say `apply something` because there's no `something`.\n"
"\n"
"Instead, we will use what mathematicians call the *reflexive property* of equality: everything is equal to itself. In Lean, if you get to a situation where you're trying to prove an equality, and the two things on both sides are *identical*, then the syntax is to give the command `rfl` (short for \"reflexivity\").\n"
"\n"
"Try it out!"
msgstr ""

#: Game.Levels.L7Levels.L02_SeqOfAbs
msgid "## What You've Proven\n"
"\n"
"Great work! You've proven that the absolute value function **preserves convergence**: if\n"
"`a n → L`, then `|a n| → |L|`. This is one of the cleanest and most elegant proofs in\n"
"the course so far.\n"
"\n"
"## The Power of Lipschitz Continuity\n"
"\n"
"The key insight was that because absolute value is Lipschitz continuous with constant 1,\n"
"we have `||a n| - |L|| ≤ |a n - L|`. This single inequality immediately gives us the\n"
"convergence we need—no complicated epsilon manipulations, no splitting cases, just a\n"
"direct application of the Lipschitz property.\n"
"\n"
"## The Bigger Picture\n"
"\n"
"This theorem is your first glimpse of a profound principle in analysis: **continuous\n"
"functions preserve limits**. We've just proven this for one specific continuous function\n"
"(absolute value), but the same idea works for all continuous functions. If `f` is\n"
"continuous and `a n → L`, then `f(a n) → f(L)`. This is why calculus works the way it\n"
"does—you can \"pass limits through\" continuous functions like polynomials, exponentials,\n"
"trigonometric functions, and more.\n"
"\n"
"The Lipschitz property is even stronger than continuity—it gives us quantitative control\n"
"over how fast the function can change. This makes Lipschitz functions particularly\n"
"well-behaved and useful throughout analysis, differential equations, and optimization."
msgstr ""

#: Game.Levels.L3Levels.L02_OneOverN
msgid "Therefore `n > 0`; try: `have npos : (0 : ℝ) < n := by linarith [Npos, N_le_n]`"
msgstr ""

#: Game.Levels.L11PsetIntro
msgid "Pset 11"
msgstr ""

#: Game.Levels.L2NewtonsCalculationOfPi.L01_SeqConvDef
msgid "The Convergence of a Sequence"
msgstr ""

#: Game.Levels.L24Pset.L01
msgid "Lipschitz implies Uniformly Continuous"
msgstr ""

#: Game.Levels.L20Pset.L02
msgid "ContinuousIff II"
msgstr ""

#: Game.Levels.L12Levels.L01_Choose
msgid "You can make `σ` by taking an orbit of `τ`! You can start at any base point, as long as `p` is satisfied for that base point; since we don't *a priori* know of such a point, we can start with `τ 0`. Try writing `let σ : ℕ → ℕ := fun n ↦ τ^[n] (τ 0)`."
msgstr ""

#: Game.Levels.L19Levels.L01
msgid "# Level 1: More Flexible Cauchy\n"
"\n"
"In this level, we prove a stronger version of the Cauchy criterion that will be essential for understanding rearrangements of series.\n"
"\n"
"## The Main Result\n"
"\n"
"**Theorem** (`StrongCauchy_of_AbsSeriesConv`): If a series converges absolutely, then for any `ε > 0`, there exists `N` such that for *any* finite set `S : Finset ℕ` whose elements all exceed `N`, we have:\n"
"\n"
"`∑ k ∈ S, |a k| < ε`\n"
"\n"
"## Why This is Stronger\n"
"\n"
"The usual Cauchy criterion only tells us that consecutive intervals `[n, m)` have small sum. This theorem says something much more powerful: *any* finite collection of sufficiently large-index terms has small sum, regardless of whether the indices are consecutive or scattered.\n"
"\n"
"## The Key Insight\n"
"\n"
"For absolutely convergent series, the tail becomes arbitrarily small. Any finite subset of the tail is contained in some interval, and by monotonicity of sums of nonnegative terms, the sum over the subset is bounded by the sum over the interval.\n"
"\n"
"This flexibility is exactly what we need to handle rearrangements, where terms might appear in a completely different order.\n"
"\n"
"## New Theorems\n"
"\n"
"- `sum_le_sum_of_nonneg`: If `S ⊆ T` and all values are nonnegative, then `∑ i ∈ S, f i ≤ ∑ i ∈ T, f i`\n"
"- `sum_le_mem_of_nonneg`: If `x ∈ S` and all values are nonnegative, then `f x ≤ ∑ i ∈ S, f i`\n"
"- `mem_Ico`: Characterizes membership in half-open intervals `[a, b)`\n"
"\n"
"Your task: Prove the strong Cauchy property using these tools!"
msgstr ""

#: Game.Levels.L10Levels.L07_Order
msgid "`(a : ℕ → ℝ) (M : ℝ) := ∀ n, a n ≤ M`\n"
"\n"
"A sequence `a : ℕ → ℝ` is *bounded by* (`SeqBddBy` holds) `M : ℝ` if, for all `n`, `a n ≤ M`, for all `n`."
msgstr ""

#: Game.Levels.L22Levels.L03
msgid "Range cardinality: `card (range n) = n`."
msgstr ""

#: Game.Levels.L3Levels.L02_OneOverN
msgid "Cast the inequality `n ≥ N` to reals, so that `linarith` can see and access it: `have N_le_n : (N : ℝ) ≤ n := by exact_mod_cast n_ge_N`"
msgstr ""

#: Game.Levels.L10Levels.L06_Prod
msgid "Big Boss : Product of Sequences"
msgstr ""

#: Game.Levels.L13Levels.L03_MonotoneSubseq
msgid "# 🎉 Congratulations!\n"
"\n"
"You've just proved one of the most elegant results in real analysis: sequences without unbounded peaks have monotone subsequences. Let's appreciate what you accomplished.\n"
"\n"
"## What You Built\n"
"\n"
"Starting with just the hypothesis that peaks don't go on forever, you:\n"
"\n"
"1. **Extracted structure from negation** - Used `choose` to get a bound `k` and witnesses `τ(n)` beyond which no peaks exist\n"
"\n"
"2. **Patched together a global function** - Combined `n+1` (for `n ≤ k`) and `τ(n)` (for `n > k`) using `if-then-else` to create `τ'` that grows everywhere\n"
"\n"
"3. **Leveraged orbits** - Applied the Lecture 12 technique of iterating `τ'` to build a strictly increasing subsequence `σ`\n"
"\n"
"4. **Extracted monotonicity** - Showed that beyond the peak bound, each step must climb: `a(σ(n)) ≤ a(σ(n+1))`\n"
"\n"
"The proof is a masterclass in constructive mathematics: you didn't just show a subsequence *exists*—you *built* it explicitly using orbits and witnesses.\n"
"\n"
"## The Bigger Picture: A Fundamental Dichotomy\n"
"\n"
"Every sequence falls into exactly one of two camps:\n"
"\n"
"- **Unbounded peaks:** Infinitely many positions from which the sequence never recovers → You can extract a **non-increasing** (antitone) subsequence (your homework!)\n"
"\n"
"- **Bounded peaks:** Eventually, no more peaks appear → You just proved there's a **non-decreasing** (monotone) subsequence\n"
"\n"
"This dichotomy is profound: *chaos is impossible*. No matter how wild a sequence appears, somewhere within it lies monotonic order. Either it keeps hitting new peaks (descending order), or it eventually runs out of peaks (ascending order). There is no third option.\n"
"\n"
"## The Technique: Conditional Construction\n"
"\n"
"The `if-then-else` construct was crucial here. We needed a single function `τ'` that:\n"
"- Works for *all* natural numbers (not just those beyond `k`)\n"
"- Grows faster than identity everywhere\n"
"- Matches our witness function `τ` where it matters (beyond `k`)\n"
"\n"
"The conditional definition elegantly threaded this needle. Combined with `lt_of_not_ge` to handle the logic, we converted a partially-defined witness into a globally-defined building block for our orbit.\n"
"\n"
"This pattern—patching together local information into global constructions—appears throughout analysis. You've now mastered a fundamental technique.\n"
"\n"
"## Looking Ahead: Bolzano-Weierstrass\n"
"\n"
"In your homework, you'll prove the complementary result for sequences with unbounded peaks. The proof is actually simpler: just take the peaks themselves as your subsequence!\n"
"\n"
"Then in Lecture 14, we'll combine both results with the bounded monotone sequence theorem (Lecture 12) to prove the **Bolzano-Weierstrass Theorem**:\n"
"\n"
"**Every bounded sequence has a Cauchy subsequence.**\n"
"\n"
"That's right—boundedness alone guarantees convergent behavior. This is one of the crown jewels of real analysis, and you've just built half of its foundation.\n"
"\n"
"## What You've Mastered\n"
"\n"
"✓ **Proof by cases:** Using negation and `choose` to extract witnesses from non-existence\n"
"\n"
"✓ **Conditional definitions:** Building functions with `if-then-else` to patch local into global\n"
"\n"
"✓ **Orbit construction:** Iterating functions to force monotonic growth\n"
"\n"
"✓ **Strategic thinking:** Breaking complex proofs into: unpack hypothesis → build auxiliary objects → extract desired properties\n"
"\n"
"These aren't just tricks for one theorem—they're fundamental tools you'll use throughout mathematics.\n"
"\n"
"## Final Thought\n"
"\n"
"You stood at the crossroads of chaos and order. You proved that beyond a certain point, if peaks cease to exist, then climbing never stops. The sequence may not increase at every step, but along some carefully chosen path—an orbit through phase space—it marches upward inexorably.\n"
"\n"
"This is the power of subsequences: they let us *choose* our vantage point, focusing only on the moments that matter. And it's the power of formal proof: what seems intuitively obvious (\"if there are no peaks, something must be going up\") becomes a rigorous construction you can trust completely.\n"
"\n"
"Next up: What happens when peaks *don't* stop? Spoiler: they fall forever.\n"
"\n"
"**Ready for the homework? Time to make those peaks tumble down!**"
msgstr ""

#: Game.Levels.L20Levels.L04
msgid "If a function `f` has limit `L` at point `c`, then for every sequence `(xₙ)` converging to `c` with `xₙ ≠ c`, the sequence `f(xₙ)` converges to `L`."
msgstr ""

#: Game.Levels.L12Pset.L12Pset2
msgid "# Problem 2:\n"
"\n"
"More fun with Cauchy sequences. Show that `1/n` is Cauchy but is neither `Monotone` nor `Antitone`! (Because of how division by zero works in Lean...)"
msgstr ""

#: Game.Levels.L3Pset.L3Pset4
msgid "Determine the limit `L` of the sequence `a (n) = (3n + 8) / (2n + 5)`, and prove that `a` indeed converges to `L`."
msgstr ""

#: Game.Levels.L6Pset.L6Pset1
#: Game.Levels.L6Pset.L6Pset2
#: Game.Levels.L6Pset.L6Pset3
#: Game.Levels.L6Pset.L6Pset4
#: Game.Levels.L6Pset.L6Pset5
#: Game.Levels.L7Pset.L7Pset1
#: Game.Levels.L7Pset.L7Pset2
#: Game.Levels.L7Pset.L7Pset3
#: Game.Levels.L8Pset.L8Pset1
#: Game.Levels.L8Pset.L8Pset2
#: Game.Levels.L8Pset.L8Pset3
#: Game.Levels.L8Pset.L8Pset4
#: Game.Levels.L9Pset.L9Pset1
#: Game.Levels.L9Pset.L9Pset2
#: Game.Levels.L9Pset.L9Pset3
msgid "Prove the statement."
msgstr ""

#: Game.Levels.L7Levels.L04_ByCases
msgid "If `a : ℕ → ℝ` converges to `L` (with *no* assumption that `L ≠ 0`), then there is an `N` so that\n"
"for all `n ≥ N`, `|a (n)| ≥ |L| / 2`."
msgstr ""

#: Game.Levels.L25Levels.L01
msgid "Uniform Convergence Implies Integrability"
msgstr ""

#: Game.Levels.L6Levels.L01_SplitAnds
msgid "The `split_ands` tactic breaks apart \\\"and\\\" Goals into individual pieces. If your goal is `h₁ ∧ h₂ ∧ h₃`, then calling `split_ands` will break that into three separate goals, the first being\n"
"`h₁`, the second `h₂`, and of course `h₃`."
msgstr ""

#: Game.Levels.L1RealAnalysisStory.L02_rfl
msgid "Every mathematical expression equals itself."
msgstr ""

#: Game.Levels.L17Levels.L01
#: Game.Levels.L17Levels.L02
msgid "The series `∑ k, 1 / ((k + 1) * (k + 2))` converges."
msgstr ""

#: Game.Levels.L10Levels.L06_Prod
msgid "If sequences `a b : ℕ → ℝ` converge with `a` going to `L ≠ 0` and `b` going to `M ≠ 0`, then `a n * b n` converges to `L * M`."
msgstr ""

#: Game.Levels.L7Levels.L00_Uniqueness
msgid "To give a proof by contradiction, the syntax is : `by_contra h`, which adds a hypothesis with the name `h` (or whatever you want), which is the negation of the current Goal, and changes the goal to `false`."
msgstr ""

#: Game.Levels.L9PsetIntro
msgid "# Problem Set 9\n"
"\n"
"Good luck!"
msgstr ""

#: Game.Levels.L22Levels.L03
msgid "`(f : ℝ → ℝ) (a b : ℝ) (I : ℝ) := SeqLim (fun N ↦ RiemannSum f a b N) I`\n"
"\n"
"A function `f : ℝ → ℝ` has integral `I` from `a` to `b` if the sequence of Riemann sums converges to `I`."
msgstr ""

#: Game.Levels.L23Levels.L03
msgid "An element `x` is in the union of sets `s i` if and only if there exists an index `i` such that `x` is in `s i`."
msgstr ""

#: Game.Levels.L21Lecture
msgid "# Lecture 21: Function Limits II"
msgstr ""

#: Game.Levels.L1RealAnalysisStory.L03_rw
msgid "# Rewriting with equalities\n"
"\n"
"Now let's learn about rewriting. Suppose you have a hypothesis called `Bob : x = 2`, and your goal is to prove that `x + y = 2 + y`.\n"
"\n"
"Can you use `rfl`? No, because the two sides of the goal (`x + y` and `2 + y`) are not *identically* the same.\n"
"\n"
"Can you use `apply Bob`? No, because `Bob` says `x = 2`, which is not what the goal is asking for.\n"
"\n"
"But you can use the hypothesis `Bob` to *rewrite* the goal. Since `Bob` tells us that `x = 2`, we can replace `x` with `2` in our goal.\n"
"\n"
"In Lean, if you have a hypothesis which is an equality, and you want to replace the *left hand side* of that equality with the *right hand side* in your goal, you use the `rewrite` tactic. The syntax is:\n"
"\n"
"`rewrite [hypothesis_name]`\n"
"\n"
"Unfortunately, those square brackets are part of the Lean syntax, and there's nothing you or I can do about them right now. Just remember: `rewrite [Bob]` means \"use the equality in `Bob` to rewrite the goal.\"\n"
"\n"
"After you rewrite, you're not done. But you should know how to finish from there.\n"
"\n"
"Try it out!"
msgstr ""

#: Game.Levels.L6Levels.L02_LeftRight
msgid "Left and Right"
msgstr ""

#: Game.Levels.L20Pset.L01
msgid "# Level 1: ContinuousIff I\n"
"\n"
"Prove the forward direction: If a function is continuous at `x=c`,\n"
"then its limit at `x=c` exists and is equal to `f c`."
msgstr ""

#: Game.Levels.L16Pset.L16Pset1
msgid "# Problem 1: Finite geometric series"
msgstr ""

#: Game.Levels.L16Levels.L01_check
msgid "If a series converges, then the terms go to zero"
msgstr ""

#: Game.Levels.L1RealAnalysisStory.L05_use
msgid "# Proving existence\n"
"\n"
"Sometimes in mathematics, you need to prove that something exists. For example, suppose I wanted to ask you what the binomial coefficient in front of $x^2y^2$ is\n"
"in the expansion of $(x+y)^4$; how would I do it? Lean can't ask questions,\n"
"it can only prove theorems! So the way I would ask this is:\n"
"  prove that there exists a real number $c$ such that\n"
"\n"
"  $(x+y)^4 = x^4 + 4x^3y + cx^2y^2 + 4xy^3 + y^4$.\n"
"\n"
"  The way to prove that such a number\n"
"  exists is to exhibit it, that is, tell me which number to *use*,\n"
"  and then prove that that number indeed satisfies the equation.\n"
"\n"
"This is called an *existential statement*. In Lean, as in mathematics,\n"
"existence is written using `∃` (read: \"there exists\").\n"
"This symbol is called the *existential quantifier*, and is written in Lean by typing \\exists, that is, a backslash, then the word `exists`, and then a space.\n"
"So this goal would look in Lean like so:\n"
"\n"
"`∃ (c : ℝ), (x + y)^4 = x^4 + 4*x^3*y + c*x^2*y^2 + 4*x*y^3 + y^4`\n"
"\n"
"To prove an existence statement, you need to provide a specific value that works. This is where the `use` tactic comes in.\n"
"\n"
"If you think you know what value of `c` would work, you can write `use 42` (or with `42` replaced by whatever number you think is right). Lean will then substitute that value and ask you to prove that the resulting equation is true.\n"
"\n"
"Try writing `use`, then a space, and then a number. Do you see what to do after that?"
msgstr ""

#: Game.Levels.L23Levels.L02
msgid "`(f : ℝ → ℝ) (S : Set ℝ) :=\n"
"  ∀ ε > 0, ∃ δ > 0, ∀ x ∈ S, ∀ y ∈ S, |y - x| < δ → |f y - f x| < ε`\n"
"\n"
"For any `ε > 0`, there exists a `δ > 0` such that for all `x, y ∈ S`, if `|x - y| < δ`, then `|f x - f y| < ε`."
msgstr ""

#: Game.Levels.L18Levels.L02
msgid "If `a : ℕ → ℝ` is `Antitone` and `∀ n, 0 ≤ a n`, then the even alternating series `n ↦ ∑ k ∈ range (2n), (-1)^k * a k` is `Monotone`."
msgstr ""

#: Game.Levels.L23Levels.L02
msgid "# A Major Milestone!\n"
"\n"
"Congratulations! You've just proved one of the fundamental theorems of real analysis: **uniformly continuous functions are integrable**.\n"
"\n"
"**What Makes This Proof Beautiful**:\n"
"- **The Cauchy Strategy**: Instead of guessing what the integral should be, we proved convergence by showing the Riemann sum sequence is Cauchy. This is a powerful technique that works even when you don't know the limit in advance.\n"
"- **The Common Multiple Trick**: The key insight was using `m * n` as an intermediate step to compare Riemann sums with `m` and `n` partitions. This transformed a seemingly difficult comparison into two applications of your Level 1 theorem.\n"
"- **The ε/2 Split**: Dividing the tolerance in half and applying the triangle inequality is a classic move in analysis that you'll see again and again.\n"
"\n"
"**The Historical Context**: This result was crucial for putting Riemann's theory of integration on solid foundations. Riemann himself understood this intuitively, but the rigorous proof required careful attention to uniform continuity - a concept that wasn't fully formalized until later.\n"
"\n"
"**What's Still Missing**: We've shown that *uniformly* continuous functions are integrable, but when is a continuous function *uniformly* continuous? The answer involves one of the most important concepts in mathematics: **compactness**.\n"
"\n"
"**Looking Ahead**: In Level 3, we'll prove that continuous functions on compact sets (like closed intervals `[a,b]`) are automatically uniformly continuous. Combined with today's result, this will show that *every* continuous function on `[a,b]` is integrable - the foundation of calculus!\n"
"\n"
"This is why topology matters for analysis: the 'right' topological framework (compactness) makes analytical problems (integration) much more tractable."
msgstr ""

#: Game.Levels.L1Pset.L1Pset2
msgid "The `have` tactic has the following\n"
"syntax: `have NewHypothesisName (Assumptions) : Claim := by GiveTheProof`.\n"
"This creates a new hypothesis called\n"
"`NewHypothesisName : ∀ (Assumptions), ClaimHolds`."
msgstr ""

#: Game.Levels.L9Levels.L04_FiniteSums
msgid "If `a : ℕ → X` (where `X` could be `ℚ` or `ℝ`) is a sequence, then any term `|a n|`\n"
"for `n < N` is less than the sum of all the terms for `n = 0` to `N - 1`."
msgstr ""

#: Game.Levels.L14Lecture
msgid "Lecture 14: Bolzano-Weierstrass"
msgstr ""

#: Game.Levels.L14Levels.L01_BolzanoWeierstrass
msgid "`|x| ≤ y ↔ -y ≤ x ≤ y`"
msgstr ""

#: Game.Levels.L6Levels.L02_LeftRight
msgid "When your goal is to prove an \\\"Or\\\" statement, `P ∨ Q`, you can do that by proving either `P` or `Q`. If you want to prove `Q`, then say `right`, and the Goal will turn into `Q`."
msgstr ""

#: Game.Levels.L18Pset.L09
msgid "Prove `BddSeriesOdd`"
msgstr ""

#: Game.Levels.L2Pset.L2Pset2
msgid "# Problem 2\n"
"\n"
"Do the same for the exponent $3/2$. Find constants `c`, `d`, and `e` so that:\n"
"\n"
"$(1 + \\frac32 x + c \\cdot x^2 + d \\cdot x^3 + e \\cdot x^4)^2 - (1 + x) ^ 3$\n"
"\n"
"has only terms of degree five or higher.\n"
"\n"
"Hint: when you have multiple existential quantifiers, you can just write a single `use`\n"
"and separate the answers by a comma, like so: `use 6, 7, 42` (in place of: `use 6`, then `use 7`, then `use 42`)."
msgstr ""

#: Game.Levels.L13PsetIntro
msgid "Pset 13"
msgstr ""

#: Game.Levels.L15Lecture
msgid "# Lecture 15: The Real Numbers\n"
"\n"
"**SIMPLICIO:** Ok, *now* can you tell me what the real numbers, `ℝ`, actually are?\n"
"\n"
"**SOCRATES:** Almost. First: what are the integers, `ℤ`?\n"
"What \"problem\" are the integers trying to solve?\n"
"\n"
"**SIMPLICIO:** Hmm... Subtraction?\n"
"\n"
"**SOCRATES:** Very good! Yes, in fact, in Lean, do you know what `3 - 7` is?\n"
"\n"
"**SIMPLICIO:** I'm guessing it's not `-4`, since that's not a natural number.\n"
"You've already told me that functions are \"total\", so if `3 : ℕ` is a natural number\n"
"and `7 : ℕ` is a natural number, then `3 - 7` will also be a natural number. So I don't know, is it ... `0`?\n"
"\n"
"**SOCRATES:** Yep! In Lean, `3 - 7 = 0`. So the \"theorem\" that `N - 7 + 7 = N` is **literally False**! When `N = 3`, we get:\n"
"\n"
"`3 - 7 + 7 = (3 - 7) + 7 = 0 + 7 = 7 ≠ 3`\n"
"\n"
"So we have to fix subtraction. Here's one way to do it, one \"model\" for `ℤ`:\n"
"\n"
"I want to think of `ℤ` as differences of naturals (but done properly this time); so let's start with `ℕ × ℕ`, just a pair of natural numbers.\n"
"\n"
"**SIMPLICIO:**\n"
"Ok, and I guess what you're saying is that I'm supposed to imagine a pair `(m, n) : ℕ × ℕ` as representing the integer `m - n`?\n"
"\n"
"**SOCRATES:**\n"
"Yes but\n"
"I don't want you to\n"
" literally write `m - n`,\n"
" since that doesn't have the right \"meaning\" (yet). Just keep the pair `(m, n)`.\n"
"What should addition look like on `ℕ × ℕ` so that it \"represents\" what we think of as integer addition, but in this model?\n"
"\n"
"\n"
"**SIMPLICIO:**  Hmm...\n"
"You're saying that if we're given, say, `(7, 2)`, which represents the integer `7 - 2 = 5`, and `(4, 8)`, which is meant to represent the integer `4 - 8 = -4`, then I want to define an operation `+ : (ℕ × ℕ) → (ℕ × ℕ) → (ℕ × ℕ)` representing addition. Ah! Why not just add the components? Then\n"
"\n"
"`(7, 2) + (4, 8) = (7 + 4, 2 + 8) = (11, 10)`\n"
"\n"
"which, in our mental model, is supposed to mean `11 - 10 = 1 = 5 + (-4)`. It works!\n"
"\n"
"**SOCRATES:**\n"
"Great! You see why this works right? Ok, so what operation should we try to construct next?\n"
"\n"
"\n"
"**SIMPLICIO:**\n"
"How about multiplication?\n"
"\n"
"\n"
"**SOCRATES:**\n"
"Sure, go for it!\n"
"\n"
"**SIMPLICIO:**\n"
"I have a feeling this won't be quite as simple. Oh, wait, no, I just have to do a little calculation first in my model. To multiply `(a, b)` by `(c, d)`, I should multiply `(a - b) * (c - d) = a * c - b * c - a * d + b * d`. Ah, I've got it; group the plusses and the minuses!\n"
"\n"
"`(a, b)` \" `×` \" `(c, d)` should be defined as: `(a * c + b * d, a * d + b * c)`\n"
"\n"
"Hey, this is fun!\n"
"\n"
"**SOCRATES:**\n"
"I'm glad to hear it. But wait, I wanted to talk about another operation on `ℤ`, the one you can't do \"properly\" in `ℕ`...\n"
"\n"
"**SIMPLICIO:**\n"
"Ah, sorry, subtraction.\n"
"\n"
"**SOCRATES:**\n"
"There's no such thing! :)\n"
"\n"
"**SIMPLICIO:**\n"
"Huh? Of course there is. But obviously you're trying to get me to say something... Oh, I see! If you have addition and **negation**, then you have subtraction. So subtraction is not a \"fundamental\" operation, it's merely the combination of two other operations. So we need to define negation?\n"
"\n"
"**SOCRATES:**\n"
"You've got it! Nu?\n"
"\n"
"**SIMPLICIO:**\n"
"What should the negation of `a - b` be? Easy! `b - a`. Oh, so *that's* the operation, just switch the entries!\n"
"\n"
"\"`-`\" `(a, b) = (b, a)`\n"
"\n"
"Nice!\n"
"\n"
"**SOCRATES:** Indeed.\n"
"I'm sure that at this point, you could carry on like this, working out all the usual properties, commutativity, associativity, distribution, etc, just from the properties you already know about the natural numbers and their operations. But I want to move on to the real numbers. There's just one problem with your model of the integers.\n"
"\n"
"**SIMPLICIO:**\n"
"Oh?\n"
"\n"
"**SOCRATES:**\n"
"There's **too many of them**. What could I mean by that?\n"
"\n"
"**SIMPLICIO:**\n"
"Oh, I see... The pair `(7, 2)` represents `5`, but so does the pair `(8, 3)`, and `(5, 0)`, and infinitely many others. So what are we supposed to do?\n"
"\n"
"**SOCRATES:**\n"
"It turns out that it's not too difficult to solve this problem. We simply declare two pairs `(a, b)` and `(c, d)` to be \"the same\" (mathematicians would say \"equivalent\", and write `(a, b) ≈ (c, d)`) if their difference is zero. Lean's flexible handling of equality allows us to do this!\n"
"\n"
"**SIMPLICIO:**\n"
"Oooooh cool! So wait, we're just going to say that the pair `(a, a)`, for any natural number `a`, *is* zero? And then two pairs `(a, b)` and `(c, d)` are \"equivalent\"\n"
"if:\n"
"\n"
"`(a, b) - (c, d) = (a, b) + (d, c) = (a + d, b + c)`\n"
"\n"
"has two equal entries, that is, when `a + d = b + c`?\n"
"\n"
"**SOCRATES:**\n"
"Yes, exactly! Technically, we have to check a few things. This operation of calling things equivalent needs to be an \"equivalence relation\". This means that three conditions are satisfied:\n"
"\n"
"- reflectivity: `x ≈ x` for any `x : ℕ × ℕ`,\n"
"- symmetry: `x ≈ y` if and only if `y ≈ x`, and\n"
"- transitivity: `x ≈ y` and `y ≈ z` implies that `x ≈ z`.\n"
"\n"
"I'll let you check on your own that those hold for our notion of equivalence, `(a, b) ≈ (c, d)` if and only if `a + d = b + c`.\n"
"\n"
"So finally, here's our \"official\" definition of the integers: they're the \"equivalence classes\" of `ℕ × ℕ` under the \"relation\" `≈`.\n"
"\n"
"Pretty cool, huh?\n"
"\n"
"\n"
"**SIMPLICIO:**\n"
"Yes! But wait... We had defined addition on *pairs* `(a, b) + (c, d) = (a + c, b + d)`. But you're saying the integers are actually equivalence *classes* of pairs. So which pair in the equivalence class should I use when I compute a sum?\n"
"\n"
"**SOCRATES:**\n"
"Excellent question! What do you think we should do?\n"
"\n"
"**SIMPLICIO:** Hmm...\n"
"Well, ideally it shouldn't *matter* which representative I pick from each equivalence class. The answer should come out the same either way. Otherwise the whole construction would be ambiguous!\n"
"\n"
"**SOCRATES:**\n"
"Very good! So what does that mean, precisely?\n"
"\n"
"**SIMPLICIO:**\n"
"Let me think... Suppose I have two pairs `(a, b)` and `(a', b')` that represent the same integer, so `(a, b) ≈ (a', b')`. And suppose I have another two pairs `(c, d)` and `(c', d')` that also represent the same integer, so `(c, d) ≈ (c', d')`.\n"
"\n"
"Then I need to check that when I add them:\n"
"\n"
"`(a, b) + (c, d)` should be equivalent to `(a', b') + (c', d')`\n"
"\n"
"Otherwise, the \"sum\" would depend on which representatives I chose, which would be a disaster!\n"
"\n"
"**SOCRATES:**\n"
"Exactly! This is what mathematicians call \"well-definedness\". Can you verify that this actually holds for our definition of addition?\n"
"\n"
"**SIMPLICIO:**\n"
"Let me try... So I'm assuming that `(a, b) ≈ (a', b')`, which means `a + b' = b + a'`. And I'm assuming that `(c, d) ≈ (c', d')`, which means `c + d' = d + c'`.\n"
"\n"
"Now, we can calculate that `(a, b) + (c, d) = (a + c, b + d)` and `(a', b') + (c', d') = (a' + c', b' + d')`.\n"
"\n"
"For these to be equivalent, I need that: `(a + c) + (b' + d') = (b + d) + (a' + c')`.\n"
"\n"
"Let me rearrange the left side: `(a + c) + (b' + d') = a + b' + c + d'`.\n"
"\n"
"And the right side: `(b + d) + (a' + c') = b + a' + d + c'`.\n"
"\n"
"But wait! From my assumptions, I have `a + b' = b + a'` and `c + d' = d + c'`. So:\n"
"\n"
"`a + b' + c + d' = (a + b') + (c + d') = (b + a') + (d + c') = b + a' + d + c'`\n"
"\n"
"They're equal! So addition really is well-defined.\n"
"\n"
"**SOCRATES:**\n"
"Excellent work! And of course, you'd need to verify the same property for multiplication and negation. In Lean, when you \"lift\" an operation from `ℕ × ℕ` to the quotient `ℤ`, you must provide exactly this kind of proof that the operation respects the equivalence relation.\n"
"\n"
"**SIMPLICIO:**\n"
"That's great. So ... what does any of this have to do with the real numbers?\n"
"\n"
"**SOCRATES:**\n"
"Well, remember how we proved that if you have a sequence that's bounded (from above and below), then it has a subsequence that's Cauchy?\n"
"\n"
"**SIMPLICIO:**\n"
"Yeah, Bolzano-Weierstrass. So what?\n"
"\n"
"**SOCRATES:**\n"
"And I kept dropping pretty big hints that a sequence being Cauchy was going to be equivalent to being convergent? (In fact, we proved one direction: if a sequence converges, then it's Cauchy.)\n"
"\n"
"**SIMPLICIO:**\n"
"Yeah??\n"
"\n"
"**SOCRATES:**\n"
"So all that's left is to prove that if a sequence is Cauchy, then it converges to a real number.\n"
"\n"
"\n"
"**SIMPLICIO:**\n"
"Yeah???\n"
"\n"
"**SOCRATES:**\n"
"Ok, so here it is, here's the definition. This is your last chance. Take the blue pill and the real numbers go back to being a number line, and everything is honky-dory. Take the red pill, and there's no turning back; you'll never see the real numbers the same way again.\n"
"\n"
"**SIMPLICIO:**\n"
"Oh would you just get on with it already!\n"
"\n"
"**SOCRATES:**\n"
"Fine, sorry; just trying to build up some suspense.\n"
"\n"
"**SIMPLICIO:**\n"
"Yes, I noticed.\n"
"\n"
"**SOCRATES:** Ok.\n"
"So the reason that Cauchy sequences converge to real numbers is ... that:\n"
"\n"
"Cauchy sequences **are** real numbers!!!\n"
"\n"
"**SIMPLICIO:**\n"
"No duh, you telegraphed that from like a mile away.\n"
"\n"
"**SOCRATES:**\n"
"You're ... completely unimpressed?\n"
"\n"
"**SIMPLICIO:** Completely.\n"
"\n"
"\n"
"**SOCRATES:**\n"
"Hm, ok, fine. But... do you really get it?\n"
"\n"
"**SIMPLICIO:**\n"
"What's not to get? You're saying that real numbers are Cauchy sequences.\n"
"I even remember our discussion of how we want real numbers to be limits of rational\n"
"sequences, but the way we defined limits presumed the existence of real numbers.\n"
"That was our rationale for defining Cauchy sequences in the first place.\n"
"It all works,\n"
"I get it.\n"
"\n"
"**SOCRATES:**\n"
"Well, that's *almost* right.\n"
"\n"
"**SIMPLICIO:**\n"
"Ok, so what's wrong?\n"
"\n"
"**SOCRATES:**\n"
"You tell me.\n"
"\n"
"**SIMPLICIO:** ... Well, ok...\n"
"Hmm... You told me a whole long story about `ℤ` and `ℕ × ℕ`. You were probably trying to\n"
"set something up. Oh, wow. Now I see it. Wow, that's ... SO cool!\n"
"\n"
"**SOCRATES:**\n"
"What is it, what do you see?\n"
"\n"
"**SIMPLICIO:**\n"
"There are **too many** Cauchy sequences!! Kind of like how there were too many elements\n"
"of `ℕ × ℕ`. I could have lots of *different* rational sequences all being Cauchy and converging to the same real number, and I wouldn't want to call them different real numbers. So what do we do?\n"
"\n"
"**SOCRATES:**\n"
"Yes?\n"
"\n"
"**SIMPLICIO:**\n"
"We say that Cauchy sequences are \"the same\"...\n"
"\n"
"**SOCRATES:**\n"
"You mean \"equivalent\"\n"
"\n"
"**SIMPLICIO:** ... yeah, whatever,\n"
"equivalent, if their limit is the same real number!\n"
"\n"
"**SOCRATES:**\n"
"Whoops, you did it again! You can't use real numbers to define real numbers!!\n"
"\n"
"**SIMPLICIO:**\n"
"Argh, right. Now I really see it. We just subtract the two Cauchy sequences.\n"
"There's one real number that we know for sure: ZERO!!!\n"
"\n"
"So: two Cauchy sequences are *equivalent* if their difference (which we proved is also a Cauchy sequence) converges to Zero (which is a number we **know**, so we can easily speak of a sequence having limit zero)!\n"
"\n"
"**SOCRATES:**\n"
"Now you've got the whole picture. The real numbers are:\n"
"\n"
"Equivalence classes of Cauchy sequences of rational numbers.\n"
"\n"
"**SIMPLICIO:**\n"
"Well, why didn't you just say so from the beginning! :)\n"
"\n"
"**SOCRATES:**\n"
"I guess maybe I should have.\n"
"Hey, remember when we proved that the sum of two Cauchy sequences was Cauchy?\n"
"\n"
"**SIMPLICIO:**\n"
"Yeah?\n"
"\n"
"**SOCRATES:**\n"
"Any guesses what that means?\n"
"\n"
"**SIMPLICIO:**\n"
"Oh! So we get all the operations on the real numbers *from* the operations we proved about Cauchy sequences! So cool! You just add two Cauchy sequences term by term, and get another. As you just explained, we'd have to check that this is \"well-defined\",\n"
"so that if you took two other Cauchy sequences that differ from our original two by sequences going to zero, then the limit also differs by a sequence going to zero. I think I could work out all the details pretty easily.\n"
"\n"
"\n"
"**SOCRATES:**\n"
"Wonderful, you've really got it now! Hey, remember all those headaches with casting between natural numbers and reals? What do you think that was all about?\n"
"\n"
"**SIMPLICIO:**\n"
"Oh, I see! Since, unlike us humans, Lean can't \"cheat\", it *literally* has to go through all the motions we just described! So say you start with a natural number like `3`, which I remember is secretly `succ (succ (succ zero))`. To get to the real numbers, I'm guessing you\n"
"first have to coerce `3 : ℤ`, which, as we just saw, means something like creating the\n"
"pair `(3, 0)` in `ℕ × ℕ` (or anything else equivalent to it). Then we have to send\n"
"`(3, 0)` up to the rationals, which are probably something like `ℤ × ℕ` where the first\n"
"factor is supposed to be the numerator and the second is the denominator, and you have to worry about dividing by zero and equivalent fractions and so on and so forth. So as a rational number, I should really think of `3 : ℚ` as having turned into a fraction `3/1`. And finally,\n"
"to send that up to the reals, I need to make a Cauchy sequence that converges to `3`.\n"
"But that's easy, I just make the constant sequence! So that's what all those annoying\n"
"up arrows mean!!! The map `↑ : ℕ → ℝ` works like this:\n"
"\n"
"`↑ : ℕ → ℝ : 3 ↦ (3/1, 3/1, 3/1, 3/1, 3/1, ...)`\n"
"\n"
"That is truly amazing, it all really works!\n"
"\n"
"\n"
"**SOCRATES:**\n"
"It sure does :) I bet that you would now like to take back all those times\n"
"you cursed at Lean for making you handle casting explicitly; maybe now you're\n"
"actually *grateful* that it's as good as it is, for being able to do all\n"
"these incredibly complicated maneuvers (almost) seamlessly under the hood! Anyway. You know what's even more amazing?\n"
"\n"
"**SIMPLICIO:**\n"
"What?\n"
"\n"
"**SOCRATES:**\n"
"This construction we just did -- taking Cauchy sequences and quotienting by the equivalence\n"
"relation -- is completely general! It works for *any* metric space (whatever that is), not\n"
"just the rationals.\n"
"\n"
"**SIMPLICIO:**\n"
"Wait, really?\n"
"\n"
"**SOCRATES:**\n"
"Yes! Given any space that has a notion of distance, so you can say what it means to be a Cauchy sequence,\n"
" you can \"complete\" it by taking equivalence classes of Cauchy sequences. The rationals with the usual absolute value metric give you the real numbers `ℝ`.\n"
" But if you take the rationals with a different metric -- say, the \"`p`-adic metric\" (whatever that is) -- you get the `p`-adic numbers `ℚₚ`!\n"
"\n"
"**SIMPLICIO:**\n"
"So the same construction gives you completely different number systems just by changing the metric?\n"
"\n"
"**SOCRATES:**\n"
"Exactly! And it's not just number systems. Any metric space can be completed this way. If you start with,\n"
"say, the space of continuous functions on an interval (with an appropriate metric), you get what's called a \"Banach space\". If you start with the space of Riemann-integrable functions, you get a Lebesgue space.\n"
"These all have completions in **exactly** the same way.\n"
"The construction is everywhere in all of mathematics!\n"
"\n"
"If you want to see a little bit more about what these `p`-adic numbers are about, you're welcome to\n"
"watch this Veritasium video (right-click the link so it pops out and you don't lose your place in the game):\n"
"\n"
"[![Veritasium Video](https://img.youtube.com/vi/tRaq4aYPzCc/hqdefault.jpg)](https://youtu.be/tRaq4aYPzCc)\n"
"\n"
"Now let's keep playing."
msgstr ""

#: Game.Levels.L12Levels.L01_MonotoneBdd
msgid "If `a n ≤ a (n+1)` holds for all `n`, then `a` is `Monotone`."
msgstr ""

#: Game.Levels.L20Pset.L02
msgid "# Level 2: ContinuousIff II\n"
"\n"
"Prove the backwards direction: If the limit at `x=c` of `f` exists and is equal to `f c`, then `f` is continuous at `x=c`."
msgstr ""

#: Game.Levels.L23Levels.L03
msgid "# The Grand Synthesis!\n"
"\n"
"You've just completed one of the most beautiful proofs in mathematics! You've shown that **continuity + compactness = uniform continuity**.\n"
"\n"
"**What Makes This Proof Extraordinary**:\n"
"- **Local to Global**: You started with local information (continuity at each point) and used compactness to extract global information (uniform continuity everywhere)\n"
"- **Infinite to Finite**: The proof converts an infinite covering problem into a finite one, where you can actually compute minima\n"
"- **Abstract to Concrete**: You used the abstract concept of compactness to solve the concrete problem of finding a uniform δ\n"
"\n"
"**The Complete Picture**: Combining all three levels, you've now proved the fundamental chain:\n"
"\n"
"`Continuous on [a,b] → Uniformly Continuous on [a,b] → Integrable on [a,b]`\n"
"\n"
"**Why This Matters Historically**:\n"
"- **Riemann** (1850s) defined integration but couldn't rigorously prove when it worked\n"
"- **Cauchy** earlier made errors by missing the uniformity requirement\n"
"- **Heine-Borel** (1890s-1900s) finally clarified compactness\n"
"- **Lebesgue** (1900s) built on these foundations for modern integration theory\n"
"\n"
"**The Topological Revolution**: Before topology, mathematicians did analysis with intuition and clever tricks. Compactness gave them the 'right' framework to make rigorous arguments. This is why closed bounded intervals `[a,b]` are so special in calculus - they're exactly the compact sets in `ℝ`!\n"
"\n"
"**Real-World Impact**: Every time you compute `∫₀¹ f(x)dx` in calculus and trust that it exists, you're using today's theorem. Every continuous function on `[0,1]` is integrable because `[0,1]` is compact!\n"
"\n"
"**Looking Forward**: You've seen how topology (compactness) illuminates analysis (integration). This pattern repeats throughout mathematics - the 'right' abstract framework often makes concrete problems much clearer. Welcome to the power of mathematical abstraction!"
msgstr ""

#: Game.Levels.L11Levels.L01_IsCauchyOfLim
msgid "`(a : ℕ → X) : Prop := ∀ (ε : X), 0 < ε → ∃ N : ℕ, ∀ n ≥ N, ∀ m ≥ n, |a m - a n| < ε`\n"
"\n"
"For a sequence `a : ℕ → X` (where `X` could be `ℚ` or `ℝ`) is said to satisfy `IsCauchy` (that is, the sequence \\\"is Cauchy\\\") if: for every `ε > 0`, there exists `N : ℕ` such that for all `n ≥ N` and `m ≥ n`, we have `|a m - a n| < ε`."
msgstr ""

#: Game.Levels.L25Levels.L01
msgid "# Level 1: Uniform Convergence Implies Integrability\n"
"\n"
"We finally prove the fundamental theorem that justifies Newton's bold term-by-term integration of infinite series! If a sequence of integrable functions `fₙ` converges uniformly to `F`, then `F` is also integrable, and crucially:\n"
"\n"
"$$\\int F = \\lim (\\int fₙ)$$\n"
"\n"
"or equivalently: $$\\int(\\lim fₙ) = \\lim (\\int fₙ)$$\n"
"\n"
"This theorem is the rigorous foundation behind Newton's calculation from Lecture 2, where he integrated the binomial series term-by-term to compute π.\n"
"\n"
"**Why uniform convergence?** As Socrates showed with his examples, pointwise convergence alone fails spectacularly:\n"
"- Step functions shifting to infinity: `∫ fₙ = 1` but `∫(lim fₙ) = 0`\n"
"- Spike functions on `[0,1]`: `∫ fₙ = 1` but `∫(lim fₙ) = 0`\n"
"- Even continuous tent functions: `∫ fₙ = 1` but `∫(lim fₙ) = 0`\n"
"\n"
"The key insight is that uniform convergence gives us simultaneous control over all function values. If `|fₙ(x) - F(x)| < ε/(b-a)` for all `x` and large `n`, then Riemann sum differences are bounded by `ε`, allowing us to interchange limits and integrals.\n"
"\n"
"**Remarkable fact**: We assume *nothing* about continuity! Integrability is strictly weaker than continuity, yet suffices for this profound result.\n"
"\n"
"This theorem bridges the gap between finite and infinite processes, making rigorous what Newton intuited centuries ago."
msgstr ""

#: Game.Levels.L6Levels.L01_SplitAnds
msgid "# Level 2: Split Ands - Breaking Down Complex Goals\n"
"\n"
"Now that you've conquered the Big Boss and proven that sums of convergent sequences converge, you've experienced firsthand how mathematical proofs often require us to establish multiple related facts simultaneously. In our previous proof, we needed to show that both individual sequences satisfied their epsilon conditions, and then combine these results.\n"
"\n"
"This pattern -- needing to prove several statements at once -- appears constantly in mathematics. Fortunately, Lean provides us with powerful tools to handle such situations elegantly. When your goal involves proving multiple statements connected by \"and\" (`∧`), the `split_ands` tactic becomes your best friend.\n"
"\n"
"Think of `split_ands` as a way to break down a complex manufacturing specification into individual quality checks. Instead of trying to verify that a product meets three different standards all at once, we can tackle each standard separately and systematically.\n"
"\n"
"## New Tools You'll Need\n"
"\n"
"- `split_ands`\n"
"\n"
"The `split_ands` tactic breaks apart \"and\" Goals into individual pieces. If your goal is `h₁ ∧ h₂ ∧ h₃`, then calling `split_ands` will break that into three separate goals, the first being\n"
"`h₁`, the second `h₂`, and of course `h₃`"
msgstr ""

#: Game.Levels.L20Levels.L03
msgid "# Level 3: Sum of Continuous Functions\n"
"\n"
"One of the most powerful aspects of continuity is that it behaves well with respect to algebraic operations. Let's prove our first **continuity theorem**: the sum of continuous functions is continuous!\n"
"\n"
"## The Theorem\n"
"\n"
"**Theorem:** If `f` and `g` are both continuous at `c`, then `f + g` is continuous at `c`.\n"
"\n"
"This seems intuitive: if `f(x)` stays close to `f(c)` and `g(x)` stays close to `g(c)` when `x` is near `c`, then their sum should stay close to `f(c) + g(c)`.\n"
"\n"
"## The Strategy: The `ε/2` Trick\n"
"\n"
"Given `ε > 0`, we want to make `|(f + g)(x) - (f + g)(c)| < ε`.\n"
"\n"
"Notice that:\n"
"\n"
"`|(f + g)(x) - (f + g)(c)| = |f(x) + g(x) - f(c) - g(c)|`\n"
"\n"
"`                           = |[f(x) - f(c)] + [g(x) - g(c)]|`\n"
"\n"
"`                           ≤ |f(x) - f(c)| + |g(x) - g(c)|`\n"
"\n"
"So if we can make each term less than `ε/2`, their sum will be less than `ε`!\n"
"\n"
"Since `f` is continuous at `c`, there exists `δ₁ > 0` such that `|x - c| < δ₁` implies `|f(x) - f(c)| < ε/2`.\n"
"\n"
"Since `g` is continuous at `c`, there exists `δ₂ > 0` such that `|x - c| < δ₂` implies `|g(x) - g(c)| < ε/2`.\n"
"\n"
"Taking `δ = min δ₁ δ₂` ensures both conditions hold simultaneously!\n"
"\n"
"## Your Challenge\n"
"\n"
"Prove that if `f` and `g` are continuous at `c`, then their sum is continuous at `c`:\n"
"\n"
"`FunContAt f c → FunContAt g c → FunContAt (fun x ↦ f x + g x) c`\n"
"\n"
"**Hint:** After introducing `ε` and `hε`, use the hypotheses `hf` and `hg` with `ε/2` to choose `δ₁` and `δ₂`. Then `use min δ₁ δ₂`. You'll need to show this is positive and that it works. The triangle inequality and `bound` will be your friends!"
msgstr ""

#: Game.Levels.L24PsetIntro
msgid "Pset 24"
msgstr ""

#: Game.Levels.L7Lecture
msgid "Lecture 7: Algebraic Limit Theorem, Part III"
msgstr ""

#: Game.Levels.L15Levels.L01_check
msgid "Completeness"
msgstr ""

#: Game.Levels.L1Pset.L1Pset2
msgid "Did you end up using `huv`?\n"
"And then `specialize`ing it with `u` and `v` replaced, respectively, by `x` and `y`?\n"
"Or did you think of going via the more direct route:\n"
"`have hxy : (x + y) ^ 2 = (x ^ 2 + y ^ 2) + 2 * (x * y) := by ring_nf`?"
msgstr ""

#: Game.Levels.L7Levels.L03_SeqInvLim
msgid "SeqInvLim"
msgstr ""

#: Game.Levels.L20Levels.L02
msgid "## What We've Learned\n"
"\n"
"This example illustrates the key differences between limits and continuity:\n"
"\n"
"- **Continuity requires three things**: the function must be defined at the point, the limit must exist, and they must be equal\n"
"- Unlike limits, continuity cares about what happens **at** the point, not just near it\n"
"- The `ε`-`δ` definitions look similar, but the absence of `x ≠ c` makes all the difference\n"
"\n"
"### The Art of Choosing `δ`\n"
"\n"
"Notice our choice: `δ = min(1, ε/5)`. This is a classic technique!\n"
"\n"
"- **First component (`δ ≤ 1`)**: Restricts `x` to a neighborhood where we can bound `|x + 2|`\n"
"- **Second component (`δ ≤ ε/5`)**: Actually controls the error to be less than `ε`\n"
"\n"
"The key algebraic insight: `|f(x) - f(c)| = |x - 2| · |x + 2|`\n"
"\n"
"We can't just use `δ = ε` because of that extra factor `|x + 2|`. So we:\n"
"1. Use `δ ≤ 1` to ensure `|x + 2| < 5`\n"
"2. Use `δ ≤ ε/5` so that `|x - 2| · |x + 2| < (ε/5) · 5 = ε`\n"
"\n"
"**Key insight:** When proving continuity, factor the difference and bound each piece separately!\n"
"\n"
"This \"localize then control\" strategy is fundamental to `ε`-`δ` proofs. You'll see it again and again throughout analysis."
msgstr ""

#: Game.Levels.L18Pset.L03
msgid "# Level 3: `AntitoneLimitBound`\n"
"\n"
"Prove `AntitoneLimitBound`:"
msgstr ""

#: Game.Levels.L3Levels.L02_OneOverN
msgid "The `field_simp` tactic tries to clear denominators, if it can figure out that the denominators are non-zero (or in the case of inequalities, positive)."
msgstr ""

#: GameServer.RpcHandlers
msgid "intermediate goal solved! 🎉"
msgstr ""

#: Game.Levels.L12Levels.L01_Choose
msgid "# Level 2: Enhanced `Choose`\n"
"\n"
"Do you know the \"Twin Prime Conjecture\"?\n"
"A number `n : ℕ` is called a Twin Prime if both `n`\n"
"and `n+2` are prime numbers. Let's call this property\n"
"`p : ℕ → Prop`. So `p` is a function that takes a\n"
"natural number `n` and returns `p (n) = ` Yes/No, depending on whether `n` is a twin prime. The Twin Prime Conjecture says that there are infinitely many twin primes; that is, for any bound `N`, no matter how large,\n"
"there is always at least one `n > N` for which `p (n)` holds. We would state the conjecture like this:\n"
"\n"
"`h : ∀ N, ∃ n > N, p n`\n"
"\n"
"Now suppose that we have a hypothesis like this, for some abstract property `p` (if you like, you're welcome to keep thinking of `p n` as testing whether `n` is a twin prime). Given that there are arbitrarily large `n`'s for which `p n` holds, how do I get my hands on a subsequence `σ : ℕ → ℕ`, so that, along the subsequence, `p (σ n)` holds, for all `n`?\n"
"\n"
"The idea is that you should interpret `h` as a collection of **functions**. Given a natural number `N`,  the hypothesis `h` will produce a `n` for you, but that `n` is a function of `N`, so we should really write `n = n (N)`. But that's not all! The hypothesis `h` also contains a *proof* that `n (N) > N` for all `N`. Do you see why the statement of `h` implies\n"
"the existence of such a function? And lastly, `h` also gives us a proof of the fact that, for all `N`,\n"
"`p (n (N))` holds. So `n (N)` is (almost) our desired sequence! (Since it's funny to write `n (N)`, let's rename `n` to `τ`, so we can write `τ (N)`.) The way in Lean to go from `h` to these sequences is to invoke a familiar tactic: `choose`! If you write:\n"
"\n"
"`choose τ hτBnd hτP using h`\n"
"\n"
"then Lean will add to your goal state:\n"
"\n"
"`τ : ℕ → ℕ`\n"
"\n"
"`hτBnd : ∀ N, τ (N) > N`\n"
"\n"
"`hτP : ∀ N, p (N)`\n"
"\n"
"Isn't that cool?! Now you should be able to use the idea from the last level to make the desired subsequence `σ`,\n"
" but you'll need to think about how *exactly* to make it work..."
msgstr ""

#: Game.Levels.L23Levels.L03
msgid "Given an indexing type `ι`, a finite subset `V` of `ι`, and a function `δs : ι → ℝ` that assigns a positive real number to each index, there exists a positive real number `δ` such that for all indices `i` in the finite set `V`, `δ` is less than or equal to `δs i`."
msgstr ""

#: Game.Levels.L23Lecture
msgid "Lecture 23: Uniformity II: Continuity"
msgstr ""

#: Game.Levels.L24Levels.L01
msgid "Heine-Borel Theorem: Part 1a"
msgstr ""

#: Game.Levels.L1Pset.L1Pset2
msgid "If you're stuck at this point, let me remind you that, in a previous level, the Goal was: `∀ ε > 0, BlahBlah`, and\n"
"after `intro ε`, the Goal became `ε > 0 → BlahBlah`.\n"
"Then what did you do?..."
msgstr ""

#: Game.Levels.L20Levels.L02
msgid "# Level 2: Continuity at a Point\n"
"\n"
"Excellent work with limits! Now we can define one of the most important concepts in analysis: **continuity**.\n"
"\n"
"## The Definition\n"
"\n"
"**Definition (`FunContAt`):** We say that `f` is **continuous at** `c` if:\n"
"```\n"
"∀ ε > 0, ∃ δ > 0, ∀ x, |x - c| < δ → |f x - f c| < ε\n"
"```\n"
"\n"
"This is written `FunContAt f c`.\n"
"\n"
"## Continuity vs. Limits\n"
"\n"
"Notice the subtle but crucial differences from `FunLimAt`:\n"
"\n"
"1. **No `x ≠ c` condition:** We care about *all* x near c, including c itself\n"
"2. **The limit is `f c`:** The function value at c must match the limit as x approaches c; we don't need a separate variable name `L` for the limit, since `L` *must* be `f c`.\n"
"\n"
"In other words: **A function is continuous at c if its limit at c exists and equals f(c).**\n"
"\n"
"## Why This Matters\n"
"\n"
"The function `f(x) = (x² - 1)/(x - 1)` from the previous level had a limit at `x = 1`, but it's *not* continuous there (because `f(1) = 0 ≠ 2` in Lean's system).\n"
"\n"
"However, the function `g(x) = x² - 1` is continuous everywhere, including at `x = 2`!\n"
"\n"
"## Your Challenge\n"
"\n"
"Prove that the function `f(x) = x² - 1` is continuous at `x = 2`:\n"
"\n"
"`FunContAt (fun x ↦ x^2 - 1) 2`\n"
"\n"
"**Hint:** Given `ε > 0`, you need to find `δ > 0` such that `|x - 2| < δ` implies\n"
"`|f(x) - f(2)| < ε`.\n"
"\n"
"Note that `f(2) = 3` and `f(x) - f(2) = x² - 1 - 3 = x² - 4 = (x - 2)(x + 2)`.\n"
"\n"
"So `|f(x) - f(2)| = |x - 2| · |x + 2|`.\n"
"\n"
"If we restrict `x` to be within distance `1` of `2` (i.e., `1 < x < 3`), then `|x + 2| < 5`.\n"
"\n"
"Therefore, if we choose `δ = min(1, ε/5)`, we can control `|f(x) - f(2)|`!\n"
"\n"
"Try using `use min 1 (ε / 5)` and split into cases based on whether `|x - 2| < 1`."
msgstr ""

#: Game.Levels.L12Pset.L12Pset1
msgid "# Problem 1:\n"
"\n"
"In lecture, we proved `IsCauchy_of_MonotoneBdd`: if a sequence is `Monotone` and bounded (from above),\n"
"then it `IsCauchy`. Here you'll prove the same thing but going down: if a sequence is `Antitone` (that\n"
"is, non-increasing -- so decreasing but not necessarily strictly so; `i ≤ j → a j ≤ a i) and bounded\n"
"from *below*, then it's Cauchy.\n"
"\n"
"Theorem: `IsCauchy_of_AntitoneBdd`.\n"
"\n"
"## New definition: `Antitone`\n"
"\n"
"Hint: You don't need to reprove everything from scratch! I'll give you two tools:\n"
"\n"
"## New theorems:\n"
"\n"
"- `MonotoneNeg_of_Antitone`: if `a` is `Antitone`, then `-a` is `Monotone`.\n"
"\n"
"- `IsCauchyNeg`: if `IsCauchy a`, then so is `IsCauchy (-a)`."
msgstr ""

#: Game.Levels.L1RealAnalysisStory.L08_choose
msgid "Write `choose c hc using h`, then you should be able to finish it yourself."
msgstr ""

#: Game.Levels.L14Levels.L01_BolzanoWeierstrass
msgid "If a sequence `a : ℕ → X` (where `X` could be `ℚ` or `ℝ`) is bounded, then it has a subsequence which is Cauchy."
msgstr ""

#: Game.Levels.L17Levels.L04
msgid "If a sequence `a : ℕ → ℝ` is Cauchy, then it converges."
msgstr ""

#: Game.Levels.L15Lecture
msgid "Lecture 15: The Real Numbers"
msgstr ""

#: Game.Levels.L15Levels.L01_check
msgid "# Conclusion: The Reals Are Complete\n"
"\n"
"Congratulations! You've just proved one of the most fundamental theorems in real analysis: **the real numbers are complete**.\n"
"\n"
"## What We Accomplished\n"
"\n"
"We showed that any Cauchy sequence of real numbers converges to a real number. This means:\n"
"- We don't need to construct yet another number system beyond ℝ\n"
"- The completion process terminates: ℚ → ℝ → ... → ℝ (we're done!)\n"
"- Every \"should converge\" sequence in ℝ actually does converge in ℝ\n"
"\n"
"## The Beauty of the Construction\n"
"\n"
"The proof relied on a clever diagonal-inspired construction:\n"
"- Each real `xₙ` is secretly a Cauchy sequence of rationals (row `n` of our array)\n"
"- We extracted a **single** sequence `y` by sampling one rational from each row\n"
"- The key: we sampled row `k` at index `N(k)` where it had already converged to within `1/(k+1)` of its limit\n"
"- This ensured `y` itself was Cauchy, and that `y` captured the limit of the sequence of reals\n"
"\n"
"The technique—choosing convergence points rather than blindly taking the diagonal—is fundamental in analysis. You'll see variations of this argument in:\n"
"- Arzela-Ascoli theorem (equicontinuous families)\n"
"- Weak compactness arguments (functional analysis)\n"
"- Diagonal extraction arguments throughout measure theory\n"
"\n"
"## Why Completeness Matters\n"
"\n"
"Completeness is what makes analysis possible. Here's what we can now guarantee:\n"
"\n"
"**Closure under limits:** Take limits freely within ℝ without worrying about \"escaping\" the space.\n"
"\n"
"**Convergence of series:** Infinite sums `∑ aₙ` converge whenever their partial sums are Cauchy.\n"
"\n"
"**Fixed point theorems:** Contractions have fixed points, found by iterating `x₀, f(x₀), f(f(x₀)), ...`\n"
"\n"
"**Function construction:** Define `eˣ`, `sin(x)`, `cos(x)` as limits of sequences/series with confidence they converge.\n"
"\n"
"**Completeness + Archimedean + Ordered Field = ℝ:** Any mathematical structure with these properties is isomorphic to the real numbers. We've fully characterized ℝ!\n"
"\n"
"## The Completion Journey\n"
"\n"
"Let's recap how we got here:\n"
"\n"
"1. **Started with ℚ** - algebraically nice but full of holes\n"
"2. **Defined Cauchy sequences** - identified \"should converge\" sequences\n"
"3. **Took equivalence classes** - two sequences are the same if their difference → 0\n"
"4. **Created ℝ** - the set of these equivalence classes\n"
"5. **Proved completeness** - Cauchy sequences in ℝ converge in ℝ\n"
"\n"
"This is the **completion** of a metric space, and it's a universal construction in mathematics.\n"
"\n"
"## Beyond the Reals\n"
"\n"
"The completeness property isn't unique to ℝ:\n"
"\n"
"**Other complete spaces:**\n"
"- ℂ (complex numbers) - complete in the same sense\n"
"- ℝⁿ (Euclidean space) - complete under the Euclidean metric\n"
"- Lᵖ spaces - complete normed vector spaces of functions\n"
"- C[a,b] - continuous functions with sup norm\n"
"\n"
"**Incomplete spaces that need completion:**\n"
"- ℚ needs completion → ℝ\n"
"- ℚₚ (p-adics) from ℚ with p-adic absolute value\n"
"- Continuous functions with L² norm need completion → L² space\n"
"\n"
"The pattern is always the same: Cauchy sequences → equivalence classes → completed space.\n"
"\n"
"## Looking Ahead\n"
"\n"
"With completeness established, we've finished building the real number system. We now have:\n"
"- ✓ An ordered field (arithmetic that respects order)\n"
"- ✓ Archimedean property (no infinitesimals)\n"
"- ✓ Monotone Convergence Theorem (bounded monotone sequences converge)\n"
"- ✓ Bolzano-Weierstrass Theorem (bounded sequences have convergent subsequences)\n"
"- ✓ Completeness (Cauchy sequences converge)\n"
"\n"
"These properties collectively **characterize** ℝ up to isomorphism.\n"
"\n"
"Now we can move beyond the construction of ℝ to actually **doing analysis**:\n"
"- Continuous functions and the Intermediate Value Theorem\n"
"- Differentiability and the Mean Value Theorem\n"
"- Integration and the Fundamental Theorem of Calculus\n"
"- Uniform convergence and series of functions\n"
"- Power series and analytic functions\n"
"\n"
"The foundation is solid. The real mathematics begins now!\n"
"\n"
"## A Final Thought\n"
"\n"
"There's something philosophically profound about completeness. To achieve it, we had to:\n"
"- Accept infinite processes as completed objects\n"
"- Embrace numbers that can't be written as finite expressions\n"
"- Work with equivalence classes rather than concrete representations\n"
"\n"
"But in return, we gained a number system where:\n"
"- Every bounded monotone sequence converges\n"
"- Every continuous function on [a,b] attains its maximum\n"
"- The Intermediate Value Theorem holds\n"
"- Calculus works!\n"
"\n"
"We traded the simplicity of ℚ (every number is p/q) for the completeness of ℝ (every Cauchy sequence converges). This trade-off—giving up finite describability to gain analytic power—is at the heart of modern mathematics.\n"
"\n"
"**Welcome to the real numbers. They're complete, they're beautiful, and they're ready for analysis.**"
msgstr ""

#: Game.Levels.L3Levels.L01_ArchProp
msgid "Given `ε` and the fact that `0 < ε`, the theorem `ArchProp` claims the existence of `N : ℕ` so that `1 / ε < N`. This is a formalization of the classical Archimedean Property."
msgstr ""

#: Game.Levels.L13Pset.L13Pset1
msgid "If `a (n+1) ≤ a n` holds for all `n`, then `a` is `Antitone`."
msgstr ""

#: Game.Levels.L12Lecture
msgid "Lecture 12: Cauchy Sequences II"
msgstr ""

#: Game.Levels.L10Pset.L10Pset3
msgid "# Problem 2:\n"
"\n"
"Finish the proof of `ProdLim`."
msgstr ""

#: Game.Levels.L5Levels.L01_DoubleSeqConv
msgid "# Level 1: Doubling Convergence\n"
"\n"
"After conquering the constant sequence, let's up our game: if a sequence converges, then doubling that sequence also converges, and converges to double the original limit.\n"
"\n"
"## The Factory Scaling Challenge\n"
"\n"
"Imagine our Machinist receives a challenge from the Engineer: 'Please double all the lengths, but maintain the same quality standards.' How should the Machinist respond?\n"
"\n"
"If the Engineer demands the doubled lengths be within $\\varepsilon$ of $2L$, the Machinist can't just demand that the original process meet the original tolerance $\\varepsilon$, because\n"
"\n"
"`|2 * a (n) - 2 * L| < 2 * ε`,\n"
"\n"
"not `ε`. Instead, we must be more clever. Can you think of what to do?\n"
"\n"
"That's right, the `ε` in the original process\n"
"is *arbitrary*, so we can play with it!\n"
"If we could get the original process can guarantee output within $\\varepsilon/2$ of $L$, then doubling that output will be within $\\varepsilon$ of $2L$.\n"
"\n"
"This is the key insight: **when scaling by a constant, we need to scale our tolerance demands inversely**.\n"
"\n"
"## The Mathematical Setup\n"
"\n"
"Suppose we have:\n"
"- A sequence $a : \\mathbb{N} \\to \\mathbb{R}$ that converges to $L$\n"
"- A sequence $b : \\mathbb{N} \\to \\mathbb{R}$ with the property that $b(n) = 2 \\cdot a(n)$ for all $n$\n"
"\n"
"We want to prove that $b$ converges to $2 \\cdot L$.\n"
"\n"
"## Key Insight: Inverse Tolerance Scaling\n"
"\n"
"The crucial observation is that:\n"
"\n"
"$|b(n) - 2L| = |2 \\cdot a(n) - 2L| = 2 \\cdot |a(n) - L|$\n"
"\n"
"So if we want $|b(n) - 2L| < \\varepsilon$, we need $2 \\cdot |a(n) - L| < \\varepsilon$, which means $|a(n) - L| < \\varepsilon/2$.\n"
"\n"
"This is exactly what we can get from the convergence of $a$!\n"
"\n"
"## New Tools You'll Need\n"
"\n"
"**Absolute Value of Products**:\n"
"You'll need the new theorem `abs_mul` which states that for any real numbers $x$ and $y$:\n"
"\n"
"$|x \\cdot y| = |x| \\cdot |y|$.\n"
"\n"
"To use this theorem, you may find it convenient to\n"
"make a new hypothesis using `have` and then `rewrite` by that hypothesis. That is, you can say,\n"
"\n"
"`have NewFact : |Something * SomethingElse| =\n"
"|Something| * |SomethingElse| :=\n"
"by apply abs_mul`\n"
"\n"
"and then `rewrite [NewFact]` will replace `|Something * SomethingElse|` by `|Something| * |SomethingElse|` (either at the Goal, or `at` a hypothesis, if you so specify).\n"
"\n"
"## Your Strategic Approach\n"
"\n"
"1. Unfold the definition of convergence for the goal\n"
"2. Given any $\\varepsilon > 0$, use the convergence of $a$ with tolerance $\\varepsilon/2$. You may find it useful to separately prove the inequality `0 < ε / 2` -- which\n"
"tactic do you think will help with that?\n"
"3. Extract the witness $N$ from the convergence of $a$\n"
"4. Use the same $N$ for your sequence $b$\n"
"5. Apply the scaling hypothesis and use `abs_mul` to relate $|b(n) - 2L|$ to $|a(n) - L|$\n"
"6. Use the convergence bound for $a$ to conclude\n"
"\n"
"## Why This Pattern Matters\n"
"\n"
"This proof introduces the important technique of **inverse scaling** for tolerances. When you scale a sequence by a constant $c$, you need to scale your tolerance demands by $1/c$. This principle will appear again when you study:\n"
"- Products of sequences (where both factors contribute to the error)\n"
"- Derivatives (where the limit definition involves scaling by $h$)\n"
"- Integration (where Riemann sums involve scaling by partition widths)\n"
"\n"
"The ability to manage how constants affect convergence is fundamental to all of analysis!"
msgstr ""

#: Game.Levels.L20Pset.L04
msgid "# Level 4: Bounded Near Limit\n"
"\n"
"Prove that if `f → L` as `x → c`, then there is an `M > 0` such that\n"
"`|f (x)| < M` near `c`."
msgstr ""

#: Game.Levels.L5Levels.L01_DoubleSeqConv
msgid "The `linarith` tactic won't work\n"
"yet, because it'll get stuck on that `|2|`; do you remember what to do\n"
"to normalize the numerical value to just `2`?"
msgstr ""

#: Game.Levels.L10Levels.L08_Mono
msgid "If a sequence `a` converges to `L` and `σ` is a subsequence, then `a ∘ σ` also converges to `L`."
msgstr ""

#: Game.Levels.L12Levels.L01_MonotoneBdd
msgid "If a sequence `a : ℕ → X` (where `X` can be `ℚ` or `ℝ`) is monotone and bounded, then it is Cauchy."
msgstr ""

#: Game.Levels.L19Levels.L03
msgid "# Level 3 **Big Boss**: Rearrangement Theorem\n"
"\n"
"This is it—the moment we've been building toward! We're about to prove one of the most profound and beautiful theorems in all of real analysis.\n"
"\n"
"## The Fundamental Theorem\n"
"\n"
"**Theorem** (`RearrangementThm`): If a series `∑ a_n` converges absolutely, then for any rearrangement `σ : ℕ → ℕ`, the rearranged series `∑ a_(σ(n))` converges to the same limit.\n"
"\n"
"In symbols: If `AbsSeriesConv a`, then there exists `L` such that, for all `Rearrangement`s, `σ`, (including the identity) and `SeriesLim (a ∘ σ) L`.\n"
"\n"
"## The Deep Meaning\n"
"\n"
"This theorem reveals a profound truth about infinite summation:\n"
"\n"
"**Infinite summation is commutative if and only if the series is absolutely convergent.**\n"
"\n"
"For finite sums, we can add terms in any order—the sum doesn't change. This theorem says that absolute convergence is *exactly* what's needed to extend this property to infinite sums!\n"
"\n"
"## Why This is a Big Deal\n"
"\n"
"Remember from Lecture 18 how we showed that rearranging the infinite matrix changed its sum from 0 to -2? That's because those series were *not* absolutely convergent.\n"
"\n"
"For absolutely convergent series, we have complete freedom: reorder the terms however you like, and the sum stays the same. It's as if absolute convergence gives infinite series the \"finite property\" of commutativity.\n"
"\n"
"## New Theorems\n"
"\n"
"- `Series_image`: Relates the rearranged series to a sum over the image of `σ`\n"
"- `sum_sdiff`: Handles sums over set differences: `∑ (S₂ \\ S₁) + ∑ S₁ = ∑ S₂`\n"
"- `abs_sum_le_sum_abs`: Triangle inequality for finite sums\n"
"\n"
"## The Proof Strategy\n"
"\n"
"We'll combine everything from Levels 1 and 2:\n"
"1. The strong Cauchy property tells us that scattered large-index terms contribute negligibly\n"
"2. The eventually covers property tells us that rearrangements eventually include all early terms\n"
"3. We'll show the rearranged series stays close to the original by bounding the \"uncovered\" terms\n"
"\n"
"This is a technical proof, but the idea is beautiful: absolute convergence gives us enough \"slack\" that scrambling the order doesn't matter.\n"
"\n"
"Your task: Prove the Rearrangement Theorem—and unlock one of the deepest truths about infinite series!"
msgstr ""

#: Game.Levels.L7Levels.L03_SeqInvLim
msgid "If `0 < |x|`, then `x ≠ 0`."
msgstr ""

#: Game.Levels.L25Levels.L01
msgid "**Victory!** You've just proven one of the most important theorems in real analysis. This result:\n"
"\n"
"- **Validates Newton's genius**: His term-by-term integration of power series, done purely by intuition in the 1660s, now has rigorous justification\n"
"- **Bridges finite and infinite**: Extends the linearity of integrals from finite sums to infinite series (under uniform convergence)\n"
"- **Enables modern analysis**: Makes possible the rigorous treatment of Fourier series, differential equations with series solutions, and much of mathematical physics\n"
"\n"
"The proof strategy you used—controlling Riemann sum differences via uniform convergence—is a masterclass in how sophisticated mathematical concepts work together. You leveraged:\n"
"- The completeness of ℝ (Cauchy sequences converge)\n"
"- The definition of integrability (Riemann sums)\n"
"- Uniform convergence (simultaneous control over all function values)\n"
"\n"
"**Historical note**: This theorem wasn't rigorously proven until the late 1800s, over 200 years after Newton used it! Mathematicians like Weierstrass, Riemann, and others had to develop the very foundations of real analysis to make Newton's intuitive leaps rigorous.\n"
"\n"
"You've now mastered the deep connection between limits and integrals. In Level 2, we'll use all the machinery we've built to prove the most 'obvious' theorem in mathematics—one so intuitive that it was assumed without proof for over 2000 years!"
msgstr ""

#: Game.Levels.L23Levels.L01
msgid "If a function `f` is uniformly continuous on `[a,b]`, then the Riemann sum at `n * k` differs\n"
"from that at `n` by at most `(b - a) * ε`, provided the partition is fine enough."
msgstr ""

#: Game.Levels.L9Levels.L04_FiniteSums
msgid "If your hypotheses lead to a contradiction, (for example: if one of your hypotheses is that `h : n < 0` where `n : ℕ` is a natural number) then the `contradiction` tactic closes the goal."
msgstr ""

#: Game.Levels.L13Levels.L03_MonotoneSubseq
msgid "If `¬ (m ≤ n)`, then `n < m`."
msgstr ""

#: Game.Levels.L22Levels.L03
msgid "Summation division: `∑ i ∈ s, (f i / c) = (∑ i ∈ s, f i) / c`."
msgstr ""

#: Game.Levels.L1RealAnalysisStory
msgid "# A First Course in Real Analysis\n"
"\n"
"You may want to pull the left-most slider all the way to the right; what follows is a discussion\n"
"between \"Socrates\" and \"Simplicio,\" which hopefully  explains what it is we're trying to do here.\n"
"\n"
"**SIMPLICIO:** What is \"Real Analysis\"?\n"
"\n"
"**SOCRATES:** Oh, it's just Calculus, but done \"right\".\n"
"\n"
"**SIMPLICIO:** Huh? Why does Calculus need a new name? What's wrong with it?\n"
"\n"
"**SOCRATES:** Well, nothing really. Quick: what's a derivative?\n"
"\n"
"**SIMPLICIO:** Easy! If I have a function $f : \\R \\to \\R$ and it's differentiable at $x$, then the\n"
"derivative is $f'(x) := \\lim_{h \\to 0}\\frac{f(x+h) - f(x)}{h}$. This represents the \"instantaneous\" slope\n"
"of the graph of the function $y=f(x)$ at the point $(x, f(x))$.\n"
"[![derivative](images/Deriv.jpg)](https://en.wikipedia.org/wiki/Derivative)\n"
"\n"
"**SOCRATES:** Very good! And tell me please, what is an integral?\n"
"\n"
"**SIMPLICIO:** That's easy, too! If you want to integrate our function $f$ along an\n"
"interval, $[a, b]$, say, you pretend that you have infinitely many, infinitely small rectangles, work out their\n"
"areas as base times height, and add them up:\n"
"$\\int_a^b f(x)dx := \\lim_{N\\to\\infty} \\sum_{j=1}^N \\frac{b-a}{N} f\\left(a + j\\frac{b-a}{N}\\right)$\n"
"[![integral](images/Integral.jpg)](https://en.wikipedia.org/wiki/Integral)\n"
"\n"
"**SOCRATES:** Great. And what are the two Fundamental Theorems of Calculus?\n"
"\n"
"**SIMPLICIO:** These too are easy! The first one says that if you make a new function by integrating $f$\n"
"up to a variable amount, $x$, that is, let\n"
" $F(x) := \\int_a^x f(t)dt$, then the derivative of the new function is just $F'(x) = f(x)$.\n"
"\n"
"**SOCRATES:** And the second?\n"
"\n"
"**SIMPLICIO:**\n"
"The second one says that, conversely, if $F$ is an antiderivative of $f$, that is, $F'(x)=f(x)$, then\n"
"it's easy to work out the area under the curve, because\n"
" $\\int_a^b f(x)dx = F(b) - F(a)$.\n"
"So differentiation and integration are inverse operations!\n"
"\n"
"**SOCRATES:** Perfect. Now, here's the problem. You used words like \"limit\", \"infinitely many\", \"infinitely small\", and so on. What do they *actually* mean?\n"
"\n"
"**SIMPLICIO:** Oh, you know, it's when something  happens \"eventually\". You just have to get used to\n"
"the feel of it.\n"
"\n"
"**SOCRATES:** Hmm yes, I see. I agree that that's an OK way to think of it, for a while at least, and one that suited Newton (who\n"
"was quite uncomfortable with such words), and Leibniz (who was more care-free here), the two 17th century inventors of\n"
"calculus (if you don't count people like the ancient Greeks Eudoxus and Archimedes, or the 14th century Indian Madhava... but this isn't a history lesson). Leibniz taught the Bernoulli\n"
"brothers (the world's \"first AP Calc students\"!), who taught, among others, the Marquis de l'Hopital, and the great Leonhard Euler (the first \"Calc native\"), who taught the rest of us. All was going quite well... and then came the 19th Century.\n"
"[![NewtonLeibnizEudoxusArchimedesMadhavaBernoulliEuler](images/People.jpg)](https://en.wikipedia.org/wiki/History_of_calculus)\n"
"\n"
"**SIMPLICIO:** Huh? What happened in the 19th Century?\n"
"\n"
"**SOCRATES:** Well you see, a guy named Augustin-Louis Cauchy came along (roughly in the 1810s), and started making a fuss that we weren't really doing things perfectly \"rigorously\".\n"
"He set out to reprove the theorems of calculus using precise definitions rather than hand-waving.\n"
"He was making great progress, including proving statements like: the limit of continuous functions is continuous.\n"
"[![Cauchy](images/Cauchy.jpg)](https://en.wikipedia.org/wiki/Augustin-Louis_Cauchy)\n"
"\n"
"**SIMPLICIO:** Sure, that sounds perfectly reasonable. A limit is a continuous process, so you do that to\n"
"continuous functions, and of course in the end you should get something continuous, too.  No?\n"
"\n"
"\n"
"**SOCRATES:** Well, the problem is that around the same time, a guy named Joseph Fourier was going around claiming\n"
" that he could add up a bunch of sines and cosines, and get basically any function he wants, including, say, the discontinuous sawtooth!\n"
"\n"
"**SIMPLICIO:** What?!\n"
"\n"
"**SOCRATES:** Look for yourself: Here's a graph of $\\sum_{n=1}^{100}\\frac1n \\sin(nx)$. As you take 100\n"
"out to infinity, Fourier claims that this will get\n"
"closer and closer to a sawtooth function!\n"
"[![Fourier](images/Fourier.jpg)](https://en.wikipedia.org/wiki/Joseph_Fourier)\n"
"\n"
"**SIMPLICIO:** Whoa. Wait, I can think of an even easier example: just look at the simplest family of\n"
"polynomials, $f_n(x) = x^n$, on the unit interval $[0,1]$. When you take high powers of any point\n"
"strictly less than $1$, that goes to $0$ in the limit, but powers of $1$ itself always stay at $1$.\n"
"So the limiting function is discontinuous, too! What the heck is going on here?\n"
"![Power Functions](images/Powers.png)\n"
"\n"
"\n"
"**SOCRATES:** Very good, Simplicio! Exactly right, between Fourier and Cauchy, they \"broke math\".\n"
" You break it, you buy it!\n"
"\n"
"**SIMPLICIO:** Ok, so what's the right answer, how *do* you do calculus rigorously?\n"
"\n"
"**SOCRATES:** Not so fast! Things got even worse, and by the mid-19th century, people realized that\n"
"we don't even know what the real numbers *are*!\n"
"\n"
"**SIMPLICIO:** What? What do you mean, what are they? Here they are right here: There's zero, and one, and $-2$, and $\\frac35$, and\n"
"$\\sqrt 2$, and $e$ and $\\pi$. What's the problem?\n"
"[![RealNumbers](images/RealLine.png)](https://en.wikipedia.org/wiki/Real_number)\n"
"\n"
"**SOCRATES:** Well, do you remember that you need something called the Intermediate Value Theorem\n"
"in calculus?\n"
"\n"
"**SIMPLICIO:** Sure, if you have a continuous function, and it goes from being negative to being positive,\n"
"then it has to cross zero at some point in between.\n"
"\n"
"**SOCRATES:** Very good. Tell me about the function $f(x) = x^2 - 2$. In particular, what happens to $f$ on the rational numbers?\n"
"\n"
"**SIMPLICIO:** Ok, well if $x$ is a rational number, then so is $x^2$, and hence so is $x^2-2$.\n"
"So actually, we could say that $f : \\mathbb Q \\to \\mathbb Q$, that is, $f$ maps rational numbers to rational numbers.\n"
"Over the reals, the graph of $y=f(x)$ is a simple parabola.\n"
"But you'd asked me about the Intermediate Value Theorem. Hmm. When $x=0$, I know that $f(x)$ will\n"
"be $f(0)=0^2-2=-2$ which is negative. And when $x=2$, $f(2)=2^2-2=2$ which is positive.\n"
"\n"
"**SOCRATES:** Go on...\n"
"\n"
"**SIMPLICIO:** So there's a root of $f$ somewhere between $0$ and $2$. But the place where $f$ crosses the $x$-axis is at $x=\\sqrt2\\approx 1.41\\dots$.\n"
"\n"
"**SOCRATES:** And what did the Pythagoreans know about this number?\n"
"\n"
"**SIMPLICIO:** Supposedly one of them, Hippasus, figured out that $\\sqrt2$ is irrational, which ruined\n"
"their entire theory of geometry and form (they originally believed that *all* numbers were rational); legend has it\n"
"that Hippasus was drowned at sea for his herecy.\n"
"\n"
"**SOCRATES:** So...\n"
"\n"
"**SIMPLICIO:** So wait, if we just restrict to rational inputs, then this parabola is negative, and then\n"
"it's positive, and it *never* hits zero?! But there's tons of rational numbers all over the place. So what makes the real numbers different from the\n"
"rational numbers, so that the Intermediate Value Theorem actually holds?\n"
"\n"
"**SOCRATES:** Ah! Now, my friend, we are ready to begin."
msgstr ""

#: Game.Levels.L17Pset.L06
msgid "If `0 ≤ a n ≤ b n` and `Series b` converges, then so does `Series a`."
msgstr ""

#: Game.Levels.L2NewtonsCalculationOfPi.L01_SeqConvDef
msgid "Try starting with `change ∀ ε > 0, ∃ N : ℕ, ∀ n ≥ N, |a n - L| < ε`"
msgstr ""

#: Game.Levels.L5Levels.L01_DoubleSeqConv
msgid "And finally, this is where the powerful `linarith` tactic can take over. Remember to feed it (in brackets) the hypothesis (or hypotheses, separated by commas) which you want to manipulate to turn into the Goal."
msgstr ""

#: Game.Levels.L13Levels.L03_MonotoneSubseq
msgid "If a sequence `a : ℕ → X` (where `X` could be `ℚ` or `ℝ`) does not have unbounded peaks, then it has a `Monotone` subsequence."
msgstr ""

#: Game.Levels.L23Levels.L01
msgid "The sum over `m * n` terms can be expressed as a double sum over `m` and `n`."
msgstr ""

#: Game.Levels.L6Levels.L03_DotNotation
msgid "# Level 4: Dot Notation - Accessing Parts of Complex Information\n"
"\n"
"Now that you've learned to construct \"and\" statements with `split_ands` and make strategic choices with \"or\" statements using `left` and `right`, it's time to learn how to efficiently extract information from complex hypotheses you already have.\n"
"\n"
"Often in mathematics, you'll be given a hypothesis that contains multiple pieces of information bundled together. For instance, you might know that \"x = 2 AND y = 3\" but only need the fact that \"y = 3\" for your current goal. Rather than using lengthy tactics to unpack this information, Lean provides an elegant shorthand: dot notation.\n"
"\n"
"Think of dot notation like accessing specific files in a well-organized filing cabinet. If you have a folder labeled `h` that contains multiple documents, you can quickly grab the second document with `h.2` instead of having to open the folder, sort through all the papers, and extract what you need manually.\n"
"\n"
"This notation becomes especially powerful when dealing with complex mathematical objects. In real analysis, we often work with properties that have multiple components—a sequence might be both bounded AND monotonic, or a function might be both continuous AND differentiable. Dot notation lets us access exactly the property we need, when we need it.\n"
"\n"
"## New Tools You'll Need\n"
"\n"
"**Dot notation**: When you have a hypothesis `h : P ∧ Q`, you can access the first part with `h.1` (which gives you `P`) and the second part with `h.2` (which gives you `Q`).\n"
"\n"
"Note that for longer conjunctions like `P ∧ Q ∧ R`, `h.1` gives `P` as expected, but\n"
"`h.2` gives `Q ∧ R`. That's because there are hidden parentheses: `P ∧ Q ∧ R = P ∧ (Q ∧ R)`. So how do you get to `Q` alone? Easy: dot notation! Writing `h.2.1` gives `Q`, and `h.2.2` gives `R`."
msgstr ""

#: Game.Levels.L1Pset.L1Pset2
msgid "# Problem 2\n"
"\n"
"In this problem you are asked to show that there is some `c` so that `(x + y) ^ 2 = c`, given that\n"
"`x * y = 1` and `x ^ 2 + y ^ 2 = 2`.\n"
"\n"
"You will likely have a hard time solving this problem as is.\n"
"You surely can work out what value of\n"
"`c` you need. But if you try\n"
"`ring_nf`, you won't have control over\n"
"how the \"normal form\" chooses to\n"
"express things. In fact, the\n"
"left-hand side, `(x + y) ^ 2` will\n"
"turn into `x * y * 2 + x ^ 2 + y ^ 2`,\n"
"which is parsed in this order:\n"
"\n"
"`(((x * y) * 2) + x ^ 2) + y ^ 2`\n"
"\n"
"This means that you *will* be able to\n"
"`rewrite [h2]` successfully,\n"
"but then you will *not* be able to rewrite by `h1`, because the (invisible) parentheses  go the wrong way. (Hint: If you want to know how things are grouped but don't see parentheses, you can hover your cursor over the text in the Goal State, and Lean will show you the groupings. Try it!)\n"
"\n"
"Now, in natural language, there are times when you might want to\n"
"record an auxiliary fact: \"let's\n"
"*have* the fact that such and such ...\". The Lean\n"
"syntax for this is as follows:\n"
"\n"
"`have NewFactName (Assumptions) : Conclusion := by Proof`\n"
"\n"
"That is, you first write `have`; then give\n"
"the new hypothesis a name; then include any\n"
"assumptions, like `(x : ℝ)`, meaning, `x`\n"
"is a real number, etc (the symbol `ℝ` is written with a backslash, then capital `R`, then space); then you put a colon,\n"
"and then state the conclusion; then you\n"
"put a colon-equals and the word `by`; and finally you give the proof.\n"
"\n"
"For example, if you wanted to declare\n"
"the new fact that, say, for any real `u` and `v`,\n"
"\n"
"`(u + v) ^ 2 = (u ^ 2 + v ^ 2) + 2 * (u * v)`\n"
"\n"
"and you wanted to call this fact `huv` (a hypothesis on `u` and `v`),\n"
"and you wanted to prove this fact by\n"
"invoking the ring normal form tactic,\n"
" then you would give Lean the command:\n"
"\n"
"`have huv (u v : ℝ) : (u + v) ^ 2 = (u ^ 2 + v ^ 2) + 2 * (u * v) := by ring_nf`\n"
"\n"
"This will add to your list of hypotheses\n"
"the fact: `huv : ∀ (u v : ℝ), (u + v) ^ 2 = (u ^ 2 + v ^ 2) + 2 * (u * v)`.\n"
"\n"
"Something like this (if not exactly this)\n"
"will be useful to you in solving this problem."
msgstr ""

#: Game.Levels.L16PsetIntro
msgid "Pset 16"
msgstr ""

#: Game.Levels.L11Levels.L02_IsCauchyOfSum
msgid "# Excellent work! Cauchy sequences are closed under addition!\n"
"\n"
"You've just proven that the set of Cauchy sequences forms a well-behaved algebraic structure—they can be added together and the result is still Cauchy.\n"
"\n"
"## What this means\n"
"\n"
"This theorem shows that the Cauchy property is **preserved by addition**. This is crucial because:\n"
"\n"
"- We can build more complex Cauchy sequences from simpler ones\n"
"- When we eventually construct the real numbers as equivalence classes of Cauchy sequences, we'll need to know that addition is well-defined\n"
"- The Cauchy sequences form what algebraists call a **vector space** (or at least a subspace of all sequences)\n"
"\n"
"## The Pattern\n"
"\n"
"Notice how similar this proof was to proving that sums of convergent sequences converge:\n"
"- Split `ε` into `ε / 2` for each sequence\n"
"- Use the triangle inequality to separate the sum\n"
"- Combine the estimates\n"
"\n"
"The key difference? **No limits appeared anywhere!** The Cauchy property is entirely self-contained.\n"
"\n"
"Ready for the next level!"
msgstr ""

#: Game.Levels.L4PsetIntro
msgid "# Problem Set 4\n"
"\n"
"Good luck!"
msgstr ""

#: Game.Levels.L22Levels.L03
msgid "Summation multiplication: `∑ i ∈ s, (f i * c) = (∑ i ∈ s, f i) * c`."
msgstr ""

#: Game.Levels.L8Pset.L8Pset2
msgid "# Problem 2\n"
"\n"
"We proved in class that `n < 2 ^ n`. It's even true that `n ^ 2 ≤ 2 ^ n`, but only for `n` sufficiently large (how large?).\n"
"\n"
"Look at the problem statement. Note how we've implemented induction starting somewhere other than zero: by shifting the argument by that amount.\n"
"\n"
"Hint: The result from Problem 1 might come in handy..."
msgstr ""

#: Game.Levels.L10Levels.L07_Order
msgid "Excellent work! You've proven that limits respect inequalities.\n"
"\n"
"**What We Learned:**\n"
"\n"
"The Order Limit Theorem tells us that **weak inequalities pass to the limit**:\n"
"- If `a n ≤ K` for all `n` and `a n → L`, then `L ≤ K`\n"
"\n"
"**Why Contradiction Works Here:**\n"
"\n"
"This is a great example of when proof by contradiction is the natural approach. We want to prove `L ≤ K`, which is hard to show directly. But assuming `L > K` gives us a concrete positive number `L - K` that we can use as `ε` in the convergence definition. The contradiction writes itself!\n"
"\n"
"**The Symmetric Result:**\n"
"\n"
"There's a symmetric version (left as an exercise): if `K ≤ a n` for all `n` and `a n → L`, then `K ≤ L`. This says sequences bounded **below** have limits bounded below.\n"
"\n"
"**Important Limitation:**\n"
"\n"
"Remember: **strict inequalities don't pass to the limit!**\n"
"\n"
"If `a n < K` for all `n`, we can only conclude `L ≤ K`, not `L < K`.\n"
"\n"
"Counter-example: `a n = 1/n` satisfies `0 < a n` for all `n`, but `lim a n = 0`.\n"
"\n"
"The limit can equal the boundary even when the sequence never touches it!\n"
"\n"
"**Coming Up: Applications**\n"
"\n"
"The Order Limit Theorem is the foundation for:\n"
"- **Squeeze Theorem (Sandwich Theorem):** If `a n ≤ b n ≤ c n` and `a n → L` and `c n → L`, then `b n → L`\n"
"- **Monotone Convergence Theorem:** Bounded monotone sequences converge\n"
"- **Comparison tests** for series\n"
"- Many other fundamental results in analysis\n"
"\n"
"This theorem lets us compare sequences and transfer information about one sequence to another via inequalities. Very powerful!"
msgstr ""

#: Game.Levels.L5Levels.L01_DoubleSeqConv
msgid "Prove that constant multiples of convergent sequences converge to the constant multiple of the limit.\n"
"This is the Machinist's response to scaling demands: 'If you want double the output with the same tolerance, I need half the tolerance on the original process!'"
msgstr ""

#: Game.Levels.L2NewtonsCalculationOfPi.L01_SeqConvDef
msgid "`(a : ℕ → ℝ) (L : ℝ) := ∀ ε > 0, ∃ N : ℕ, ∀ n ≥ N, |a n - L| < ε`\n"
"\n"
"For a sequence `a : ℕ → ℝ` and a real number `L : ℝ`, we say that `SeqLim a L` holds if: for every `ε > 0`, there exists `N : ℕ` such that for all `n ≥ N`, we have `|a n - L| < ε`."
msgstr ""

#: Game.Levels.L24Levels.L04
msgid "# Level 4: Heine-Borel Theorem: Part 2a\n"
"\n"
"**The Hard Direction Begins**: Now for the converse! We need to prove that every closed bounded interval `[a,b]` is compact. This is where the real analysis gets deep.\n"
"\n"
"**The Challenge**: Given any open cover of `[a,b]` by balls, we must extract a finite subcover. But how do you go from \"every point is covered\" to \"finitely many balls suffice\"?\n"
"\n"
"**The Brilliant Strategy - Growing Intervals**:\n"
"We'll use your Least Upper Bound Property in a clever way:\n"
"\n"
"1. **Define the \"Good Set\"**: Let `S = {t ∈ [a,b] : [a,t] can be covered by finitely many balls}`\n"
"\n"
"2. **Show S is Bounded Above**: Obviously `S ⊆ [a,b]`, so `b` is an upper bound\n"
"\n"
"3. **Show S is Non-empty**: Since our cover includes some ball containing `a`, we have `a ∈ S`\n"
"\n"
"4. **Apply LUB**: By Level 3, `S` has a supremum `L`. The magic is showing `L = b`!\n"
"\n"
"**The Key Insight**: If `L < b`, then `L` itself is covered by some ball in our covering. But balls have positive radius, so this ball covers not just `L` but some interval `[L-δ, L+δ]`. Since `L = sup S`, there's some `t ∈ S` with `t > L-δ`. Now we can:\n"
"- Cover `[a,t]` with finitely many balls (since `t ∈ S`)\n"
"- Cover `[t, L+δ]` with the single ball around `L`\n"
"- Combine them to cover `[a, L+δ]`\n"
"\n"
"This means `L+δ ∈ S`, contradicting that `L` is an upper bound for `S`!\n"
"\n"
"**Why This Works**: The proof exploits the tension between:\n"
"- **Discrete**: Finite covers (what we want to construct)\n"
"- **Continuous**: The supremum property (what Level 3 gives us)\n"
"- **Open**: Balls have positive radius (what creates the contradiction)\n"
"\n"
"**Your Mission**: Implement this supremum-based argument. You'll need to carefully handle the cases and use the fact that every point in `[a,b]` is covered by some ball with positive radius.\n"
"\n"
"This is where topology meets real analysis in its full glory!"
msgstr ""

#: Game.Levels.L13Pset.L13Pset1
msgid "Prove `AntitoneSubseq_of_UnBddPeaks`"
msgstr ""

#: Game.Levels.L24Pset.L02
msgid "# Level 2: Open Balls are Open\n"
"\n"
"Prove that an open ball `Ball x r` is open, as a set."
msgstr ""

#: Game.Levels.L12Levels.L00_SubseqIterate
msgid "If a sequence `σ : ℕ → ℕ` grows faster than the identity, `n < σ n`,\n"
"then the orbit of any base point `n₀ : ℕ` under `σ` -- this means the sequence `n₀, σ n₀, σ^[2] n₀, ...` -- is a `Subseq`, that is, is strictly increasing."
msgstr ""

#: Game.Levels.L7Levels.L00_Uniqueness
msgid "Uniqueness of Limits"
msgstr ""

#: Game.Levels.L3Levels.L02_OneOverN
msgid "The `exact_mod_cast` tactic is similar to `apply`, except it automatically handles type coercions that would otherwise require manual casting."
msgstr ""

#: Game.Levels.L22Levels.L01
msgid "The composition of continuous functions is continuous."
msgstr ""

#: Game.Levels.L16Levels.L01_check
msgid "Excellent! You've proven one of the most important necessary conditions for series convergence.\n"
"\n"
"## What You've Shown\n"
"\n"
"**Theorem (LimZero_of_SeriesConv):** If `SeriesConv a`, then `SeqLim a 0`.\n"
"\n"
"In other words: *The terms of a convergent series must approach zero.*\n"
"\n"
"## Why This Matters\n"
"\n"
"This gives us a quick **divergence test**. To show a series diverges, you only need to check whether its terms go to zero. If they don't, the series definitely diverges!\n"
"\n"
"**Examples of divergent series:**\n"
"- `∑ 1` diverges (terms stay at 1)\n"
"- `∑ (-1)^k` diverges (terms oscillate between ±1)\n"
"- `∑ k/(k+1)` diverges (terms approach 1, not 0)\n"
"\n"
"## The Key Insight\n"
"\n"
"Your proof used a beautiful idea: the difference between consecutive partial sums is exactly one term of the original sequence:\n"
"\n"
"`Series a (n+1) - Series a n = a n`\n"
"\n"
"Since convergent sequences are Cauchy, consecutive partial sums get arbitrarily close together. Therefore the terms `a n` must vanish!\n"
"\n"
"## Critical Warning: The Converse Fails!\n"
"\n"
"Be careful! It is **NOT** true that if `SeqLim a 0`, then `SeriesConv a`.\n"
"\n"
"The classic counterexample is the **harmonic series**:\n"
"`∑ 1/k = 1 + 1/2 + 1/3 + 1/4 + ...`\n"
"\n"
"Here `1/k → 0`, but the series diverges! The partial sums grow like `log n`.\n"
"\n"
"So vanishing terms are *necessary* but not *sufficient* for convergence. To prove a series converges, we need additional tests (which we'll develop in future levels).\n"
"\n"
"## Historical Note\n"
"\n"
"This test was known to early mathematicians like Nicole Oresme (14th century) and Jakob Bernoulli (17th century). It was one of the first tools for distinguishing convergent from divergent series.\n"
"\n"
"Oresme also proved the harmonic series diverges using a clever grouping argument, showing that the converse of this theorem fails -- a result that surprised many mathematicians at the time!\n"
"\n"
"---\n"
"\n"
"**Next:** We'll evaluate some explicit series, starting with the beautiful Leibniz series."
msgstr ""

#: Game.Levels.L6Levels.L00_SumOfSeqs
msgid "# 🎉 Outstanding! 🎉\n"
"\n"
"You've just proven one of the fundamental theorems of analysis! Let's celebrate what you accomplished and understand why this result is so powerful.\n"
"\n"
"**Why This Matters:**\n"
"This theorem and others like it are the foundation for all of calculus! Every time we differentiate or integrate a sum, we're implicitly using arguments of this kind.\n"
"\n"
"**The Deeper Insight:**\n"
"Notice how the proof required more than just intuition. The 'obvious' fact that sums of convergent sequences converge needed careful epsilon management. This is the hallmark of rigorous analysis: making intuitive ideas completely precise.\n"
"\n"
"## Check in, in Natural Language\n"
"\n"
"Yet again, let's step back from the formal Lean proof and understand what we just proved in plain English.\n"
"\n"
"**Theorem (in natural language):** If two sequences of real numbers converge to their respective limits, then the sequence formed by adding corresponding terms also converges, and its limit is the sum of the original limits.\n"
"\n"
"**Proof:** Suppose sequences $a(n)$ and $b(n)$ converge to $L$ and $M$ respectively, and we want to show that $c(n) = a(n) + b(n)$ converges to $L + M$.\n"
"\n"
"By definition, we need to show that for any tolerance $\\varepsilon > 0$, we can find a point $N$ such that for all $n \\geq N$, we have $|c(n) - (L + M)| < \\varepsilon$.\n"
"\n"
"Since $a(n)$ converges to $L$, we can find $N_1$ such that $|a(n) - L| < \\varepsilon/2$ for all $n \\geq N_1$.\n"
"Since $b(n)$ converges to $M$, we can find $N_2$ such that $|b(n) - M| < \\varepsilon/2$ for all $n \\geq N_2$.\n"
"\n"
"Let $N = N_1 + N_2$ (any number that's at least as large as both $N_1$ and $N_2$ would work). Then for any $n \\geq N$:\n"
"\n"
"$$|c(n) - (L + M)| = |(a(n) + b(n)) - (L + M)| = |(a(n) - L) + (b(n) - M)|$$\n"
"\n"
"By the triangle inequality, this is at most:\n"
"$$|a(n) - L| + |b(n) - M| < \\frac{\\varepsilon}{2} + \\frac{\\varepsilon}{2} = \\varepsilon$$\n"
"\n"
"Therefore, $c(n)$ converges to $L + M$. **QED**"
msgstr ""

#: Game.Levels.L1RealAnalysisStory.L08_choose
msgid "If there exists a point where f equals 2, then there exists a point where f² equals 4."
msgstr ""

#: Game.Levels.L9Levels.L05_BddOfConv
msgid "`(a : ℕ → X) := ∃ M > 0, ∀ n, |a n| ≤ M`\n"
"\n"
"  A sequence `a : N → X` (where `X` could be `ℚ` or `ℝ`) is bounded (`SeqBdd` holds) if there exists some positive\n"
"`M : X` so that `|a n| ≤ M`, for all `n`."
msgstr ""

#: Game.Levels.L9Levels.L04_FiniteSums
msgid "Given a function `f : ℕ → ℝ` and a natural number `N`, `sum_range_succ f n` says that:\n"
"`∑ n ∈ range (N + 1), f n = ∑ n ∈ range N, f n + f N`."
msgstr ""

#: Game.Levels.L3Pset.L3Pset1
msgid "Prove the full Archimedean Property."
msgstr ""

#: Game.Levels.L24Levels.L02
msgid "# Compactness ⟹ Closed and Bounded: Complete!\n"
"\n"
"Excellent! You've just proved that **compact ⟹ closed**. Combined with Level 1, you've now established the full first direction of Heine-Borel:\n"
"\n"
"**Compact ⟹ Closed and Bounded** ✓\n"
"\n"
"**What Made This Proof Ingenious**:\n"
"- **The Separation Trick**: The key insight was using balls of radius `|y - x|/2` around points in `S`. These balls contain points of `S` but can never reach the outside point `y`.\n"
"- **Local to Uniform**: You converted the fact that `y` is separated from each individual point in `S` into uniform separation from the entire set `S`. This is compactness at its finest!\n"
"- **Finite Extraction**: Once again, compactness let you reduce an infinite problem (separation from all points in `S`) to a finite one (separation from finitely many covering balls).\n"
"\n"
"**The Geometric Picture**: Imagine trying to \"push\" the outside point `y` into the compact set `S`. The proof shows this is impossible - there's always a \"safety buffer\" around `y` that keeps it separated from `S`.\n"
"\n"
"**Why This Direction Is \"Easy\"**: Compactness gives you such strong control (every cover reduces to a finite subcover) that proving additional properties becomes manageable. The hard direction will be the converse!\n"
"\n"
"**What's Next**: Now comes the serious work. In Level 3, you'll prove the **Least Upper Bound Property** of ℝ - every bounded set has a supremum. This fundamental property of the real numbers is what makes the converse direction possible.\n"
"\n"
"**Looking Ahead**: Levels 4-5 will prove **Closed and Bounded ⟹ Compact**. This is where the real analysis gets deep, and you'll see why the completeness of ℝ matters!\n"
"\n"
"The easy direction is done - now for the hard one! 🚀"
msgstr ""

#: Game.Levels.L18Levels.L02
msgid "# Level 2: Alternating Series Test\n"
"\n"
"In this level, we prove one of the most elegant and useful results in the theory of infinite series: the **Alternating Series Test**, also known as the **Leibniz Test** (named after Gottfried Wilhelm Leibniz, who discovered it in the 17th century).\n"
"\n"
"## The Setting\n"
"\n"
"Consider an alternating series—one where the signs alternate between positive and negative:\n"
"\n"
"$a_0 - a_1 + a_2 - a_3 + a_4 - \\cdots = \\sum_{n=0}^{\\infty} (-1)^n \\cdot a_n$\n"
"\n"
"When does such a series converge?\n"
"\n"
"## The Theorem\n"
"\n"
"**Theorem** (`AlternatingSeriesTest`): Suppose `a : ℕ → ℝ` is an `Antitone` sequence (meaning $a_0 \\geq a_1 \\geq a_2 \\geq \\cdots$) that converges to `0`. Then the alternating series\n"
"\n"
"$\\sum_{n=0}^{\\infty} (-1)^n \\cdot a_n$\n"
"\n"
"converges.\n"
"\n"
"In other words: *if the terms decrease to zero, then the alternating series converges*.\n"
"\n"
"**Note**: By `AntitoneLimitBound` (to be proved in homework), since $a_n \\to 0$ and $a$ is antitone, we automatically have $a_n \\geq 0$ for all $n$.\n"
"\n"
"## Classic Examples\n"
"\n"
"- The alternating harmonic series: $\\sum_{k=1}^{\\infty} \\frac{(-1)^{k+1}}{k} = 1 - \\frac{1}{2} + \\frac{1}{3} - \\frac{1}{4} + \\cdots$ converges to $\\ln 2$\n"
"- The Leibniz formula for $\\pi$: $\\sum_{k=0}^{\\infty} \\frac{(-1)^k}{2k+1} = 1 - \\frac{1}{3} + \\frac{1}{5} - \\frac{1}{7} + \\cdots = \\frac{\\pi}{4}$\n"
"\n"
"## Proof Strategy\n"
"\n"
"The idea is to show that the **even** partial sums and **odd** partial sums both converge to the same limit:\n"
"- Even partial sums: $S_{2n} = a_0 - a_1 + a_2 - \\cdots - a_{2n-1}$ form a monotone increasing, bounded sequence\n"
"- Odd partial sums: $S_{2n+1} = a_0 - a_1 + a_2 - \\cdots + a_{2n}$ form a monotone decreasing, bounded sequence\n"
"- The difference $S_{2n+1} - S_{2n} = a_{2n} \\to 0$, so they converge to the same limit\n"
"\n"
"This will require several technical lemmas (all to be proved in homework), but the main proof brings them all together beautifully!\n"
"\n"
"Your task: Prove the `AlternatingSeriesTest` by showing both even and odd subsequences of partial sums converge to the same limit.\n"
"\n"
"## New Theorems: look up: `AntitoneLimitBound`, `CoherenceOfReals`, `SeqEvenOdd`, `MonotoneSeriesEven`, `AntitoneSeriesOdd`, `BddSeriesEven`, `BddSeriesOdd`, and `DiffGoesToZero`."
msgstr ""

#: Game.Levels.L7Pset.L7Pset1
msgid "If `a : ℕ → ℝ` converges to `L` and `L ≠ 0`, then `|a n|` is eventually bounded by `2 * |L|`."
msgstr ""

#: Game.Levels.L7PsetIntro
msgid "# Problem Set 7\n"
"\n"
"Good luck!"
msgstr ""

#: Game.Levels.L5Levels.L01_DoubleSeqConv
msgid "Doubling a Convergent Sequence"
msgstr ""

#: Game.Levels.L15Levels.L01_check
msgid "`{a : ℕ → ℚ} (ha : IsCauchy a) : ℝ`\n"
"\n"
"A sequence `a : ℕ → ℚ` that is Cauchy converges to a real number; this *is* that real number."
msgstr ""

#: Game.Levels.L8Pset.L8Pset3
msgid "# Problem 3\n"
"\n"
"Prove that `n (n + 1) (2 n + 1)` is always divisible by `6`. (Hint: induction.)"
msgstr ""

#: Game.Levels.L7Levels.L03_SeqInvLim
msgid "# Level 4: Reciprocals of Convergent Sequences — Big Boss Level\n"
"\n"
"One of the most important limit theorems concerns reciprocals: if a sequence converges to\n"
"a nonzero limit, then the sequence of reciprocals converges to the reciprocal of the limit.\n"
"This result is crucial for proving theorems about quotients and rational functions.\n"
"\n"
"This is a **Big Boss level**—it will require you to synthesize multiple techniques you've\n"
"developed throughout this lecture: working with nonzero limits, manipulating complex\n"
"algebraic expressions, and carefully choosing your epsilon strategy.\n"
"\n"
"## What We're Proving\n"
"\n"
"**Theorem:** If `a : ℕ → ℝ` converges to `L` with `L ≠ 0`, and `b : ℕ → ℝ` is defined\n"
"by `b n = 1 / a n` for all `n`, then `b` converges to `1 / L`.\n"
"\n"
"This is the most technically challenging proof in this lecture.\n"
"\n"
"## New Tools You'll Need\n"
"\n"
"### `abs_div`\n"
"For any real numbers `x` and `y` (with `y ≠ 0`), we have `|x / y| = |x| / |y|`.\n"
"\n"
"### `nonzero_of_abs_pos`\n"
"If `0 < |x|`, then `x ≠ 0`.\n"
"\n"
"## Hints\n"
"\n"
"Think about what you've proven in the previous levels:\n"
"- How can you ensure that `a n ≠ 0` eventually, so the reciprocals are well-defined?\n"
"- What happens when you try to bound `|1/a n - 1/L|`? Can you get a common denominator?\n"
"- How should you choose your epsilon when applying the convergence of `a` to `L`?\n"
"- What role does the lower bound on `|a n|` play in controlling the reciprocals?\n"
"\n"
"The key is finding the right epsilon and carefully managing the algebraic manipulations\n"
"involving fractions. You have all the tools you need—now it's time to put them together!"
msgstr ""

#: Game
msgid "# Welcome to Real Analysis, The Game!\n"
"\n"
"This course is currently being developed for Rutgers University Math 311H by [Alex Kontorovich](https://math.rutgers.edu/~alexk).\n"
" Please email alex.kontorovich@rutgers.edu for suggestions/corrections,\n"
"or better yet, post a PR/issue to\n"
"https://github.com/AlexKontorovich/RealAnalysisGame.\n"
"\n"
"For the main course website, go to: https://alexkontorovich.github.io/2025F311H.\n"
"\n"
"This course takes you through an Introduction to the Real Numbers, rigorous `ε`-`δ` Calculus,\n"
"and basic Point-Set Topology.\n"
"To get started, click on\n"
"**\"Level 1: The Story of Real Analysis\"**, and good luck!"
msgstr ""

#: Game.Levels.L16Levels.L01_check
msgid "Series"
msgstr ""

#: Game.Levels.L22Lecture
msgid "# Lecture 22: Uniformity\n"
"\n"
"**SOCRATES:** I just noticed something about that last level.\n"
"\n"
"**SIMPLICIO:** Ugh. Ok, what was it?\n"
"\n"
"**SOCRATES:** I don't know, you tell me.\n"
"\n"
"**SIMPLICIO:** We proved that $x^2-1$ was continuous everywhere. So what?\n"
"\n"
"**SOCRATES:** Right. How did we do it? What `δ` did we choose, once `ε` was given?\n"
"\n"
"**SIMPLICIO:** Are you getting senile, old man? We chose `δ = ε / (2|x|+1)`.\n"
"\n"
"**SOCRATES:** Anything interesting about that?\n"
"\n"
"**SIMPLICIO:** What, that it has an `x` in it? So what? We had no other choice but to choose `δ` depending on `x`. We took `y` near `x`, `|y-x|<δ`, and computed that `|f y - f x|` was `|y-x|*|y+x|`.\n"
"The first factor is good, since it's less than `δ`; in the second factor,\n"
"since `y` is near `x`, then `|y+x|` has size about `2*|x|`, and we\n"
"added one just to be safe.\n"
"\n"
"**SOCRATES:** Ok, let's put a pin in this and come back to it later. Here's a question: suppose I have a sequence of continuous functions $f_n$, and suppose $f_n$ converges to some limit function $F$.\n"
"That is, for every $x$, the sequence of real numbers $n \\mapsto f_n(x)$ converges to $F(x)$. What can you tell me about $F$?\n"
"\n"
"**SIMPLICIO:** Is $F$ continuous? Wait, I've fallen into this trap before. I even remember my counterexample from Lecture 1: Just take $f_n(x) = x^n$ on $[0,1]$. Each $f_n$ is continuous, but the limiting function is discontinuous at $x=1$.\n"
"\n"
"**SOCRATES:** Exactly! So mere pointwise convergence isn't enough. But let's pretend that it was and see what goes wrong with our proof of continuity.\n"
"\n"
"**SIMPLICIO:** Ok, so you want me to try (and fail) to prove that $F$ is continuous at some point $x$. Given `ε > 0`, we need to find `δ > 0` such that for all `y` with `|y - x| < δ`, we have `|F(y) - F(x)| < ε`.\n"
"\n"
"**SOCRATES:** Right. Go on.\n"
"\n"
"**SIMPLICIO:** Since $f_n$ converges to $F$ pointwise, for our given `x` and `ε`, we can find some big enough `N` such that for all `n ≥ N`, we have `|f_n(x) - F(x)| < ε/3`.\n"
"\n"
"**SOCRATES:** Yes. And?\n"
"\n"
"**SIMPLICIO:** Now, since $f_N$ is continuous at `x`, we can find some `δ > 0` such that for all `y` with `|y - x| < δ`, we have `|f_N(y) - f_N(x)| < ε/3`.\n"
"\n"
"**SOCRATES:** Good so far. Now, what would you like to do next?\n"
"\n"
"**SIMPLICIO:** Well, I want to show that `|F(y) - F(x)| < ε` for `y` close to `x`. I can use the triangle inequality:\n"
"`|F(y) - F(x)| ≤ |F(y) - f_N(y)| + |f_N(y) - f_N(x)| + |f_N(x) - F(x)|`.\n"
"\n"
"**SOCRATES:** Excellent! And what can you say about each of these three terms?\n"
"\n"
"**SIMPLICIO:** Well, the middle term is less than `ε/3` by our choice of `δ`. The last term is less than `ε/3` by our choice of `N`. So if I can make the first term less than `ε/3`, I'm done!\n"
"\n"
"**SOCRATES:** And can you?\n"
"\n"
"**SIMPLICIO:** Hmm... I need `|F(y) - f_N(y)| < ε/3`. Since $f_n$ converges to $F$ at the point `y`, I can find some `M` (which might depend on `y`) such that for `n ≥ M`, we have `|f_n(y) - F(y)| < ε/3`. Uh oh...\n"
"\n"
"**SOCRATES:** What's the problem?\n"
"\n"
"**SIMPLICIO:** The problem is that my `N` was chosen to work at the specific point `x`, but now I need it to work at this other point `y` too! And `y` could be **any** point near `x`, so I'd need `N` to work at *all* of these points near `x` simultaneously.\n"
"\n"
"**SOCRATES:** Yeah, so what? No matter which `y` you pick, you can always find some `M` that works for that `y`.\n"
"\n"
"**SIMPLICIO:** But that's exactly the problem! The `M` I find depends on which `y` I'm looking at. For one `y`, I might need `M = 100`. For another `y` nearby, I might need `M = 1000`. And for yet another `y`, I might need `M = 10000`.\n"
"\n"
"**SOCRATES:** So?\n"
"\n"
"**SIMPLICIO:** So my original `N` was fixed at the beginning - it only depends on `x` and `ε`. But now I need this same fixed `N` to work for all possible values of `y` near `x`. There's no guarantee that my fixed `N` is bigger than all the different `M`'s I'd need for different `y`'s!\n"
"\n"
"**SOCRATES:** Ah, I see. So you're saying that even though $f_n(y) \\to F(y)$ for each individual `y`, there might not be a single `N` that makes the convergence happen \"fast enough\" simultaneously for all `y` in a neighborhood?\n"
"\n"
"**SIMPLICIO:** Exactly! The convergence might be happening at wildly different rates at different points. At some points it might converge quickly, at others very slowly.\n"
"\n"
"**SOCRATES:** Interesting. So what kind of convergence would you need to make this proof work?\n"
"\n"
"**SIMPLICIO:** I'd need the convergence to be... uniform over the whole space? Or at least uniform over neighborhoods? So that I can find a single `N` that works for all points at once, not just point by point.\n"
"\n"
"**SOCRATES:** Precisely! You've just discovered why we need the concept of **uniform convergence**. Shall we make this precise?\n"
"\n"
"**SIMPLICIO:** Yes! What exactly do we mean by \"uniform convergence\"?\n"
"\n"
"**SOCRATES:** You tell me.\n"
"\n"
"**SIMPLICIO:** Well, I said that I need a single `N` that works for all points at once. So instead of saying \"for each `y`, there exists `M` such that for `n ≥ M`, we have `|f_n(y) - F(y)| < ε/3`\", I need to say \"there exists `N` such that for all `y` and all `n ≥ N`, we have `|f_n(y) - F(y)| < ε/3`\".\n"
"\n"
"**SOCRATES:** Exactly! So uniform convergence means: for every `ε > 0`, there exists `N` such that for all `n ≥ N` and for all `x` in our domain, we have `|f_n(x) - F(x)| < ε`.\n"
"\n"
"**SIMPLICIO:** Got it! The key difference is the *order of quantifiers*. In pointwise convergence, we have \"for all `x`, there exists `N`\" - the `N` can depend on `x`. In uniform convergence, we have \"there exists `N` such that for all `x`\" - the same `N` must work for every point.\n"
"\n"
"**SOCRATES:** Perfect! This is *exactly* what Cauchy got **wrong** in his first attempt at proving that limits of continuous functions were continuous; he was missing uniformity! Ready to work on the proof?\n"
"\n"
"**SIMPLICIO:** Yes, let's do it!"
msgstr ""

#: Game.Levels.L1RealAnalysisStory.L03_rw
msgid "The `rewrite` tactic"
msgstr ""

#: Game.Levels.L22Pset.L04
msgid "The sum of the squares of the first `n` natural numbers is given by the formula:\n"
"$$\\\\sum_{i=0}^{n-1} (i+1)^2 = \\frac{n(n+1)(2n+1)}{6}.$$"
msgstr ""

#: Game.Levels.L18Pset.L01
msgid "DiffOfSeries"
msgstr ""

#: Game.Levels.L17Levels.L03
msgid "Perfect! You've proven a fundamental monotonicity property of series.\n"
"\n"
"## What You've Proven\n"
"\n"
"**Theorem (SeriesOrderThm):** If `a n ≤ b n` for all `n`, then:\n"
"`Series a n ≤ Series b n` for all `n`\n"
"\n"
"That is, term-by-term inequalities are preserved in partial sums.\n"
"\n"
"## The Proof Technique\n"
"\n"
"Your induction proof was beautifully straightforward:\n"
"- **Base case:** Empty sums are equal, so `0 ≤ 0`\n"
"- **Inductive step:** Split each sum using `sum_range_succ`, apply the inductive hypothesis to the first `n` terms, and use `a n ≤ b n` for the last term\n"
"\n"
"The inequality $∑_{k<n} a k + a n ≤ ∑_{k<n} b k + b n$ followed immediately from combining two simpler inequalities!\n"
"\n"
"## Why This Is Powerful\n"
"\n"
"This theorem is the cornerstone of **comparison tests** for series convergence. Here's the typical application:\n"
"\n"
"**Comparison Test Setup:**\n"
"- Suppose `0 ≤ a n ≤ b n` for all `n`\n"
"- Suppose the series `∑ b n` converges to some limit `B`\n"
"\n"
"**Conclusion:** The series `∑ a n` also converges, and `∑ a n ≤ B`.\n"
"\n"
"**Why?** By your theorem, every partial sum satisfies `Series a n ≤ Series b n ≤ B`. So the sequence `Series a n` is monotone increasing (adding positive terms) and bounded above by `B`. Therefore it must converge!\n"
"\n"
"## Taking Limits\n"
"\n"
"An important consequence: if `a n ≤ b n` for all `n`, and both infinite series converge, then:\n"
"`∑_{k=0}^∞ a k ≤ ∑_{k=0}^∞ b k`\n"
"\n"
"This follows by taking limits on both sides of your partial sum inequality. Limits preserve weak inequalities!\n"
"\n"
"## Preview: The Basel Problem\n"
"\n"
"In the next level, we'll use this theorem to prove that the famous **Basel series** converges:\n"
"`∑ k, 1/(k+2)² = 1/4 + 1/9 + 1/16 + 1/25 + ...`\n"
"\n"
"The strategy: compare it with the Leibniz series! Since `1/(k+2)² ≤ 1/((k+1)(k+2))`, your theorem tells us the Basel series has smaller partial sums. Since the Leibniz series converges to 1, the Basel series is bounded above by 1.\n"
"\n"
"Combined with the fact that the Basel series is monotone increasing (adding positive terms), this will prove convergence!\n"
"\n"
"## General Principle\n"
"\n"
"Your theorem exemplifies a key principle in analysis: **order structure is preserved under limits**. This makes inequality reasoning a powerful tool throughout real analysis.\n"
"\n"
"---\n"
"\n"
"**Next:** Time to tackle the Basel Problem—one of the most famous series in mathematical history!"
msgstr ""

#: Game.Levels.L7Levels.L02_SeqOfAbs
msgid "If `a : ℕ → ℝ` converges to `L`, and `b : ℕ → ℝ` is its absolute value, `b n = |a n|` for all `n`, then `b` converges to `|L|`."
msgstr ""

#: Game.Levels.L16Pset.L16Pset2
msgid "# Problem 2: Prove that multiplying a series by a constant scales its sum accordingly."
msgstr ""

#: Game.Levels.L17Levels.L03
msgid "If `a n ≤ b n`, then `∑ k, a n ≤ ∑ k, b n`."
msgstr ""

#: Game.Levels.L24Levels.L03
msgid "Every nonempty set of real numbers that is bounded above has a least upper bound."
msgstr ""

#: Game.Levels.L7Levels.L03_SeqInvLim
msgid "If `a : ℕ → ℝ` converges to `L`, and `b : ℕ → ℝ` is its inverse, `b n = 1 / a n` for all `n`, then `b` converges to `1 / L`, provided `L ≠ 0`."
msgstr ""

#: Game.Levels.L1RealAnalysisStory.L04_ring_nf
msgid "Excellent! You've learned the `ring_nf` tactic.\n"
"\n"
"This tactic is incredibly powerful for algebraic manipulations. It automatically handles all the tedious algebra that would take many steps to do by hand.\n"
"\n"
"Your toolkit now includes:\n"
"- `apply hypothesis_name` for when a hypothesis matches your goal\n"
"- `rfl` for proving something equals itself\n"
"- `rewrite [hypothesis_name]` for rewriting using equalities\n"
"- `ring_nf` for algebraic simplifications and expansions\n"
"\n"
"As we move into real analysis proper, you'll find that `ring_nf` is invaluable for dealing with polynomial expressions, which appear everywhere in calculus!"
msgstr ""

#: Game.Levels.L3Levels.L02_OneOverN
msgid "Since 1 / ε < N, we get N > 0: `have Npos : (0 : ℝ) < N := by linarith [f3, eps_inv_lt_N]`. Again we need to be specific about the casting."
msgstr ""

#: Game.Levels.L6Pset.L6Pset2
msgid "# Problem 2\n"
"\n"
"You know that `h : x = 2 ∧ y = 3 ∧ z = 4`.\n"
"Your goal is to show that: `z = 4`."
msgstr ""

#: Game.Levels.L1RealAnalysisStory.L07_specialize
msgid "The specialize tactic"
msgstr ""

#: Game.Levels.L1RealAnalysisStory.L00_the_problem
msgid "Introduction to Lean"
msgstr ""

#: Game.Levels.L1Pset.L1Pset2
msgid "Show that there exists a constant `c` so that, for any real numbers `x` and `y` with `x ^ 2 + y ^ 2 = 2` and `x * y = 1`, we have `(x + y) ^ 2 = c`."
msgstr ""

#: Game.Levels.L10Pset.L10Pset7
msgid "# Problem 6:\n"
"\n"
"Show that if a sequence has two subsequences that converge to\n"
"different limits, then the sequence itself cannot converge."
msgstr ""

#: Game.Levels.L10Levels.L09_Subseq
msgid "# Level 4: Subsequence Example\n"
"\n"
"We've proven that `(-1)^n` does not converge—it oscillates between -1 and 1 forever. But even though the full sequence diverges, it has subsequences that converge!\n"
"\n"
"**The Goal:** Exhibit a subsequence of `a n = (-1)^n` that converges to some limit `L`.\n"
"\n"
"**The Idea:** Extract the **even-indexed terms**.\n"
"\n"
"Define `σ(n) = 2*n`, which picks out indices 0, 2, 4, 6, 8, ...\n"
"\n"
"Then:\n"
"- `(a ∘ σ)(0) = a(0) = (-1)^0 = 1`\n"
"- `(a ∘ σ)(1) = a(2) = (-1)^2 = 1`\n"
"- `(a ∘ σ)(2) = a(4) = (-1)^4 = 1`\n"
"- `(a ∘ σ)(n) = a(2n) = (-1)^(2n) = 1` for all `n`\n"
"\n"
"So the subsequence is constant: `1, 1, 1, 1, ...` which clearly converges to 1!\n"
"\n"
"**New Tool: The `let` Tactic**\n"
"\n"
"To define `σ` within our proof, we use the `let` tactic. This creates a new variable or function/sequence (unlike `have`, which proves propositions).\n"
"\n"
"**The `fun` Keyword:**\n"
"\n"
"To create a function in Lean, we use `fun`:\n"
"```\n"
"fun x ↦ expression\n"
"```\n"
"This creates a function that takes input `x` and returns `expression`.\n"
"\n"
"The arrow `↦` (type `\\mapsto` or just use `=>`) separates input from output.\n"
"\n"
"Example: `fun x ↦ x ^ 2` is the squaring function.\n"
"\n"
"**Combining `let` and `fun`:**\n"
"\n"
"```\n"
"let σ : ℕ → ℕ := fun n ↦ 2 * n\n"
"```\n"
"\n"
"This defines a function `σ : ℕ → ℕ` by `σ(n) = 2*n`.\n"
"\n"
"**The Proof Structure:**\n"
"\n"
"We need to prove `∃ σ L, Subseq σ ∧ SeqLim (a ∘ σ) L`.\n"
"\n"
"1. Define `σ(n) = 2*n` using `let`\n"
"2. Use `σ` and `L = 1` as our witnesses\n"
"3. Prove two things:\n"
"   - `σ` is a subsequence (strictly increasing)\n"
"   - `a ∘ σ` converges to 1\n"
"\n"
"For part 2, compute `a(2*n) = (-1)^(2*n) = 1`, so `|a(2*n) - 1| = 0 < ε` for any `ε > 0`.\n"
"\n"
"**The Deeper Lesson:**\n"
"\n"
"Even though `(-1)^n` diverges, we can extract convergent behavior by focusing on the even terms (or odd terms). This shows that **subsequences can be better behaved than the original sequence**.\n"
"\n"
"The fact that the even and odd subsequences converge to *different* limits (1 and -1) is exactly what proves the original sequence diverges!"
msgstr ""

#: Game.Levels.L13Levels.L03_MonotoneSubseq
msgid "# Level 1 **Big Boss:**  Monotone Subsequence\n"
"\n"
"Every sequence has hidden order within it. No matter how chaotic a sequence may appear, we can always extract a subsequence that moves consistently in one direction—either always increasing (monotone) or always decreasing (antitone). This beautiful result, part of the classical Bolzano-Weierstrass theory, reveals that disorder is never complete.\n"
"\n"
"Our strategy hinges on a key observation: some positions in a sequence are **peaks**—places from which the sequence never rises again. Either there are arbitrarily many such peaks (unbounded peaks), or there aren't. We'll prove that if peaks are *not* unbounded, then we can construct a monotone (non-decreasing) subsequence by cleverly avoiding the peaks entirely.\n"
"\n"
"## New Definitions\n"
"\n"
"**IsAPeak:** Standing at position `n`, we say it's a peak if we can look down at all future values:\n"
"\n"
"`def IsAPeak {X : Type*} [LinearOrder X] (a : ℕ → X) (n : ℕ) : Prop := ∀ m > n, a m ≤ a n`\n"
"\n"
"**UnBddPeaks:** A sequence has unbounded peaks if for any bound `k`, there's always another peak beyond it:\n"
"\n"
"`def UnBddPeaks {X : Type*} [LinearOrder X] (a : ℕ → X) : Prop := ∀ k, ∃ n > k, IsAPeak a n`\n"
"\n"
"**Conditional definition:** We can define functions by cases using `if h : condition then value₁ else value₂`. The proof `h` of the condition (or its negation) becomes available in each branch.\n"
"\n"
"## The Goal\n"
"\n"
"Prove that if a sequence `a : ℕ → X` does **not** have unbounded peaks, then it has a **monotone** (non-decreasing) subsequence.\n"
"\n"
"The intuition: if peaks eventually stop appearing, the sequence must eventually start climbing. By taking an orbit starting beyond the last peak, each step moves to a position that's not a peak—meaning there's always somewhere higher to go next.\n"
"\n"
"(In the homework, you'll prove the complementary result: sequences *with* unbounded peaks have **antitone** subsequences. Just pick the peaks themselves!)\n"
"\n"
"## New Theorem\n"
"\n"
"**lt_of_not_ge:** If it's not true that `m ≤ n`, then `n < m`.\n"
"\n"
"This simple fact lets us convert a failed inequality into a strict one—essential for working with our conditional definition of the auxiliary sequence.\n"
"\n"
"## Strategy Outline\n"
"\n"
"1. **Extract witnesses:** Use `choose` to get a bound `k` beyond which there are no peaks, and for each `n > k`, get a witness `τ(n) > n` where `a(τ(n)) > a(n)`\n"
"\n"
"2. **Build auxiliary sequence:** Define `τ'(n) = if n ≤ k then n+1 else τ(n)` that grows faster than identity everywhere\n"
"\n"
"3. **Take the orbit:** Let `σ(n) = τ'^[n](k+1)` be the n-fold iteration starting from `k+1`\n"
"\n"
"4. **Verify monotonicity:** Since `σ(n) > k` always, we're always beyond the peaks, so `a(σ(n)) ≤ a(τ'(σ(n))) = a(σ(n+1))`\n"
"\n"
"Each piece builds on techniques from Lecture 12: `choose` for extracting witnesses, orbits for building subsequences, and induction for verification. Now let's make it rigorous!"
msgstr ""

#: Game.Levels.L8Levels.L03_Induction'
msgid "NotEven"
msgstr ""

#: Game.Levels.L22Levels.L01
msgid "# Level 1: Continuous Composition\n"
"\n"
"Welcome to our first exploration of function composition in the context of continuity! After spending considerable time understanding the nuances of uniform convergence and why pointwise convergence fails to preserve continuity, let's start with something reassuring: some properties of continuous functions are indeed well-behaved.\n"
"\n"
"## The Beautiful Truth\n"
"\n"
"**Theorem `Cont_Comp`**: The composition of continuous functions is continuous.\n"
"\n"
"This might seem \"obvious\" from your calculus intuition, but as we've learned, intuition can be misleading in analysis. The beauty of this theorem lies not just in its truth, but in how cleanly the proof works—it's a perfect example of the `ε-δ` method in action.\n"
"\n"
"## Why This Matters\n"
"\n"
"Think about it: every time you write something like $\\sin(\\cos(x))$ or $e^{x^2}$ or $(x^2 + 1)^{3/2}$, you're implicitly using this theorem. Without it, we'd have to verify continuity from scratch for every composite function we encounter!\n"
"\n"
"## The Intuitive Picture\n"
"\n"
"If $g$ is continuous at $x$, then small changes in $x$ produce small changes in $g(x)$. If $f$ is continuous at $g(x)$, then small changes in $g(x)$ produce small changes in $f(g(x))$. Chain these together: small changes in $x$ lead to small changes in $(f \\circ g)(x) = f(g(x))$.\n"
"\n"
"But remember—intuition must be backed by rigorous proof!\n"
"\n"
"## The Strategy\n"
"\n"
"The proof is a beautiful example of the \"intermediate tolerance\" technique:\n"
"\n"
"1. **Engineer demands**: $|(f \\circ g)(x) - (f \\circ g)(c)| < \\varepsilon$\n"
"2. **We rewrite**: This means $|f(g(x)) - f(g(c))| < \\varepsilon$\n"
"3. **Use $f$'s continuity**: Find $\\varepsilon_1 > 0$ such that $|y - g(c)| < \\varepsilon_1 \\Rightarrow |f(y) - f(g(c))| < \\varepsilon$\n"
"4. **Use $g$'s continuity**: Find $\\delta > 0$ such that $|x - c| < \\delta \\Rightarrow |g(x) - g(c)| < \\varepsilon_1$\n"
"5. **Chain them**: If $|x - c| < \\delta$, then $|g(x) - g(c)| < \\varepsilon_1$, so $|f(g(x)) - f(g(c))| < \\varepsilon$\n"
"\n"
"## A Moment of Appreciation\n"
"\n"
"This theorem works so smoothly because we have complete control over both levels of approximation. Compare this to what happens with pointwise convergence—there, the \"inner\" approximation (how quickly $f_n$ approaches $F$) happens at different rates at different points, breaking our ability to chain the estimates uniformly.\n"
"\n"
"## Your Challenge\n"
"\n"
"Prove that if $f : \\mathbb{R} \\to \\mathbb{R}$ and $g : \\mathbb{R} \\to \\mathbb{R}$ are continuous, then $f \\circ g$ is continuous.\n"
"\n"
"**Lean signature**: `FunCont f → FunCont g → FunCont (f ∘ g)`\n"
"\n"
"Ready to see the $\\varepsilon$-$\\delta$ method at its finest? Let's compose some functions!"
msgstr ""

#: Game.Levels.L3PsetIntro
msgid "# Problem Set 3\n"
"\n"
"Good luck!"
msgstr ""

#: Game.Levels.L3Levels.L01_ArchProp
msgid "Let's compare now to the purely natural language proof:\n"
"\n"
"## Natural Language Proof of the Archimedean Property\n"
"\n"
"**Theorem**: For any positive real number ε > 0, there exists a natural number N such that 1 / ε < N.\n"
"\n"
"**Proof**:\n"
"Let ε > 0 be given. We need to find a natural number N such that 1 / ε < N.\n"
"\n"
"Use the value N = ⌈1 / ε⌉₊ + 1, where ⌈·⌉₊ denotes the natural number ceiling function.\n"
"\n"
"Since ε > 0, we have 1 / ε > 0. By the definition of the natural number ceiling function, we know that:\n"
"\n"
"1 / ε ≤ ⌈1 / ε⌉₊\n"
"\n"
"Now, since ⌈1 / ε⌉₊ is a natural number and N = ⌈1 / ε⌉₊ + 1, we have:\n"
"\n"
"⌈1 / ε⌉₊ < ⌈1 / ε⌉₊ + 1 = N\n"
"\n"
"Combining these inequalities, we get that:\n"
"\n"
"1 / ε ≤ ⌈1 / ε⌉₊ < N\n"
"\n"
"Therefore, 1 / ε < N, which completes the proof. □\n"
"\n"
"**Significance**: The Archimedean Property is fundamental to analysis because it ensures that the real numbers have no \"infinite\" or \"infinitesimal\" elements. It guarantees that we can always find natural numbers large enough to dominate any given positive real number when we take their reciprocals. This property is essential for many limit processes and is equivalent to the completeness of the real numbers in certain formulations of real analysis.\n"
"\n"
"## Review of Common Pitfalls\n"
"\n"
"- **Don't use the regular ceiling function `⌈·⌉`** - it returns integers, not natural numbers!\n"
"- **Watch out for casting issues** - if `bound` isn't working, try `push_cast` first\n"
"- **The addition `⌈1 / ε⌉₊ + 1` happens in `ℕ`**, then gets cast to `ℝ` - this is why we need `push_cast`\n"
"\n"
"**Historical Note**: While often attributed to Archimedes (c. 287-212 BCE), this property was likely known to Eudoxus (c. 408-355 BCE) and appears in Euclid's *Elements*. Archimedes used a version of this principle in his method of exhaustion, particularly in calculating areas and volumes by approximating them with polygons of increasing numbers of sides."
msgstr ""

#: Game.Levels.L19Levels.L02
msgid "Rearrangements"
msgstr ""

#: Game.Levels.L1RealAnalysisStory.L00_the_problem
msgid "If we know that $x = 5$, then we can prove that $x = 5$."
msgstr ""

#: Game.Levels.L18Lecture
msgid "Lecture 18: Infinite Addition"
msgstr ""

#: Game.Levels.L12PsetIntro
msgid "Pset 12"
msgstr ""

#: Game.Levels.L15PsetIntro
msgid "Pset 15"
msgstr ""

#: Game.Levels.L19Levels.L03
msgid "If `s₁ ⊆ s₂`, then `∑ x ∈ s₂ \\ s₁, f x + ∑ x ∈ s₁, f x = ∑ x ∈ s₂, f x`."
msgstr ""

#: Game.Levels.L5Levels.L01_DoubleSeqConv
msgid "Apply the absolute value of products: `have abs_factor : |2 * (a n - L)| = |2| * |a n - L| := by apply abs_mul`"
msgstr ""

#: Game.Levels.L7Levels.L04_ByCases
msgid "# Level 5: Case Analysis Without Existing Hypotheses\n"
"\n"
"## The Need for `by_cases`\n"
"\n"
"You've already learned how to use `cases'` to handle disjunctions when you have a hypothesis\n"
"`h : P ∨ Q`. This allows you to split your proof into two branches: one where you assume `P`\n"
"is true, and another where you assume `Q` is true.\n"
"\n"
"But what if you need to perform case analysis on a statement that isn't already among your\n"
"hypotheses? Sometimes you need to consider whether a certain proposition is true or false,\n"
"even when you haven't been explicitly told which case holds.\n"
"\n"
"This is where the **law of excluded middle** comes in: for any proposition `P`, either `P` is\n"
"true or `¬P` is true. The `by_cases` tactic allows you to exploit this fundamental logical\n"
"principle directly in your proofs.\n"
"\n"
"Just so you know: the law of excluded middle is somewhat controversial in certain mathematical\n"
"circles. \"Constructivist\" mathematicians argue that to prove `P ∨ ¬P`, you should need to either\n"
"construct a proof of `P` or construct a proof of `¬P`, not merely assert that one of these must be true.\n"
"However, among mainstream mathematicians (and in classical logic, which Lean allows),\n"
"the law of excluded middle is accepted without question. For our purposes in real analysis,\n"
"we'll use it freely, as it's an incredibly powerful and natural tool for organizing proofs.\n"
"\n"
"## How by_cases Works\n"
"\n"
"The `by_cases` tactic has the syntax:\n"
"\n"
"`by_cases h : fact`\n"
"\n"
"where `h` is the name you choose for the new hypothesis, and `fact` is the proposition you\n"
"want to analyze. This creates two subgoals:\n"
"- **First subgoal:** Assume `fact` is true, giving you hypothesis `h : fact`\n"
"- **Second subgoal:** Assume `fact` is false, giving you hypothesis `h : ¬fact`\n"
"\n"
"You must prove your goal in both cases.\n"
"\n"
"## When to Use by_cases\n"
"\n"
"Use `by_cases` when:\n"
"- You need to consider whether some condition holds, but it's not already a hypothesis\n"
"- Different proof strategies apply depending on whether a statement is true or false\n"
"- You need to handle edge cases (like checking if a number equals zero)\n"
"- You want to prove a theorem with weaker assumptions by splitting into cases\n"
"\n"
"## A Motivating Example\n"
"\n"
"In this level, we'll prove a generalization of `EventuallyGeHalfLimPos`. The previous version\n"
"required the assumption `L ≠ 0`. But what if we want to prove the result without that\n"
"assumption? We can use `by_cases` to split into two cases:\n"
"- If `L = 0`, the result is trivially true (since `|L|/2 = 0`)\n"
"- If `L ≠ 0`, we can apply our previous theorem\n"
"\n"
"This demonstrates how `by_cases` allows us to handle all possibilities systematically, making\n"
"our theorems more general and our proofs more robust.\n"
"\n"
"## New Tools You'll Need\n"
"\n"
"### `by_cases`\n"
"The `by_cases` tactic allows you to split a proof into two cases based on whether a\n"
"proposition is true or false.\n"
"\n"
"**Syntax:** `by_cases h : P`\n"
"- Creates two subgoals\n"
"- First subgoal has hypothesis `h : P`\n"
"- Second subgoal has hypothesis `h : ¬P`"
msgstr ""

#: Game.Levels.L19Levels.L02
msgid "If `σ` is a `Rearrangement`, then for any `M`, there is an `N`, so that,\n"
"  for all `n ≥ N`, the `range M` is contained in `image σ (range n)`."
msgstr ""

#: Game.Levels.L1RealAnalysisStory.L00_the_problem
msgid "The `apply` tactic solves a goal when one of the hypotheses is the same as the goal. The syntax is `apply hypothesis_name`"
msgstr ""

#: Game.Levels.L24Lecture
msgid "Lecture 24: Topology"
msgstr ""

#: Game.Levels.L21Levels.L08
msgid "# Great Work!\n"
"\n"
"You proved that `f(x) = x² - 1` is continuous at **every** point in ℝ. This means:\n"
"- The function has no jumps, breaks, or discontinuities anywhere\n"
"- Small changes in input always produce small changes in output\n"
"- You can trace the entire graph without lifting your pen\n"
"\n"
"## The Technical Triumph\n"
"\n"
"The key challenge was making your `δ` depend on the point `x` where you're proving continuity. Unlike derivatives where `δ = ε` worked universally, continuity required the more sophisticated choice:\n"
"\n"
"`δ = min(1, ε / (|2x| + 1))`\n"
"\n"
"This elegant formula ensures that:\n"
"- `|t - x| < 1` controls how far `t` can be from `x`\n"
"- The factor `|2x| + 1` accounts for how the function's \"sensitivity\" changes at different points\n"
"- The `min` operation balances both constraints perfectly\n"
"\n"
"## From Specific to Universal\n"
"\n"
"Notice the beautiful progression through all four levels:\n"
"\n"
"1. **Level 1:** Sequential limits ↔ Function limits (foundational equivalence)\n"
"2. **Level 2:** Derivative at one point (local linear behavior)\n"
"3. **Level 3:** Derivatives everywhere (global differentiability)\n"
"4. **Level 4:** Continuity everywhere (global continuity)\n"
"\n"
"You've built a complete picture of how polynomials behave!\n"
"\n"
"## The Hierarchy of Smoothness\n"
"\n"
"You've now established that `f(x) = x² - 1` is:\n"
"- **Continuous everywhere** (what you just proved)\n"
"- **Differentiable everywhere** (from Level 3)\n"
"\n"
"This illustrates a fundamental hierarchy: differentiability implies continuity. Functions that have derivatives must be continuous, but continuous functions need not have derivatives everywhere.\n"
"a"
msgstr ""

#: Game.Levels.L18Pset.L08
msgid "# Level 8: `BddSeriesEven`\n"
"\n"
"Prove `BddSeriesEven`:\n"
"\n"
"You might find the theorem `sum_range_succ'` useful. It is like `sum_range_succ`, but\n"
"pulls out the first term instead of the last."
msgstr ""

#: Game.Levels.L18Pset.L04
msgid "CoherenceOfReals"
msgstr ""

#: Game.Levels.L18Pset.L02
msgid "Series_abs_add"
msgstr ""

#: Game.Levels.L16Levels.L01_check
msgid "`(a : ℕ → ℝ) (L : ℝ) : Prop := SeqLim (Series a) L`\n"
"\n"
"If a sequence `a : N → ℝ` converges to `L`,\n"
"we say that `SeriesLim a L` holds."
msgstr ""

#: Game.Levels.L6Pset.L6Pset5
msgid "Done. (Hopefully you didn't do that by hand, but rather quoted -- twice -- a theorem that we recently proved?)"
msgstr ""

#: Game.Levels.L20Levels.L04
msgid "# Level 4: Sequential Criterion for Limits\n"
"\n"
"We now have two notions of limits in our arsenal:\n"
"1. **Function limits:** `FunLimAt f L c` means `f(x) → L` as `x → c`\n"
"2. **Sequence limits:** `SeqLim x L` means `xₙ → L` as `n → ∞`\n"
"\n"
"Could these concepts be connected? It's **mathematics**, how could they not!\n"
"\n"
"In this level, we'll prove the first half of the **Sequential Criterion for Limits**.\n"
"\n"
"## The Sequential Criterion (Forward Direction)\n"
"\n"
"**Theorem:** If `f` has limit `L` at `c`, then for *every* sequence `(xₙ)` with `xₙ → c` and `xₙ ≠ c`, we have `f(xₙ) → L`.\n"
"\n"
"In other words: function limits can be **tested** using sequences!\n"
"\n"
"## Why This Matters\n"
"\n"
"This theorem is incredibly useful because:\n"
"- It connects two different limit concepts\n"
"- It lets us use sequence intuition to understand function limits\n"
"- It may be easier to work with certain sequences than with the `ε-δ` definition\n"
"\n"
"## The Proof Strategy\n"
"\n"
"**Given:** `FunLimAt f L c` and a sequence `(xₙ)` with `xₙ → c` and `xₙ ≠ c`.\n"
"\n"
"**Want:** To show `f(xₙ) → L`, i.e., for all ε > 0, eventually `|f(xₙ) - L| < ε`.\n"
"\n"
"**How:**\n"
"1. Given ε > 0, use `FunLimAt` to get δ > 0 such that `|x - c| < δ` and `x ≠ c` implies `|f(x) - L| < ε`\n"
"2. Use `SeqLimit` to get N such that for all n ≥ N, we have `|xₙ - c| < δ`\n"
"3. For n ≥ N, we know `xₙ ≠ c` and `|xₙ - c| < δ`, so `|f(xₙ) - L| < ε`\n"
"\n"
"## Your Challenge\n"
"\n"
"Prove the forward direction of the sequential criterion:\n"
"\n"
"`FunLimAt f L c → (∀ x : ℕ → ℝ, (∀ n, x n ≠ c) → SeqLimit x c → SeqLimit (fun n ↦ f (x n)) L)`\n"
"\n"
"**Hint:** After introducing all the hypotheses, introduce `ε` and `hε`. Use `hf` with `ε` to get `δ` and its properties. Then use `hx` with `δ` to get `N`. Use this `N` to show that the sequence `f(xₙ)` converges to `L`."
msgstr ""

#: Game.Levels.L1RealAnalysisStory.L08_choose
msgid "# Extracting information from existential quantifiers\n"
"\n"
"Now let's learn the counterpart to `use`. You know that if you have `∃` in the goal, you write `use` to provide a specific value.\n"
"\n"
"But suppose you have a *hypothesis* that says \"there exists a real number `c` such that `f (c) = 2`\". In Lean, this looks like:\n"
"`h : ∃ (c : ℝ), f c = 2`\n"
"\n"
"And say you want to prove that \"there exists a real number `c` such that `(f c)^2 = 4`\".\n"
"\n"
"Again, you can't just say `apply h` because these are different statements.\n"
"If you know from `h` that at least one such `c` exists, how do you *choose* one?\n"
" The name of this command is... `choose`.\n"
"\n"
"The syntax for `choose` is as follows:\n"
"\n"
"`choose c hc using h`.\n"
"\n"
"You need to give a name to both the value of `c`, and to the hypothesis with which `c` is bundled. Here we named it `hc` (a hypothesis about `c`).\n"
"\n"
"You should be able to figure out how to solve the goal from here."
msgstr ""

#: Game.Levels.L12Levels.L02_IterateGap
msgid "## What You've Accomplished\n"
"\n"
"You've proven the technical engine that drives the fundamental theorem about bounded monotone sequences. This lemma reveals exactly how persistent gaps accumulate under iteration - linearly, predictably, and inevitably.\n"
"\n"
"## The Mathematical Machinery\n"
"\n"
"The proof demonstrates how several sophisticated techniques work together:\n"
"- **Induction** to handle the iterative structure\n"
"- **Monotonicity** to control the relationships between intermediate points\n"
"- **The gap condition** applied at each iteration step\n"
"- **Telescoping inequalities** to accumulate the growth\n"
"\n"
"This is real analysis in action: taking local properties and scaling them up to global phenomena through careful mathematical reasoning.\n"
"\n"
"## Why Linear Accumulation Matters\n"
"\n"
"The key insight is that gaps don't just accumulate - they accumulate *linearly*. This linear growth `k * ε` is what makes the contradiction with boundedness inevitable.\n"
"\n"
"## Completing the Circle\n"
"\n"
"With this lemma proven, the main theorem is now complete. You've seen how:\n"
"1. **Level 1:** Iteration extracts monotonic subsequences from chaotic growth\n"
"2. **Level 2:** Contradiction converts persistent gaps into bounded violation\n"
"3. **Level 3:** Technical precision makes the gap accumulation rigorous\n"
"\n"
"Each piece was essential, and together they form a complete argument about a fundamental property of ordered systems.\n"
"\n"
"## The Broader Pattern\n"
"\n"
"You've mastered a proof technique that appears throughout analysis: assume pathological behavior exists, extract witnesses using choice principles, iterate to amplify the pathology until it contradicts known constraints. This pattern - *local pathology + iteration + contradiction* - is one of the most powerful tools in real analysis.\n"
"\n"
"The orbit construction from Level 1, the contradiction framework from Level 2, and the inductive gap accumulation from Level 3 will serve you well in advanced mathematics."
msgstr ""

#: Game.Levels.L18Pset.L05
msgid "# Level 5: `SeqEvenOdd`\n"
"\n"
"Prove `SeqEvenOdd`:\n"
"\n"
"## New theorem: `even_or_odd`"
msgstr ""

#: Game.Levels.L18Pset.L10
msgid "DiffGoesToZero"
msgstr ""

#: Game.Levels.L22Levels.L03
msgid "# Level 3 Conclusion: The Art of Exact Computation\n"
"\n"
"Bravo! You've just completed your first rigorous integration proof—and what a journey it was! You didn't just compute an integral; you built it from the ground up using the fundamental definition, proving that the intuitive notion of \"area under a curve\" has a precise mathematical meaning.\n"
"\n"
"## What You Just Accomplished\n"
"\n"
"You proved that $\\int_a^b x \\, dx = \\frac{b^2 - a^2}{2}$ using nothing but:\n"
"- The definition of integration as a limit of Riemann sums\n"
"- Careful algebraic manipulation of finite sums\n"
"- The Archimedean property to control convergence\n"
"\n"
"This is **pure mathematics**—no hand-waving, no appeals to geometric intuition, just rigorous logical reasoning.\n"
"\n"
"## The Beauty of Exact Computation\n"
"\n"
"Look back at your proof's centerpiece calculation:\n"
"\n"
"`RiemannSum (fun x ↦ x) a b n - (b² - a²)/2 = (b - a)²/(2n)`\n"
"\n"
"This isn't an approximation or estimate—it's an **exact formula**. You showed that the error between the $n$-th Riemann sum and the true integral is precisely $(b-a)^2/(2n)$. As $n \\to \\infty$, this error vanishes at the predictable rate of $1/n$.\n"
"\n"
"This kind of exact computation is one of the most satisfying experiences in mathematics!\n"
"\n"
"## The Summation Symphony\n"
"\n"
"Your proof orchestrated a beautiful sequence of summation identities:\n"
"\n"
"1. **Decomposition**: `sum_add_distrib` split the Riemann sum into manageable pieces\n"
"2. **Constant handling**: `sum_const` and `card_range` evaluated the trivial sum\n"
"3. **Factor extraction**: `sum_div` and `sum_mul` isolated the interesting terms\n"
"4. **The grand finale**: `sum_range_add_one` gave you the exact value $\\frac{n(n+1)}{2}$\n"
"\n"
"Each step was essential, and the final algebraic simplification revealed the beautiful error term $(b-a)^2/(2n)$.\n"
"\n"
"## Riemann's Vision Realized\n"
"\n"
"You've just walked in Riemann's footsteps! In the 1850s, he revolutionized calculus by showing that \"area under a curve\" could be defined precisely using limits. Your proof demonstrates exactly how this works for the simple but fundamental case $f(x) = x$.\n"
"\n"
"Before Riemann, integration was largely geometric intuition. After Riemann (and after your proof!), integration is **analysis**—the rigorous study of limits.\n"
"\n"
"## The Connection to Uniformity\n"
"\n"
"Notice something beautiful: this integration proof connects to everything you've learned about convergence. The sequence of Riemann sums converges to the integral, and the rate of convergence is **uniform** across all intervals $[a,b]$ with the same length $(b-a)$.\n"
"\n"
"The error term $(b-a)^2/(2n)$ depends only on the interval length, not on the specific location or any pathological behavior. This uniformity is why integration of continuous functions works so cleanly.\n"
"\n"
"## Technical Mastery: The Archimedean Finale\n"
"\n"
"Your use of the Archimedean property at the end was masterful:\n"
"\n"
"`choose N hN using ArchProp (show 0 < 2 * ε / (b - a)^2 by bound)`\n"
"\n"
"This single line encapsulates a profound idea: for any desired accuracy $\\varepsilon$, you can find $N$ large enough that $\\frac{(b-a)^2}{2N} < \\varepsilon$. The Archimedean property guarantees that such an $N$ exists—completing the rigorous proof that your sequence converges.\n"
"\n"
"## From Specific to General\n"
"\n"
"While you proved integrability for just $f(x) = x$, you've learned the **method** that works for all \"nice\" functions:\n"
"\n"
"1. Compute the Riemann sum exactly using summation identities\n"
"2. Show the difference from the proposed integral has a specific form\n"
"3. Use properties of real numbers (like the Archimedean property) to show this difference vanishes\n"
"\n"
"This template will serve you well for more complex integrals!\n"
"\n"
"## The Deeper Mathematical Lesson\n"
"\n"
"This level taught you that rigorous mathematics often involves:\n"
"- **Exact computation** rather than just estimation\n"
"- **Algebraic virtuosity** with summation formulas\n"
"- **Patience** with detailed calculations that reveal deeper truths\n"
"\n"
"The final result $\\int_a^b x \\, dx = \\frac{b^2-a^2}{2}$ is the same as in calculus, but now you **know why it's true** at the foundational level.\n"
"\n"
"## A Moment of Historical Perspective\n"
"\n"
"You've just completed work that would have impressed the great analysts of the 19th century. The transition from intuitive calculus to rigorous analysis was one of the major mathematical achievements of that era, and you've experienced this transition firsthand.\n"
"\n"
"## Looking Forward: The Integration Universe\n"
"\n"
"Your success with $\\int x \\, dx$ opens the door to the entire theory of integration:\n"
"- More complex polynomials (using similar summation techniques)\n"
"- Transcendental functions (requiring different approaches)\n"
"- Functions that aren't integrable (where the Riemann sum limits don't exist)\n"
"- Advanced integration theories (Lebesgue integration, measure theory)\n"
"\n"
"You now understand integration not as a collection of techniques, but as a profound concept about **limits and convergence**.\n"
"\n"
"## The Ultimate Achievement\n"
"\n"
"You've proven that one of the most basic operations in calculus—computing $\\int x \\, dx$—rests on sophisticated foundations involving:\n"
"- Sequence convergence\n"
"- Algebraic manipulation\n"
"- Properties of real numbers\n"
"- Careful logical reasoning\n"
"\n"
"This is **analysis**—the art of making calculus rigorous. And you've mastered a beautiful piece of it.\n"
"\n"
"## Final Reflection\n"
"\n"
"Integration bridges the discrete (Riemann sums) and the continuous (the integral). Your proof shows exactly how this bridge is built: through the limiting process that you've now seen in multiple contexts throughout this lecture.\n"
"\n"
"From function composition to uniform convergence to integration, you've seen the theme repeated: **the right kind of limit preserves the properties we care about**.\n"
"\n"
"Congratulations on completing this mathematical journey! You've moved from calculus student to analyst. The precise, rigorous, beautiful world of real analysis is now yours to explore. 🎯✨\n"
"\n"
"*Ready for even more challenging integrals? The techniques you've mastered will serve as your foundation!*"
msgstr ""

#: Game.Levels.L17Levels.L04
msgid "If `a : ℕ → ℝ` is Monotone and bounded, then `SeqConv a`."
msgstr ""

#: Game.Levels.L1RealAnalysisStory.L04_ring_nf
msgid "The binomial expansion: $(x + y)^3 = x^3 + 3x^2y + 3xy^2 + y^3$."
msgstr ""

#: Game.Levels.L6Levels.L06_Squeeze
msgid "Big Boss : Squeeze Theorem"
msgstr ""

#: Game.Levels.L24Pset.L01
msgid "# Level 1: Lipschitz implies Uniformly Continuous\n"
"\n"
"A function `f : ℝ → ℝ` is called *Lipschitz* if there exists a constant `K > 0` such that for all `x, y ∈ ℝ`,\n"
"\n"
"`|f(y) - f(x)| ≤ K * |y - x|`.\n"
"\n"
"In this problem, you will prove that every Lipschitz function is uniformly continuous."
msgstr ""

#: Game.Levels.L1Pset.L1Pset4
#: Game.Levels.L3Pset.L3Pset4
#: Game.Levels.L6Pset.L6Pset4
#: Game.Levels.L8Pset.L8Pset4
#: Game.Levels.L10Pset.L10Pset5
msgid "Problem 4"
msgstr ""

#: Game.Levels.L10Pset.L10Pset2
msgid "# Problem 1:\n"
"\n"
"\n"
"Prove the Theorem `LimZeroTimesBdd`: if a sequence `a n` converges to `0`, and the sequence `b n` is merely bounded (not necessarily convergent!), then the product\n"
"`a * b` converges to `0`."
msgstr ""

#: Game.Levels.L12Levels.L01_MonotoneBdd
msgid "Monotone and Bounded Implies Cauchy"
msgstr ""

#: Game.Levels.L10Levels.L08_Mono
msgid "Subsequences"
msgstr ""

#: Game.Levels.L22Lecture
msgid "Lecture 22: Uniformity"
msgstr ""

#: Game.Levels.L19Levels.L04
msgid "Conditional Convergence Theorem"
msgstr ""

#: Game.Levels.L9Levels.L04_FiniteSums
msgid "Finite Sums"
msgstr ""

#: Game.Levels.L3Levels.L02_OneOverN
msgid "# Level 2: Our First Real Limit\n"
"\n"
"*Congratulations!* You've just proved the Archimedean Property. Now let's use it to prove something genuinely interesting: our first non-trivial limit.\n"
"\n"
"## The Goal: Proving that `1 / n → 0`\n"
"\n"
"We want to prove that the sequence `a(n) = 1 / n` converges to `0` as `n` approaches infinity. This is intuitively obvious—as `n` gets larger, `1 / n` gets smaller and approaches `0`. But how do we make this rigorous using the `ε`-`N` definition of limits?\n"
"\n"
"**Theorem**: The sequence `a(n) = 1 / n` converges to `0`.\n"
"\n"
"This might seem straightforward, but let's see it as a test of the definition.\n"
"\n"
"## Recall: The Definition of Sequential Convergence\n"
"\n"
"A sequence `a : ℕ → ℝ` converges to a limit `L` (written `SeqLim a L`) if:\n"
"\n"
"**For every `ε > 0`, there exists `N : ℕ` such that for all `n ≥ N`, `|a(n) - L| < ε`**\n"
"\n"
"In formal notation: `∀ ε > 0, ∃ N, ∀ n ≥ N, |a(n) - L| < ε`\n"
"\n"
"For our specific case with `a(n) = 1 / n` and `L = 0`, this becomes:\n"
"`∀ ε > 0, ∃ N, ∀ n ≥ N, |1 / n - 0| < ε`\n"
"\n"
"## The Natural Language Proof Strategy\n"
"\n"
"Here's how we'll prove this step by step:\n"
"\n"
"**Step 1**: Let `ε > 0` be given. (This will correspond to `intro ε hε`)\n"
"\n"
"**Step 2**: We need to find `N` such that for all `n ≥ N`, we have `1 / n < ε`.\n"
"\n"
"**Key insight**: We need `1 / n < ε`, which is equivalent to `1 / ε < n` (since both sides are positive). So we need `n` to be larger than `1 / ε`.\n"
"When our Engineer requests the tolerance of `ε = 1/100`, the Machinist replies, ok, I can do that, but I'll need `N = 1 / ε = 100` days in my factory.\n"
"\n"
"\n"
"**Step 3**: That's exactly why we developed the Archimedean Property! It tells us that there exists some natural number `N` such that `1 / ε < N`.\n"
"Rather than reproving that from scratch, we can simply quote this fact;\n"
"then\n"
"we'll choose such an `N` and use it.\n"
"\n"
"**Step 4**: Now let `n ≥ N` be given. We have:\n"
"- `1 / ε < N` (by our choice of `N`)\n"
"- `N ≤ n` (by assumption)\n"
"- Therefore: `1 / ε < N ≤ n`, so `1 / ε < n`\n"
"- Taking reciprocals (and flipping the inequality): `1 / n < ε`\n"
"\n"
"**Step 5**: Since `|1 / n - 0| = |1 / n| = 1 / n < ε`, we're done! □\n"
"\n"
"## The Lean Implementation Challenges\n"
"\n"
"### Challenge 1: Cross-Multiplying Fractions\n"
"Our key step is showing that `1 / n < ε`. In paper mathematics, we'd simply cross-multiply to get `1 < n * ε`. But Lean is very careful about division by zero, so we can't just cross-multiply willy-nilly.\n"
"\n"
"**The Problem**: We want to go from `1 / n < ε` to `1 < n * ε`, but this is only valid if `n > 0` and `ε > 0`.\n"
"\n"
"**Solution**: The `field_simp` tactic handles this automatically! It will clear denominators by cross-multiplying, but only after it can verify that all denominators are positive (or at least non-zero).\n"
"\n"
"### Challenge 2: Linear Arithmetic\n"
"Once we've cleared the fractions, we need to combine various inequalities like:\n"
"- `1 / ε < N` (from the Archimedean Property)\n"
"- `N ≤ n` (our assumption)\n"
"- `1 < n * ε` (our goal after clearing denominators)\n"
"\n"
"For some reason, the `bound` tactic doesn't always handle these linear combinations well, especially when they involve multiplication by variables.\n"
"\n"
"**Solution**: The `linarith` tactic is specifically designed for linear arithmetic. It can take a list of hypotheses and solve goals that follow from linear combinations of those hypotheses.\n"
"\n"
"### Challenge 3: Explicit Type Casting\n"
"Remember those mysterious up arrows `↑` from the last level? They're back! When we write `1 / n`, Lean sees this as `1 / ↑n` where `n` starts as a natural number but needs to be cast as a real number.\n"
"\n"
"Sometimes we have to be specific about what type of casting to use. The expression `1 / ↑n` could be ambiguous—are we casting to integers, rationals, reals, or something else?\n"
"\n"
"**Solution**: Instead of an up arrow, we can specify the casting explicitly with this syntax: `(n : ℝ)`. This tells Lean exactly what type we want to cast `n` to, in this case, the reals. This eliminates ambiguity and makes your proofs more precise.\n"
"\n"
"### Challenge 4: Casting in Tactic Applications\n"
"Sometimes you want to apply a tactic or theorem, but the types don't quite match because of casting issues. For example, you might have the hypothesis that `N ≤ n` where `n, N` are naturals, but `bound` or `linarith` are searching for a proof that `(N : ℝ) ≤ (n : ℝ)` as reals.\n"
"\n"
"**Solution**: The `exact_mod_cast` tactic is like `apply`, but it automatically handles the type coercions for you. If you're trying to prove `(N : ℝ) ≤ (n : ℝ)`, and you have the hypothesis `h : N ≤ n` (as naturals), then you can write: `exact_mod_cast h`. Lean will look at `h`\n"
"and realize, oh it's exactly what you're trying to prove, but just\n"
"cast to a different number system; and it'll figure out the proof from there.\n"
"\n"
"## New Tools You'll Need\n"
"\n"
"- **`field_simp`**: Clears denominators by cross-multiplying, but only when it can prove the denominators are non-zero. This is the key to handling fractional inequalities safely.\n"
"\n"
"- **Arithmetic with inequalities**: You might also find the `linarith` tactic helpful. It is a very powerful, general tactic like `ring_nf`, but instead of proving algebraic *identities*, it proves *inequalities* involving \"linear arithmetic\" on the specified hypotheses. For example,\n"
"if you have as hypotheses: `h₁ : X ≤ Y`, `h₂ : 2 * Y ≤ Z`,\n"
"and your Goal is to prove that `2 * X ≤ Z`, then\n"
"simply calling `linarith [h₁, h₂]` will do the trick. So add as many inequality hypotheses to your Game Board as you may need, and then call `linarith` on them to prove a Goal. I find that `linarith` is best called at the very end, when you've assembled all your facts and are ready to close a Goal (but it has many other uses as well, as you'll see).\n"
"\n"
"- **Explicit casting `(n : ℝ)`**: Tells Lean exactly what type to use, eliminating ambiguity in expressions like `1 / n`. You only need to cast\n"
"once in any expression, and Lean will automatically cast everything else.\n"
"For example, you can say `(0 : ℝ) < N`, and Lean will figure out that\n"
"the `0` you mean is a real number, and so, to compare that with `N`,\n"
"the latter too must be cast to the reals.\n"
"\n"
"- **`exact_mod_cast`**: Automatically handles type coercions between different number types (ℕ, ℤ, ℚ, ℝ), when the Goal is *exactly*\n"
"what you're trying to prove, just needs to get coerced.\n"
"\n"
"\n"
"## Pro Tips for This Level\n"
"\n"
"1. **Use `change`** to convert `SeqLim a 0` to its definition\n"
"2. **Apply the Archimedean Property** to get the existence of an `N`\n"
"3. **Use `choose`** to extract the `N` from the existential statement\n"
"4. **Establish positivity first** before using `field_simp`\n"
"5. **Work step by step** - don't try to do everything at once!\n"
"\n"
"## What Makes This Non-Trivial?\n"
"\n"
"Unlike the constant sequence (which was essentially definitional), this proof requires:\n"
"- **The Archimedean Property** to find a suitable `N`\n"
"- **Careful type management** between `ℕ` and `ℝ`\n"
"- **Positivity arguments** to handle division\n"
"- **Inequality manipulation** to connect our bounds\n"
"\n"
"This is a perfect example of how even \"obvious\" mathematical facts require sophisticated machinery to prove rigorously!"
msgstr ""

#: Game.Levels.L20Pset.L04
msgid "Bounded Near Limit"
msgstr ""

#: Game.Levels.L18Levels.L02
msgid "If `a : ℕ → ℝ` is `Antitone` and `∀ n, 0 ≤ a n`, then the even alternating series `n ↦ ∑ k ∈ range (2n), (-1)^k * a k` is bounded by `a 0`."
msgstr ""

#: Game.Levels.L11PsetIntro
msgid "# Problem Set 11\n"
"\n"
"(Lighter than usual; study for the quiz!)\n"
"\n"
"Good luck!"
msgstr ""

#: Game.Levels.L24Levels.L02
msgid "Heine-Borel Theorem: Part 1b"
msgstr ""

#: Game.Levels.L21Levels.L07
msgid "`(f : ℝ → ℝ) (g : ℝ → ℝ) := ∀ x, FunDerivAt f (g x) x`.\n"
"\n"
"The derivative of `f` is `g` everywhere."
msgstr ""

#: Game.Levels.L7Levels.L04_ByCases
msgid "Prove `EventuallyGeHalfLimPos`, but without the assumption that `L ≠ 0`."
msgstr ""

#: Game.Levels.L12Levels.L00_SubseqIterate
msgid "## What You've Accomplished\n"
"\n"
"You've just proven a fundamental result about extracting monotonic behavior from non-monotonic sequences. By taking the orbit of any sequence that grows faster than the identity, you've shown that iteration naturally produces strictly increasing subsequences.\n"
"\n"
"## The Key Insight\n"
"\n"
"The power of this result lies in the orbit construction: even though `σ` might jump around chaotically, as long as it always moves forward (`n < σ n`), iterating it from any starting point creates a predictable, monotonic pattern. This is the mathematical analogue of how planetary orbits reveal underlying order in seemingly complex celestial mechanics.\n"
"\n"
"## Looking Ahead\n"
"\n"
"This technique will be crucial in future levels. The ability to extract monotonic subsequences from sequences with persistent gaps will allow us to construct a contradiction with boundedness - showing that such gaps must eventually disappear.\n"
"\n"
"The orbit method you've mastered here demonstrates a powerful principle: iteration can transform local properties (like `n < σ n`) into global structure (like strict monotonicity). This pattern appears throughout analysis, where local behavior accumulates into global phenomena."
msgstr ""

#: Game.Levels.L17Lecture
msgid "Lecture 17: Series II"
msgstr ""

#: Game.Levels.L21Levels.L06
msgid "`FunLimAt (fun h ↦ (f (c + h) - f c) / h) L 0`\n"
"\n"
"The derivative of `f` at `x = c` is `L`."
msgstr ""

#: Game.Levels.L25Lecture
msgid "Lecture 25: Swapping Limits and Integrals"
msgstr ""

#: Game.Levels.L20Levels.L01
msgid "## What We've Learned\n"
"\n"
"This first example captures the essence of function limits:\n"
"\n"
"- The limit is about **behavior near a point**, not at the point itself\n"
"- The function `f(x) = (x² - 1)/(x - 1)` is undefined at `x = 1` (in standard mathematics), yet the limit exists!\n"
"- The algebra works out beautifully: for `x ≠ 1`, we can simplify the expression\n"
"- The `ε`-`δ` definition formalizes the intuitive idea of \"getting arbitrarily close\"\n"
"\n"
"Notice how simple our choice of `δ` was: we just took `δ = ε`! This is because after simplification, the difference `|f(x) - L|` equals exactly `|x - c|`. In more complicated examples (like the next level), we'll need to be more clever with our choice of `δ`.\n"
"\n"
"**Key insight:** Limits care about *tendency*, not *destination*.\n"
"\n"
"The real power of this definition becomes clear when we realize that we can study the behavior of functions at points where they're not even defined. This is exactly what makes calculus work—derivatives are limits of difference quotients that are undefined when `h = 0`!"
msgstr ""

#: Game.Levels.L3Levels.L02_OneOverN
msgid "First Real Limit"
msgstr ""

#: Game.Levels.L1Pset.L1Pset1
#: Game.Levels.L1Pset.L1Pset3
#: Game.Levels.L1Pset.L1Pset4
#: Game.Levels.L1Pset.L1Pset5
#: Game.Levels.L2Pset.L2Pset1
#: Game.Levels.L2Pset.L2Pset2
#: Game.Levels.L3Pset.L3Pset1
#: Game.Levels.L3Pset.L3Pset2
#: Game.Levels.L3Pset.L3Pset3
#: Game.Levels.L3Pset.L3Pset4
#: Game.Levels.L4Pset.L4Pset1
#: Game.Levels.L6Pset.L6Pset1
#: Game.Levels.L6Pset.L6Pset2
#: Game.Levels.L6Pset.L6Pset3
#: Game.Levels.L6Pset.L6Pset4
#: Game.Levels.L7Pset.L7Pset1
#: Game.Levels.L7Pset.L7Pset2
#: Game.Levels.L7Pset.L7Pset3
#: Game.Levels.L10Pset.L10Pset2
#: Game.Levels.L10Pset.L10Pset3
#: Game.Levels.L10Pset.L10Pset4
#: Game.Levels.L10Pset.L10Pset5
#: Game.Levels.L10Pset.L10Pset6
#: Game.Levels.L10Pset.L10Pset7
#: Game.Levels.L11Pset.L11Pset1
#: Game.Levels.L15Pset.L15Pset1
msgid "Done."
msgstr ""

#: Game.Levels.L13Levels.L03_MonotoneSubseq
msgid "If you have a proposition `P`, you can say `if P then x else y`."
msgstr ""

#: Game.Levels.L22Pset.L04
msgid "Integral Exercise"
msgstr ""

#: Game.Levels.L18Levels.L02
msgid "If `a : ℕ → ℝ` is `Antitone` and converges to `L`, then for all `n`, `L ≤ a n`. Analogous to `MonotoneLimitBound`."
msgstr ""

#: Game.Levels.L16Lecture
msgid "# Lecture 16: Series"
msgstr ""

#: Game.Levels.L21Levels.L05
msgid "# Congratulations!\n"
"\n"
"You've just proved one of the most powerful and elegant results connecting sequences and function limits!\n"
"\n"
"## What You Accomplished\n"
"\n"
"The **Sequential Criterion (Backward Direction)** establishes that:\n"
"\n"
"*If every sequence test passes, then the function limit exists.*\n"
"\n"
"This is remarkable because it gives us a **sequential characterization** of function limits. We can now think about function limits in two equivalent ways:\n"
"- **ε-δ definition:** Traditional analytical approach\n"
"- **Sequential approach:** Test with all possible sequences\n"
"\n"
"## The Power of Proof by Contradiction\n"
"\n"
"Your proof showcased a beautiful contradiction argument:\n"
"1. **Assume** the function limit doesn't exist\n"
"2. **Construct** a problematic sequence using the failure of the ε-δ definition\n"
"3. **Show** this sequence converges to `c` but `f(xₙ)` doesn't converge to `L`\n"
"4. **Contradiction!** This violates our sequential hypothesis\n"
"\n"
"This technique - constructing counterexample sequences from ε-δ failures - is a fundamental tool in real analysis.\n"
"\n"
"## Why This Matters\n"
"\n"
"Combined with the forward direction, we now have:\n"
"\n"
"**Sequential Criterion for Function Limits (Complete):**\n"
"`FunLimAt f L c ↔ (∀ x : ℕ → ℝ, (∀ n, x n ≠ c) → SeqLim x c → SeqLim (fun n ↦ f (x n)) L)`\n"
"\n"
"This equivalence is incredibly useful because:\n"
"- Sometimes sequences are easier to work with than ε-δ arguments\n"
"- It connects the discrete world (sequences) with the continuous world (functions)\n"
"- It provides a bridge between different areas of analysis\n"
"\n"
"## Looking Ahead\n"
"\n"
"This sequential criterion will be essential for:\n"
"- Proving properties of continuous functions\n"
"- Understanding derivatives (coming up next!)\n"
"- Advanced topics like uniform convergence and compactness\n"
"\n"
"You've mastered a fundamental tool that working mathematicians use regularly. Well done!"
msgstr ""

#: Game.Levels.L22Pset.L01
msgid "Pointwise of Uniform Convergence"
msgstr ""

#: Game.Levels.L19Levels.L02
msgid "A `Rearrangement` `σ : ℕ → ℕ` is a function that is `Injective` and `Surjective`."
msgstr ""

#: Game.Levels.L6Pset.L6Pset5
msgid "# Problem 5\n"
"\n"
"You are given five sequences `a b c d e : ℕ → ℝ`, and you know that\n"
"`a`, `c`, and `e` converge to `L`, and that, for all `n`, `a n ≤ b n ≤ c n ≤ d n ≤ e n`.\n"
"Prove that both `b` and `d` also converge to `L`."
msgstr ""

#: Game.Levels.L12Levels.L02_IterateGap
msgid "Iterated Gaps"
msgstr ""

#: Game.Levels.L1RealAnalysisStory.L07_specialize
msgid "If a function of `x` always equals `x²`, then it equals `t²` when evaluated at `t`."
msgstr ""

#: Game.Levels.L7Pset.L7Pset3
msgid "# Problem 3\n"
"\n"
"Prove `abs_Lipschitz`, obviously without referring to that theorem!\n"
"(Hint: you'll want to break things into cases according to whether `0 ≤ x` or not,\n"
"then systematically use `abs_of_nonneg` and `abs_neg`...)"
msgstr ""

#: Game.Levels.L20Pset.L04
msgid "If `f → L` as `x → c`, then there is an `M > 0` such that\n"
"`|f (x)| < M` near `c`."
msgstr ""

#: Game.Levels.L3Pset.L3Pset4
msgid "# Problem 4\n"
"\n"
"Here's an even more involved limit problem. We've had luck getting `bound` to prove `|X| = X`, especially when there's a hypothesis `h : 0 ≤ X` already available in the list of assumptions. But I've found it not to be reliable, unfortunately. So let me give you one more theorem for your toolchest.\n"
"\n"
"## New Theorem: `abs_of_nonneg`.\n"
"If you have a hypothesis `h : 0 ≤ X` in your toolchest,\n"
"then you can prove that `|X| = X` via:\n"
"\n"
"`have factName : |X| = X := by apply abs_of_nonneg h`."
msgstr ""

#: Game.Levels.L17Pset.L05'
msgid "If `a : ℕ → ℝ` is `Monotone` and has limit `L`, then for all `n`, `a n ≤ L`."
msgstr ""

#: Game.Levels.L16PsetIntro
msgid "# Problem Set 16: Solve these problems in Natural Language:\n"
"\n"
"$\\# 1)$ Let `0 < x < 1`. Prove that the sequence `n ↦ x ^ n` converges to `0` as `n` tends to infinity. [Hint: First prove that the sequence is `Antitone` and bounded from below; therefore it converges to some limit `L`. Notice that the sequence `n ↦ x ^ (2 * n)` is a subsequence of the original, and hence converges to the same limit. On the other hand, `x ^ (2 * n) = (x ^ n) ^ 2`, so this subsequence converges to `L ^ 2`...]\n"
"\n"
"$\\# 2)$ You will prove formally that the finite geometric series satisfies the formula:\n"
"\n"
"`(1 - x) * ∑ k ∈ range n, x ^ k = 1 - x ^ n`.\n"
"\n"
"Assume that `0 < x < 1` and use this to prove that the infinite geometric series\n"
"\n"
"`∑ k, x ^ k`\n"
"\n"
"converges to `1 / (1 - x)`.\n"
"\n"
"$\\# 3)$ Find an explicit formula for the sequence of partial sums of the series\n"
"\n"
"`∑ k, log ((k + 1) / k)`\n"
"\n"
"and determine whether the series converges or diverges."
msgstr ""

#: Game.Levels.L1RealAnalysisStory.L04_ring_nf
msgid "The `ring_nf` tactic puts both sides of an equation into a standard algebraic form and checks if they're equal."
msgstr ""

#: Game.Levels.L1RealAnalysisStory.L06_intro
msgid "Use `intro ε` to introduce the variable, then `intro hε` to introduce the hypothesis `ε > 0`. Then how do you solve the goal?"
msgstr ""

#: Game.Levels.L6Levels.L00_SumOfSeqs
msgid "Big Boss: The Sum of Convergent Sequences"
msgstr ""

#: Game.Levels.L20Levels.L02
msgid "Continuous Functions"
msgstr ""

#: Game.Levels.L6Levels.L02_LeftRight
msgid "# 🎯 Strategic Decision-Making Mastered! 🎯\n"
"\n"
"Excellent! You've now learned how to navigate the fundamental logical choice points in mathematical proof. The `left` and `right` tactics represent one of the most elegant aspects of mathematical reasoning: sometimes proving less is actually more efficient.\n"
"\n"
"**Why This Matters:**\n"
"\"Or\" statements are everywhere in mathematics. Existence proofs often have this flavor -- \"there exists an `x` such that `P(x)` or `Q(x)`\" -— and being able to choose the right branch can dramatically simplify your proof strategy.\n"
"\n"
"**The Art of Mathematical Choice:**\n"
"Notice how in our example, we had information about both `x` and `y`, but we chose to go `right` and use the fact about `y`. This wasn't arbitrary -- it was the path that led directly to our goal. Learning to recognize these opportunities is a key skill in mathematical reasoning.\n"
"\n"
"**Looking Forward:**\n"
"As we continue developing our proof techniques for analysis, you'll find that `left` and `right` combine powerfully with our convergence arguments. Often we'll need to prove statements like \"either the sequence is eventually positive, or it's eventually negative,\" and these tactics will be essential tools in our arsenal.\n"
"\n"
"Mathematics is as much about knowing when to commit to a path as it is about following that path to its conclusion. You're building the judgment to make these strategic choices wisely."
msgstr ""

#: Game.Levels.L6Lecture
msgid "Lecture 6: Algebraic Limit Theorem, Part II"
msgstr ""

#: Game.Levels.L21Levels.L05
msgid "# Level 1: Sequential Criterion for Limits (Backward Direction)\n"
"\n"
"Previously, we proved that function limits imply sequential limits. Now we prove the **converse**: if function values converge for *every* appropriate sequence, then the function has a limit!\n"
"\n"
"## The Sequential Criterion (Backward Direction)\n"
"\n"
"**Theorem:** Suppose that for *every* sequence `(xₙ)` with `xₙ → c` and `xₙ ≠ c`, we have `f(xₙ) → L`. Then `FunLimAt f L c`.\n"
"\n"
"This says: if sequences **test** the limit and all tests pass, then the function limit exists!\n"
"\n"
"## Why This Direction Is Harder\n"
"\n"
"The forward direction was straightforward: we had `δ` from the function limit and used it directly.\n"
"\n"
"For the backward direction, we use **proof by contradiction**:\n"
"- Assume `FunLimAt f L c` is false\n"
"- Then `∃ ε > 0` such that `∀ δ > 0`, `∃ x` with `|x - c| < δ`, `x ≠ c`, but `|f(x) - L| ≥ ε`\n"
"- We'll construct a **problematic sequence** by choosing such an `x` for each `δ = 1/(n+1)`\n"
"- This sequence converges to `c` but `f(xₙ)` does *not* converge to `L`, contradicting our hypothesis!\n"
"\n"
"## The Proof Strategy\n"
"\n"
"**Given:** `∀ x : ℕ → ℝ, (∀ n, x n ≠ c) → SeqLim x c → SeqLim (fun n ↦ f (x n)) L`\n"
"\n"
"**Want:** `FunLimAt f L c`, i.e., `∀ ε > 0, ∃ δ > 0, ∀ x ≠ c, |x - c| < δ → |f(x) - L| < ε`\n"
"\n"
"**Proof by contradiction:**\n"
"1. **Assume negation:** `∃ ε > 0` such that `∀ δ > 0`, the implication fails\n"
"2. **Extract witnesses:** Use `choose` to get `ε` and a function `g` that produces counterexamples\n"
"3. **Construct sequence:** Define `xₙ = g(1/(n+1))` with `|xₙ - c| < 1/(n+1)` and `|f(xₙ) - L| ≥ ε`\n"
"4. **Show convergence:** Prove `xₙ → c` (since `|xₙ - c| < 1/(n+1) → 0`)\n"
"5. **Apply hypothesis:** Get `f(xₙ) → L` from our assumption\n"
"6. **Derive contradiction:** This contradicts `|f(xₙ) - L| ≥ ε > 0`\n"
"\n"
"## Your Challenge\n"
"\n"
"Prove the backward direction of the sequential criterion:\n"
"\n"
"`(∀ x : ℕ → ℝ, (∀ n, x n ≠ c) → SeqLim x c → SeqLim (fun n ↦ f (x n)) L) → FunLimAt f L c`\n"
"\n"
"**Key tactics to use:**\n"
"- `by_contra` to assume the negation\n"
"- `push_neg` to simplify the negated statement\n"
"- `choose` to extract witnesses from existential statements\n"
"- The Archimedean property to handle `1/(n+1) → 0`\n"
"\n"
"**Hint:** The trickiest part is proving that your constructed sequence `xₙ` actually converges to `c`. You'll need to use the Archimedean property to find `N` such that `1/N < δ`, then show that for `n ≥ N`, we have `1/(n+1) ≤ δ`."
msgstr ""

#: Game.Levels.L16Pset.L16Pset3
msgid "The partial sums of the series `∑ k, a k + b k` is equal to that of `∑ k, a k + ∑ k, b k`."
msgstr ""

#: Game.Levels.L1RealAnalysisStory.L04_ring_nf
msgid "The ring_nf tactic"
msgstr ""

#: Game.Levels.L24Levels.L03
msgid "Least Upper Bound Property"
msgstr ""

#: Game.Levels.L20Pset.L03
msgid "Const Times Limit"
msgstr ""

#: Game.Levels.L4Pset.L4Pset1
msgid "# Problem 1\n"
"\n"
"Let `a (n)` be a sequence that alternates between\n"
"`3 - 1 / n` and `1 + 1 / n`. Prove that this sequence diverges.\n"
"\n"
"**Hint:** You may wish to argue using `N` that's slightly\n"
"larger than the smallest possible value.\n"
"\n"
"**Hint 2:** If your desired `have` is a consequence of two facts put together, you can separate them by a semicolon. For example, if you know that `h : X = Y + Z`,\n"
"and you want to add a hypothesis `h' : |X - Y| = |Z|`, which is a combination of rewriting by `h` and a ring operation, then you can say:\n"
"\n"
"`have h' : |X - Y| = |Z| := by rewrite [h]; ring_nf`.\n"
"\n"
"This might come in handy!..."
msgstr ""

#: Game.Levels.L12Pset.L12Pset1
msgid "If `a` is `Antitone`, then `-a` is `Monotone`."
msgstr ""

#: Game.Levels.L17Levels.L01
msgid "Beautiful! You've found an explicit formula for the partial sums of the Leibniz series.\n"
"\n"
"## What You've Proven\n"
"\n"
"**Theorem (LeibnizSeriesFinite):** For `a n = 1 / ((n + 1) * (n + 2))`, we have:\n"
"`∑ k ∈ range n, a k = 1 - 1 / (n + 1)`\n"
"\n"
"## The Power of Telescoping\n"
"\n"
"Your proof used the **telescoping** technique: the terms cancel in pairs, leaving only the first and last pieces. This is one of the most elegant methods in mathematics!\n"
"\n"
"The partial fractions decomposition `1/((k+1)(k+2)) = 1/(k+1) - 1/(k+2)` was the key insight that made everything collapse beautifully.\n"
"\n"
"We can verify the first few partial sums:\n"
"- n=1: `1/2 = 1 - 1/2` ✓\n"
"- n=2: `1/2 + 1/6 = 2/3 = 1 - 1/3` ✓\n"
"- n=3: `2/3 + 1/12 = 3/4 = 1 - 1/4` ✓\n"
"- n=4: `3/4 + 1/20 = 4/5 = 1 - 1/5` ✓\n"
"\n"
"Each partial sum is `n/(n+1)`, steadily approaching 1!\n"
"\n"
"## The Proof Technique\n"
"\n"
"Your induction proof had two key steps:\n"
"1. **Base case:** The empty sum equals `0 = 1 - 1/1` (after checking carefully!)\n"
"2. **Inductive step:** Split off the last term with `sum_range_succ`, apply the hypothesis, and let `field_simp` and `ring_nf` handle the algebra.\n"
"\n"
"Lean's automation made the algebraic manipulation painless!\n"
"\n"
"---\n"
"\n"
"**Historical note:** Leibniz studied many such telescoping series in his work on infinite series in the 1670s-1680s, alongside his development of calculus!"
msgstr ""

#: Game.Levels.L1RealAnalysisStory.L03_rw
msgid "If we know that $x = 2$, then we can prove that $x + y = 2 + y$."
msgstr ""

#: Game.Levels.L9PsetIntro
msgid "Pset 9"
msgstr ""

#: Game.Levels.L24Levels.L01
msgid "# Level 1: Heine-Borel Theorem: Part 1a\n"
"\n"
"**The Goal**: We're starting our formal proof of the famous Heine-Borel theorem. First up: every compact set is bounded.\n"
"\n"
"**The Strategy**: Remember that compactness means \"every open cover has a finite subcover.\" To show a set is bounded, we need to trap it inside some big ball. Here's the clever idea:\n"
"\n"
"1. **Create an infinite cover**: Cover the entire real line with balls `Ball(0, 1)`, `Ball(0, 2)`, `Ball(0, 3)`, etc. These definitely cover any set `S`.\n"
"\n"
"2. **Extract a finite subcover**: Since `S` is compact, only finitely many of these balls are needed to cover `S`.\n"
"\n"
"3. **Take the maximum**: The largest radius among these finitely many balls gives us our bound!\n"
"\n"
"**Why This Works**: If `S` can be covered by balls of radii `1, 3, 7, 12` (for example), then every point in `S` has absolute value less than `max(1, 3, 7, 12) = 12`.\n"
"\n"
"**Key Tool**: The `FinMax` lemma guarantees that any finite collection of real numbers has a maximum:\n"
"\n"
"`lemma FinMax (ι : Type) (V : Finset ι) (δs : ι → ℝ) :\n"
"    ∃ δ, ∀ i ∈ V, δs i ≤ δ`\n"
"\n"
"**Your Mission**: Formalize this intuitive argument. Use the balls `Ball(0, n+1)` for `n : ℕ`, apply compactness to get a finite subcover, then use `FinMax` to extract the bound!"
msgstr ""

#: Game.Levels.L12Levels.L01_MonotoneBdd
msgid "`(a : X → Y) {i j} (hij : i ≤ j) : a i ≤ a j`\n"
"\n"
"A sequence `a : X → Y` is said to be `Monotone` if `a n ≤ a m` whenever `n ≤ m`."
msgstr ""

#: Game.Levels.L6Levels.L05_AbsLt
msgid "# Level 6: AbsLe - Working with Absolute Values in Convergence\n"
"\n"
"Now that you've mastered the complete And/Or toolkit, it's time to apply these skills to a fundamental aspect of real analysis: working with absolute values in the context of sequence convergence. This level introduces you to one of the most useful tools for manipulating absolute value inequalities.\n"
"\n"
"You now have the full And/Or matrix \"Cheat Sheet\":\n"
"\n"
"|           | ∧        | ∨      |\n"
"|-----------|----------|--------|\n"
"| **Goal**  | `split_ands`    | `left`/`right`  |\n"
"| **Hypothesis** | `h.1`, `h.2` | `cases'` |\n"
"\n"
"Remember our definition of sequence convergence: `SeqLim a L` means that for any `ε > 0`, there exists an `N` such that for all `n ≥ N`, we have `|a n - L| < ε`. The absolute value here captures the idea that the sequence terms can approach the limit from either direction—they might be slightly above L or slightly below L, but either way, they're getting close.\n"
"\n"
"However, sometimes we need to extract more specific information from this absolute value condition. We might need to know that the sequence terms are not just close to L, but specifically that they're bounded below by `L - ε` or bounded above by `L + ε`. This is where the `abs_lt` theorem becomes invaluable.\n"
"\n"
"The key insight is that `|x| < y` is equivalent to saying both `-y < x` AND `x < y`. This gives us a way to \"unpack\" absolute value statements into more manageable pieces that we can work with using our And/Or toolkit.\n"
"\n"
"## New Tools You'll Need\n"
"\n"
"**`abs_lt`**: This theorem states that `|x| < y` if and only if `-y < x ∧ x < y`. This allows you to convert between absolute value inequalities and conjunction of regular inequalities, making them easier to work with in proofs."
msgstr ""

#: Game.Levels.L12Levels.L01_MonotoneBdd
msgid "If a sequence `a : ℕ → X` (where `X` could be `ℚ` or `ℝ`) is `Monotone` and grows along some subsequences by `ε`, then it eventually grows by `k * ε` for any `k`."
msgstr ""

#: Game.Levels.L18Pset.L09
msgid "# Level 9: `BddSeriesOdd`\n"
"\n"
"Prove `BddSeriesOdd`:"
msgstr ""

#: Game.Levels.L21Levels.L05
msgid "Sequential Criterion for Limits (Backward Direction)"
msgstr ""

#: Game.Levels.L6Levels.L04_Cases'
msgid "# Level 5: Cases' - Handling All Possibilities\n"
"\n"
"You've now mastered creating \"or\" statements with `left` and `right`, but what happens when you're given an \"or\" statement as a hypothesis and need to work with it? This is where the `cases'` tactic becomes essential—it's the perfect complement to the choice-making tactics you've already learned.\n"
"\n"
"When you have a hypothesis like `h : P ∨ Q`, you know that either `P` is true or `Q` is true, but you don't know which one. To proceed with your proof, you need to consider both possibilities systematically. The `cases'` tactic does exactly this: it splits your proof into two separate cases, one for each possibility.\n"
"\n"
"Think of this like a lawyer preparing for trial. If you know \"either the defendant was at home OR the defendant was at work\" during the time of the incident, you need to prepare your argument for both scenarios. You can't just pick one and hope for the best—you need a strategy that works regardless of which turns out to be true.\n"
"\n"
"In mathematical analysis, this pattern appears constantly. You might know that a sequence is either eventually positive or eventually negative, and need to prove something that holds in both cases. Or you might know that a function achieves its maximum either in the interior of an interval or at one of the endpoints.\n"
"\n"
"## New Tools You'll Need\n"
"\n"
"**`cases'`**: When you have a hypothesis `h : P ∨ Q`, you can say `cases' h with h1 h2`. This creates two separate goals:\n"
"- In the first goal, you get a new hypothesis `h1 : P`\n"
"- In the second goal, you get a new hypothesis `h2 : Q`\n"
"\n"
"You must solve both goals to complete your proof. This ensures you've covered all logical possibilities."
msgstr ""

#: Game.Levels.L19Levels.L02
msgid "A function `f` is called `Injective` if: for all `i, j`, `f i = f j → i = j`."
msgstr ""

#: Game.Levels.L7Pset.L7Pset1
msgid "# Problem 1\n"
"\n"
"Suppose that a sequence `a : ℕ → ℝ` converges to `L ≠ 0`. Show that eventually `|a n|` is at most\n"
"`2|L|`."
msgstr ""

#: Game.Levels.L1RealAnalysisStory.L02_rfl
msgid "Excellent! You've learned the `rfl` tactic.\n"
"\n"
"The key difference:\n"
"- Use `apply hypothesis_name` when you have a hypothesis that matches your goal\n"
"- Use `rfl` when you need to prove that something equals itself\n"
"\n"
"These are two of the most fundamental tactics in Lean. As we progress through real analysis, you'll see that many complex proofs ultimately come down to showing that two expressions are identical."
msgstr ""

#: Game.Levels.L6Levels.L06_Squeeze
msgid "# Level 7 Big Boss: Squeeze Theorem\n"
"\n"
"Welcome to another Big Boss level! You're about to prove one of the most elegant and powerful theorems in real analysis: the Squeeze Theorem (also known as the Sandwich Theorem or Pinching Theorem). This theorem beautifully captures the intuitive idea that if you trap a sequence between two other sequences that both converge to the same limit, then the trapped sequence must also converge to that limit.\n"
"\n"
"The Squeeze Theorem is a perfect showcase for how the logical tools you've been developing—working with conjunctions, absolute values, and inequalities—come together to prove deep mathematical results. You'll need to orchestrate all your skills: extracting information from convergence conditions, managing multiple epsilon-N arguments simultaneously, and combining inequalities with absolute value manipulations.\n"
"\n"
"**The Intuitive Picture:**\n"
"Imagine three runners on a track. Runner A and Runner C are both heading to the same finish line L, and Runner B is always between them. No matter how A and C weave back and forth, as long as they both end up at L and B stays between them, B must also end up at L. There's simply nowhere else for B to go!\n"
"\n"
"**The Mathematical Challenge:**\n"
"The formal proof requires careful epsilon management. Given any tolerance `ε`, you need to show that `b (n)` gets within `ε` of `L`. Since `a (n)` and `c (n)` both get within `ε` of `L`, and `b (n)` is squeezed between them, you can use the transitivity of inequalities to show that `b (n)` is also within `ε` of `L`."
msgstr ""

#: Game.Levels.L22PsetIntro
msgid "# Problem Set 22\n"
"\n"
"$\\# 1)$ Prove `IntegrableOn` for `f : x ↦ x^2`; that is, formally (in natural language) compute $\\int_a^b x^2 \\, dx$.\n"
"[Hint: The identity $\\sum_{i=0}^{n-1} (i+1)^2 = \\frac{(n)(n+1)(2n+1)}{6}$ may be useful. You're welcome\n"
"that we're using right Riemann sums!..]\n"
"\n"
"$\\# 2)$ Prove the Product Rule for derivatives: If `f` and `g` are differentiable at `c`, then so is `f * g`, and\n"
"`(f * g)'(c) = f'(c) * g(c) + f(c) * g'(c)`, formally (in natural language).\n"
"\n"
"$\\# 3)$ Prove the Reciprocal Rule for derivatives: If `f` is differentiable at `c` and `f(c) ≠ 0`, then\n"
"`fun x ↦ 1 / f x` is differentiable at `c`, with derivative `-f'(c) / (f(c))^2`, formally (in natural language).\n"
"\n"
"$\\# 4)$ Prove the Chain Rule for derivatives: If `f` is differentiable at `c` and `g` is differentiable at `f(c)`, then\n"
"`fun x ↦ g (f x)` is differentiable at `c`, with derivative `g'(f(c)) * f'(c)`, formally (in natural language).\n"
"\n"
"$\\# 5)$ Prove that integrals are linear (part I): If `f` and `g` are integrable on `[a, b]`, then so is `fun x ↦ f x + g x`, and\n"
"$\\int_a^b (f(x) + g(x)) \\, dx = \\int_a^b f(x) \\, dx + \\int_a^b g(x) \\, dx$.\n"
"\n"
"$\\# 6)$ Prove that integrals are linear (part II): If `f` is integrable on `[a, b]` and `k` is a constant, then so is `fun x ↦ k * f x`, and\n"
"$\\int_a^b k * f(x) \\, dx = k * \\int_a^b f(x) \\, dx$.\n"
"\n"
"$\\# 7)$ Prove that derivatives are linear (part I): If `f` and `g` are differentiable at `c`, then so is `fun x ↦ f x + g x`, with derivative\n"
"`f'(c) + g'(c)`.\n"
"\n"
"$\\# 8)$ Prove that derivatives are linear (part II): If `f` is differentiable at `c` and `k` is a constant, then so is `fun x ↦ k * f x`, with derivative `k * f'(c)`."
msgstr ""

#: Game.Levels.L16Levels.L01_check
msgid "`(a : ℕ → ℝ) : ℕ → ℝ := fun n ↦ ∑ k ∈ range n, a k`\n"
"\n"
"Given a sequence `a : ℕ → ℝ`, the `Series a` is the sequence of its partial sums."
msgstr ""

#: Game.Levels.L5Levels.L01_DoubleSeqConv
msgid "Also try unfolding the definition in `h`: `change ∀ ε₁ > 0, ∃ N₁ : ℕ, ∀ n ≥ N₁, |a n - L| < ε₁ at h`"
msgstr ""

#: Game.Levels.L11Lecture
msgid "Lecture 11: The Real Numbers I"
msgstr ""

#: Game.Levels.L22Levels.L02
msgid "#Redemption and the Power of Uniformity\n"
"\n"
"Magnificent! You've just completed one of the most important theorems in real analysis—the theorem that rescued Cauchy's intuition and clarified one of the fundamental relationships in mathematics.\n"
"\n"
"## What You Just Accomplished\n"
"\n"
"You proved that **uniform convergence preserves continuity**. This isn't just another theorem—it's the resolution to a mathematical crisis that puzzled the greatest minds of the 19th century. When Cauchy's \"proof\" that pointwise limits preserve continuity was shown to be false, mathematicians had to completely rethink what kinds of convergence were \"safe.\"\n"
"\n"
"Your proof shows that the answer is: **uniform convergence**.\n"
"\n"
"## The Beauty of the $\\varepsilon/3$ Method\n"
"\n"
"Look back at your proof. Notice how the $\\varepsilon/3$ trick created perfect harmony:\n"
"\n"
"```\n"
"|F(y) - F(x)| ≤ |F(y) - f_N(y)| + |f_N(y) - f_N(x)| + |f_N(x) - F(x)|\n"
"                     ↓                    ↓                    ↓\n"
"                  < ε/3              < ε/3                < ε/3\n"
"```\n"
"\n"
"The magic is that uniform convergence gave you control over the **first and third terms simultaneously**. This is precisely what pointwise convergence couldn't do—it could only promise that each term could be made small, but not necessarily at the same time with the same choice of $N$.\n"
"\n"
"## The Quantifier Order Victory\n"
"\n"
"Remember the crucial difference:\n"
"- **Pointwise**: $\\forall x, \\exists N_{x,\\varepsilon}, \\ldots$ (each point gets its own $N$)\n"
"- **Uniform**: $\\exists N_\\varepsilon, \\forall x, \\ldots$ (one $N$ works everywhere)\n"
"\n"
"Your proof exploited this difference beautifully. When you wrote:\n"
"```lean\n"
"choose N hN using hfF (ε / 3) (by bound)\n"
"```\n"
"\n"
"You were extracting a **single** $N$ that worked for **all points** simultaneously. This is the heart of why uniform convergence is so powerful.\n"
"\n"
"## Historical Vindication\n"
"\n"
"Cauchy's original intuition was that \"limits of continuous functions should be continuous.\" He was absolutely right—he just didn't know about uniform convergence yet! Your theorem shows that:\n"
"\n"
"1. Cauchy's intuition was mathematically sound\n"
"2. The problem was with pointwise convergence, not with the intuition\n"
"3. Uniform convergence is the \"correct\" notion of convergence for preserving nice properties\n"
"\n"
"## The Deeper Mathematical Lesson\n"
"\n"
"This theorem illustrates a profound principle: **the order of quantifiers matters tremendously**. Moving from $\\forall x, \\exists N$ to $\\exists N, \\forall x$ seems like a tiny change, but it's the difference between:\n"
"- A convergence that can destroy continuity (pointwise)\n"
"- A convergence that preserves continuity (uniform)\n"
"\n"
"This is why mathematicians are so careful about logic and quantifiers—small changes can have enormous consequences.\n"
"\n"
"## Technical Mastery\n"
"\n"
"In your Lean proof, you demonstrated sophisticated technique:\n"
"- **Strategic decomposition**: Using the triangle inequality to break a complex problem into manageable pieces\n"
"- **Resource management**: Carefully allocating your $\\varepsilon$ budget as $\\varepsilon/3 + \\varepsilon/3 + \\varepsilon/3$\n"
"- **Logical precision**: Extracting the right witnesses from existential statements in the right order\n"
"\n"
"The `choose` tactic and careful hypothesis management are becoming second nature to you!\n"
"\n"
"## Looking Forward: Integration and Beyond\n"
"\n"
"Your next challenge involves integration—and guess what? The distinction between pointwise and uniform convergence will be crucial there too. Many of the most important theorems in analysis (dominated convergence, monotone convergence, etc.) are essentially about finding the right conditions under which \"limit\" and \"integral\" can be swapped.\n"
"\n"
"## A Moment of Mathematical Pride\n"
"\n"
"You've just proven a theorem that eluded even Cauchy initially. The mathematical community spent decades clarifying exactly when limits preserve continuity, and you've now mastered this crucial insight.\n"
"\n"
"Every time you work with power series, Fourier series, or any other infinite sum of functions, you're implicitly using the principles you just proved.\n"
"\n"
"## The Ultimate Insight\n"
"\n"
"The real lesson of this level isn't just about uniform convergence—it's about the incredible precision required in mathematics. The difference between two types of convergence, distinguished only by the order of two quantifiers, is the difference between a theorem that's true and one that's false.\n"
"\n"
"This is why mathematics is both beautiful and challenging: every word, every symbol, every logical connection matters.\n"
"\n"
"## Final Thought\n"
"\n"
"Uniform convergence is more than just a technical condition—it's a way of saying \"all the convergence happens in harmony.\" When functions converge uniformly, they converge \"together,\" maintaining their nice properties. When they converge only pointwise, they can converge \"separately,\" potentially destroying structure.\n"
"\n"
"You've now learned to distinguish between these two fundamentally different types of convergence, and that makes you a much more sophisticated analyst.\n"
"\n"
"Ready for integration? Your mastery of uniform convergence will serve you well! 🌟"
msgstr ""

#: Game.Levels.L9Pset.L9Pset2
msgid "# Problem 2\n"
"\n"
"Prove that `N * (N + 1)` is always even."
msgstr ""

#: Game.Levels.L9Levels.L04_FiniteSums
msgid "# Level 1: Finite Sums\n"
"\n"
"Welcome to a new world of mathematics: **finite sums**! In this level, you'll prove that any individual term in a sum of absolute values is bounded by the total sum. This is a fundamental property that bridges discrete and continuous mathematics.\n"
"\n"
"## The Goal\n"
"\n"
"Prove that for any sequence `a : ℕ → ℝ` and natural number `N`, every term `|a n|` with `n < N` is at most the sum `∑ k ∈ range N, |a k|`.\n"
"\n"
"Intuitively: if you're adding up a bunch of nonnegative numbers, no single number can be bigger than the total!\n"
"\n"
"## Strategy: Induction from the Start!\n"
"\n"
"🎯 **Big Hint:** Even though the goal starts with `∀ n < N`, do **NOT** begin with `intro n hn`. Instead, run **induction on `N`** right from the beginning!\n"
"\n"
"This might feel counterintuitive, but trust the process. Induction gives you the perfect structure to peel off one term at a time using `sum_range_succ`.\n"
"\n"
"### Your Induction Strategy:\n"
"- **Base case (`N = 0`):** There are no natural numbers less than 0, so you'll get a `contradiction`\n"
"- **Inductive step (`N → N + 1`):** Use `sum_range_succ` to write the sum for `N + 1` as the sum for `N` plus the new term `|a N|`\n"
"  - Split into cases: Is `n < N` (use inductive hypothesis) or `n = N` (use nonnegativity)?\n"
"\n"
"## New Tools You'll Need\n"
"\n"
"### Summation Notation\n"
"`∑ k ∈ range N` means sum as `k` goes from `0` to `N - 1` (which has `N` terms total!)\n"
"\n"
"### `sum_range_succ`\n"
"Peels off the last term: `∑ k ∈ range (N + 1), f k = (∑ k ∈ range N, f k) + f N`\n"
"\n"
"### `sum_nonneg`\n"
"If each term is nonnegative, so is the sum. Usage: `apply sum_nonneg`, then prove `∀ k ∈ range N, 0 ≤ f k`\n"
"\n"
"### `contradiction`\n"
"If your hypotheses are contradictory (like `n : ℕ` with `n < 0`), this tactic closes the goal immediately.\n"
"\n"
"### `by_cases`\n"
"Split into cases based on a decidable proposition. Usage: `by_cases h : n < N` creates two goals:\n"
"- One where `h : n < N` holds\n"
"- One where `h : ¬(n < N)` holds\n"
"\n"
"Good luck! Remember: **induction first, then introduce `n`!**"
msgstr ""

#: Game.Levels.L8Pset.L8Pset1
#: Game.Levels.L8Pset.L8Pset2
#: Game.Levels.L8Pset.L8Pset3
#: Game.Levels.L8Pset.L8Pset4
#: Game.Levels.L9Pset.L9Pset1
#: Game.Levels.L9Pset.L9Pset2
#: Game.Levels.L9Pset.L9Pset3
#: Game.Levels.L12Pset.L12Pset1
#: Game.Levels.L12Pset.L12Pset2
#: Game.Levels.L13Pset.L13Pset1
#: Game.Levels.L16Pset.L16Pset1
#: Game.Levels.L16Pset.L16Pset2
#: Game.Levels.L16Pset.L16Pset3
#: Game.Levels.L17Pset.L05
#: Game.Levels.L17Pset.L05'
#: Game.Levels.L17Pset.L06
#: Game.Levels.L18Pset.L01
#: Game.Levels.L18Pset.L02
#: Game.Levels.L18Pset.L03
#: Game.Levels.L18Pset.L04
#: Game.Levels.L18Pset.L05
#: Game.Levels.L18Pset.L06
#: Game.Levels.L18Pset.L07
#: Game.Levels.L18Pset.L08
#: Game.Levels.L18Pset.L09
#: Game.Levels.L18Pset.L10
#: Game.Levels.L20Pset.L01
#: Game.Levels.L20Pset.L02
#: Game.Levels.L20Pset.L03
#: Game.Levels.L20Pset.L04
#: Game.Levels.L22Pset.L02
#: Game.Levels.L22Pset.L03
#: Game.Levels.L22Pset.L04
#: Game.Levels.L24Pset.L01
#: Game.Levels.L24Pset.L02
msgid ""
msgstr ""

#: Game.Levels.L24Pset.L02
msgid "Open Balls are Open"
msgstr ""

#: Game.Levels.L18Pset.L06
msgid "# Level 6: `MonotoneSeriesEven`\n"
"\n"
"Prove `MonotoneSeriesEven`:"
msgstr ""

#: Game.Levels.L3Levels.L01_ArchProp
msgid "This is a good time to record the fact that `1 / ε ≤ ⌈1 / ε⌉₊`.\n"
"You can do that with: `have fact : 1 / ε ≤ ⌈1 / ε⌉₊ := by bound`. The `bound` tactic can solve inequalities like this."
msgstr ""

#: Game.Levels.L25Levels.L02
msgid "The Intermediate Value Theorem (IVT) states that if a function is continuous on a closed interval `[a, b]` and takes values `f(a) < 0` and `0 < f(b)`, then there exists `c ∈ (a, b)` so that `f(c)=0`."
msgstr ""

#: Game.Levels.L17Levels.L01
msgid "# Level 1: Leibniz Series — Partial Sums\n"
"\n"
"Welcome to Lecture 17! We now turn to evaluating explicit series, starting with a beautiful classical example.\n"
"\n"
"Consider the series:\n"
"`∑ k, 1 / ((k + 1) * (k + 2)) = 1/2 + 1/6 + 1/12 + 1/20 + 1/30 + ...`\n"
"\n"
"This series was studied by Gottfried Wilhelm Leibniz in the 17th century. Our goal is to find an *explicit formula* for its partial sums.\n"
"\n"
"## The Strategy: Telescoping\n"
"\n"
"The key insight is **partial fractions**. Each term can be rewritten as:\n"
"`1 / ((k + 1) * (k + 2)) = 1/(k + 1) - 1/(k + 2)`\n"
"\n"
"When we sum these, most terms cancel! This is called a **telescoping sum**:\n"
"```\n"
"  (1/1 - 1/2) + (1/2 - 1/3) + (1/3 - 1/4) + (1/4 - 1/5) + ...\n"
"= 1/1 - 1/2 + 1/2 - 1/3 + 1/3 - 1/4 + 1/4 - 1/5 + ...\n"
"= 1 - 1/(n+1)\n"
"```\n"
"\n"
"## Your Challenge\n"
"\n"
"Prove that for the sequence `a` defined by `a n = 1 / ((n + 1) * (n + 2))`, we have:\n"
"\n"
"`∑ k ∈ range n, a k = 1 - 1 / (n + 1)`\n"
"\n"
"**Hint:** Use induction on `n`. The base case is straightforward. For the inductive step, use `sum_range_succ` to split off the last term, apply the inductive hypothesis, and then do some algebra with `field_simp` and `ring_nf`."
msgstr ""

#: Game.Levels.L3Levels.L01_ArchProp
msgid "You might think that the `bound` tactic\n"
"would also be able to solve `1 / ε < ↑(⌈1 / ε⌉₊ + 1)`, but No!\n"
"That's because the addition `⌈1 / ε⌉₊ + 1` happens as **natural numbers**, and only then is the result cast to the reals; so the\n"
"`fact` that was just proved is not useful to `bound`. Instead try: `push_cast` to get the casting to push down as far as possible.\n"
"The Goal will change to `1 / ε < ↑⌈1 / ε⌉₊ + 1`, where now the\n"
"ceiling is cast to the reals, and then the real number `1` is added."
msgstr ""

#: Game.Levels.L6Levels.L05_AbsLt
msgid "This says that `|x| < y` if and only if `-y < x ∧ x < y`."
msgstr ""

#: Game.Levels.L10Levels.L06_Prod
msgid "# Level 1: Big Boss - Product of Sequences\n"
"\n"
"This is the capstone of the Algebraic Limit Theorem! We've already proven that limits behave well under addition, scalar multiplication, and inversion. Now we tackle multiplication of sequences.\n"
"\n"
"**The Challenge:** If `a n → L` and `b n → M`, prove that `a n * b n → L * M`.\n"
"\n"
"**The Key Insight:** We need to write the error `a n * b n - L * M` in a way that separates the contributions from each sequence. The trick is to add and subtract `b n * L`:\n"
"\n"
"```\n"
"a n * b n - L * M = (a n - L) * b n + L * (b n - M)\n"
"```\n"
"\n"
"**Why does this work?** Think about rectangles! The product `a n * b n` is the area of a rectangle with dimensions `a n` by `b n`, while `L * M` is the limiting rectangle. The difference decomposes into two strips:\n"
"- `(a n - L) * b n`: a thin vertical strip (small width, bounded height)\n"
"- `L * (b n - M)`: a thin horizontal strip (bounded width, small height)\n"
"\n"
"The corner piece `(a n - L) * (b n - M)` gets absorbed into the first term—it's doubly small so it doesn't hurt us!\n"
"\n"
"**The Strategy:**\n"
"1. Use `Bdd_of_ConvNonzero` to get a bound `K` on the sequence `b`\n"
"2. Make `|a n - L| < ε/(2*K)` to control the first term\n"
"3. Make `|b n - M| < ε/(2*|L|)` to control the second term\n"
"4. Combine using the triangle inequality\n"
"\n"
"\n"
"Good luck!"
msgstr ""

#: Game.Levels.L19Levels.L01
msgid "# Congratulations!\n"
"\n"
"You've just proven the **Strong Cauchy Property** for absolutely convergent series—a crucial stepping stone toward the Rearrangement Theorem!\n"
"\n"
"## What We've Accomplished\n"
"\n"
"This theorem shows that absolute convergence gives us tremendous flexibility in how we sum the terms. Not only do consecutive intervals have small sum (the usual Cauchy property), but *any* finite collection of sufficiently large-index terms has arbitrarily small sum.\n"
"\n"
"This is much more flexible than the standard Cauchy criterion, which only considers intervals `[n, m)`. Here, we could pick scattered indices like `{100, 137, 1000000, 10^10}` and still guarantee the sum is small, as long as all indices exceed our threshold `N`.\n"
"\n"
"## The Key Technique\n"
"\n"
"The proof uses a clever bounding argument:\n"
"1. Every finite set has a maximum element, so we can find an interval containing it\n"
"2. The finite set is a subset of this interval\n"
"3. Since all terms are nonnegative (we're working with absolute values), monotonicity gives us the bound we need\n"
"\n"
"## Why This Matters for Rearrangements\n"
"\n"
"When we rearrange a series, terms appear in a completely different order. At some point in the rearranged series, we'll have covered all the early terms, but there will be scattered later terms we haven't seen yet.\n"
"\n"
"The strong Cauchy property tells us that these scattered \"missing\" terms contribute negligibly to the sum, because they all have large indices. This is the key to showing that rearrangements don't change the sum!\n"
"\n"
"## Looking Ahead\n"
"\n"
"In the next level, we'll formalize what a rearrangement is and prove that rearrangements eventually \"catch up\" with the original ordering. Combined with this strong Cauchy property, we'll have all the tools needed to prove the magnificent Rearrangement Theorem."
msgstr ""

#: Game.Levels.L24Levels.L01
msgid "A compact set is bounded."
msgstr ""

#: Game.Levels.L22Pset.L02
msgid "# Level 2: Continuity Exercise\n"
"\n"
"Prove that `x ↦ x ^ 3` is continuous."
msgstr ""

#: Game.Levels.L17Lecture
msgid "# Lecture 17: Series II"
msgstr ""

#: Game.Levels.L20Levels.L01
msgid "`∀ ε > 0, ∃ δ > 0, ∀ x ≠ c, |x - c| < δ → |f x - L| < ε`\n"
"\n"
"  A function `f` has limit `L` at `x = c`."
msgstr ""

#: Game.Levels.L1RealAnalysisStory.L09_big_boss
msgid "# 🎉 VICTORY! 🎉\n"
"\n"
"You've defeated the Big Boss and mastered all the fundamental tactics of mathematical reasoning!\n"
"\n"
"**Let's see what you just accomplished:**\n"
"\n"
"1. **`choose a ha using h_existential`** - Extracted the witness `a` and fact that `f (a) = 3` from the hypothesis\n"
"2. **`use a`** - Chose `a` as your witness for the existence statement in the goal\n"
"3. **`intro y hy`** - Handled the universal quantifier \"for all y > 0\" in the goal\n"
"4. **`specialize h_universal y hy`** - Applied the universal property to your specific value in the hypothesis\n"
"5. **`rewrite [h_universal]`** - Used the specialized fact to rewrite the goal\n"
"6. **`rewrite [ha]`** - Used the original fact that `f (a) = 3` to also rewrite the goal\n"
"7. **`ring_nf`** - Verified finally that `(f y + 9) ^ 2 = (f y + 3 ^ 2) ^ 2`\n"
"\n"
"You've just completed a genuinely sophisticated mathematical argument! This kind of multi-step reasoning, combining existence statements, universal properties, and algebraic manipulation, is exactly what you'll encounter throughout real analysis.\n"
"\n"
"**You are now ready to begin your journey to rigorous calculus!**\n"
"\n"
"Welcome to the Introduction to Formal Real Analysis. 🎓\n"
"\n"
"**Epilogue**\n"
"\n"
"Before we continue with more Real Analysis and more Lean, let’s pause to note a few interesting things about working formally.\n"
"Using a theorem prover interactively is (I hope) tremendously fun and (I hope) leads to rapid gains, immediate feedback, and clarity of thought.\n"
"\n"
"Imagine trying to learn chess by just reading through algebraic notation - 1.e4 e5 2.Nf3 Nf6 3.Bb5 a6 - sure, all the information is technically there, but isn't it so much easier to learn by actually looking at a chess board and seeing how the position changes after each move? In mathematics, it would be extraordinarily tedious to manually write on the blackboard the entire goal state after every move, keeping track of all the hypotheses and their relationships by hand. A theorem prover does this bookkeeping for you automatically, letting you focus on the mathematical content rather than the clerical work.\n"
"\n"
"But! This is, as we've already noted, a double-edged sword. We still want to train our brains to \"see\" a mental model of the goal state evolving - good chess players can visualize many moves ahead precisely because they've learned to maintain multiple mental game boards simultaneously. But until you develop that skill, and even after you have it, there's immense value in being able to instantly generate the current \"game board\" of your proof state. The immediate feedback helps you understand the consequences of each logical move, building the very intuition that will eventually let you work more independently. It's the difference between learning to navigate by always checking your GPS versus eventually developing an internal sense of direction - both have their place, and the former helps develop the latter."
msgstr ""

#: Game.Levels.L20Levels.L03
msgid "Sum of Continuous Functions"
msgstr ""

#: Game.Levels.L4Lecture
msgid "Lecture 4: Even more fun with Sequences"
msgstr ""

#: Game.Levels.L23Levels.L01
msgid "Riemann Sum Refinement"
msgstr ""

#: Game.Levels.L13Levels.L03_MonotoneSubseq
msgid "`(a : ℕ → X) (n : ℕ) := ∀ m > n, a m ≤ a n`\n"
"\n"
"For a sequence `a : ℕ → X` (where `X` is `ℚ` or `ℝ`) and `n : ℕ`, we say that `IsAPeak a n` if: `∀ m > n, a m ≤ a n`."
msgstr ""

#: Game.Levels.L17Levels.L03
msgid "# Level 3: Series Order Theorem\n"
"\n"
"One of the most fundamental properties of series is that they **respect inequalities**: if one sequence is term-by-term less than or equal to another, then their partial sums satisfy the same relationship.\n"
"\n"
"## The Theorem\n"
"\n"
"**Series Order Theorem:** If `a n ≤ b n` for all `n`, then:\n"
"`Series a n ≤ Series b n` for all `n`\n"
"\n"
"In other words:\n"
"`∑ k ∈ range n, a k ≤ ∑ k ∈ range n, b k`\n"
"\n"
"## Why This Matters\n"
"\n"
"This seemingly simple result is the foundation for **comparison tests** in series theory. If we know that:\n"
"- `0 ≤ a n ≤ b n` for all `n`, and\n"
"- `∑ b n` converges to some value `M`\n"
"\n"
"Then we can conclude that `∑ a n` also converges, and moreover `∑ a n ≤ M`.\n"
"\n"
"We'll use this exact strategy in the next level to prove the Basel series converges!\n"
"\n"
"## The Proof Strategy\n"
"\n"
"This is a straightforward **induction** argument:\n"
"- **Base case (n=0):** Both sums are empty, so `0 ≤ 0` ✓\n"
"- **Inductive step:** If $\\sum_{k<n} a_k \\le \\sum_{k<n} b_k$ and `a n ≤ b n`, then adding `a n` to the left and `b n` to the right preserves the inequality.\n"
"\n"
"## Your Task\n"
"\n"
"Prove `SeriesOrderThm`: given `a n ≤ b n` for all `n`, show that `Series a n ≤ Series b n` for all `n`.\n"
"\n"
"**Hints:**\n"
"- Use induction with `induction' n with n hn`\n"
"- The base case can be handled with `bound`\n"
"- For the inductive step, use `sum_range_succ` to split off the last term\n"
"- Then combine the inductive hypothesis with `hab n` using `linarith`\n"
"\n"
"This is a clean, elegant proof—enjoy the simplicity!"
msgstr ""

#: Game.Levels.L6Levels.L00_SumOfSeqs
msgid "# Level 1 **Big Boss**: Adding Convergent Sequences\n"
"\n"
"Now that we've had some experience with the definition of convergence, let's tackle this world's Big Boss. One of the most fundamental ideas in analysis is that 'nice operations preserve convergence.' If two sequences each converge, then their sum also converges, and converges to the sum of their limits.\n"
"\n"
"This might seem obvious at first -- after all, if $a(n)$ is getting close to $L$ and $b(n)$ is getting close to $M$, shouldn't $a(n) + b(n)$ get close to $L + M$? While the intuition is correct, making this rigorous requires some clever maneuvering with our epsilon-N definition.\n"
"\n"
"**Big Boss**\n"
"Here's the key insight: if an engineer demands that our combined output be within $\\varepsilon$ of the target $L + M$, we can't just demand that each factory independently meet the full tolerance $\\varepsilon$. Instead, we need to be clever about how we allocate our 'tolerance budget.'\n"
"\n"
"Think of it this way: if the first factory can guarantee its output is within $\\varepsilon/2$ of $L$, and the second factory can guarantee its output is within $\\varepsilon/2$ of $M$, then by the triangle inequality, their sum will be within $\\varepsilon$ of $L + M$. This is the heart of the proof!\n"
"\n"
"## The Mathematical Setup\n"
"\n"
"Suppose we have:\n"
"- A sequence $a : \\mathbb{N} \\to \\mathbb{R}$ that converges to $L$\n"
"- A sequence $b : \\mathbb{N} \\to \\mathbb{R}$ that converges to $M$\n"
"- A sequence $c : \\mathbb{N} \\to \\mathbb{R}$ with the property that $c(n) = a(n) + b(n)$ for all $n$\n"
"\n"
"We want to prove that $c$ converges to $L + M$.\n"
"\n"
"\n"
"## Your Strategic Approach\n"
"\n"
"- Start by unfolding the definitions of `SeqLim` in the Goal and hypotheses. I recommend you give your dummy variables different names, so as not to get confused later.\n"
"- Given any `ε > 0`, use the convergence of `a` to get an `Na` that works for `ε / 2`.\n"
"- Similarly, use the convergence of `b` to get an `Nb` that works for `ε / 2`\n"
"- You might think that it would be a good idea at this point to `use max Na Nb`, that is, take the larger of the two for `N`. But we don't care how big `N` is! Can you\n"
"think of another way to achieve the same objective? (Hint:\n"
" I haven't told you how to use the `max` function, but I bet you can come up with another function for which you already have everything you need at your disposal...)\n"
"- Use the triangle inequality to combine the two half-tolerances\n"
"\n"
"This proof embodies a fundamental principle in analysis: when dealing with sums, we often need to 'divide and conquer' by splitting our error tolerance between the components."
msgstr ""

#: Game.Levels.L7Levels.L02_SeqOfAbs
msgid "# Level 3: Continuity of Absolute Value—Sequences of Absolute Values\n"
"\n"
"The absolute value function behaves extremely well with respect to limits—if a sequence\n"
"converges, then the sequence of absolute values converges to the absolute value of the\n"
"limit. This is a manifestation of the **continuity** of the absolute value function.\n"
"\n"
"\n"
"## What We're Proving\n"
"\n"
"**Theorem:** If `a : ℕ → ℝ` converges to `L`, and `b : ℕ → ℝ` is defined by\n"
"`b n = |a n|` for all `n`, then `b` converges to `|L|`.\n"
"\n"
"In other words: taking absolute values preserves convergence.\n"
"\n"
"## New Tool: `abs_Lipschitz`\n"
"\n"
"A function `f : ℝ → ℝ` is called \"Lipschitz\"  (with constant `K`) if we have `|f(x) - f(y)| ≤ K · |x - y|` for all `x` and `y`. This means the function can't change too rapidly—the output values can't get farther apart than `K` times the input distance.  The theorem `abs_Lipschitz`  states that for any real numbers `x` and `y`:\n"
"$$||x| - |y|| \\leq |x - y|$$\n"
"that is, the absolute value function is Lipschitz with constant `K = 1`. This means taking absolute values is non-expansive: it never increases distances between points, and often decreases them.\n"
"\n"
"(This is also sometimes called the **reverse triangle inequality for absolute values**.)\n"
"\n"
"The proof of this fact will be reserved for the Exercises.\n"
"\n"
"## The Strategy\n"
"\n"
"This proof is remarkably clean compared to our previous results:\n"
"\n"
"1. Given `ε > 0`, use convergence of `a` to get `N` such that `|a n - L| < ε` for `n ≥ N`\n"
"2. For `n ≥ N`, observe that `b n = |a n|`\n"
"3. Apply `abs_Lipschitz`: `||a n| - |L|| ≤ |a n - L| < ε`\n"
"4. Therefore `|b n - |L|| < ε`, proving `b n → |L|`\n"
"\n"
"The Lipschitz property does all the heavy lifting for us!\n"
"\n"
"## Why This Matters\n"
"\n"
"This theorem is a special case of a much more general principle: **continuous functions\n"
"preserve limits**. The absolute value function is continuous everywhere, so it maps\n"
"convergent sequences to convergent sequences. This principle extends to all continuous\n"
"functions and is fundamental to mathematical analysis."
msgstr ""

#: Game.Levels.L21Levels.L08
msgid "Continuity Everywhere"
msgstr ""

#: Game.Levels.L2PsetIntro
msgid "# Problem Set 2\n"
"\n"
"This is problem set 2."
msgstr ""

#: Game.Levels.L11Levels.L01_IsCauchyOfLim
msgid "# Level 1: Big Boss - Limits are Cauchy\n"
"\n"
"Now that we understand what a Cauchy sequence is, let's prove our first major theorem: **every convergent sequence is Cauchy**.\n"
"\n"
"This might seem obvious at first—if a sequence converges to some limit `L`, then the terms should eventually be close to each other. But making this intuition rigorous requires careful epsilon management!\n"
"\n"
"## The Key Insight\n"
"\n"
"If `aₙ → L`, then for large `n` and `m`, both `aₙ` and `aₘ` are close to `L`. By the triangle inequality, this means they must be close to *each other*:\n"
"\n"
"`|aₙ - aₘ| = |(aₙ - L) + (L - aₘ)| ≤ |aₙ - L| + |L - aₘ|`\n"
"\n"
"## Strategy\n"
"\n"
"1. **Extract the limit**: Since the sequence converges, use `choose` to get the limit `L`\n"
"2. **Clever epsilon choice**: Apply the definition of `aₙ → L` with `ε/2` (not `ε`!)\n"
"3. **Rewrite the goal**: Express `|aₙ - aₘ|` in terms of differences from `L`\n"
"4. **Apply triangle inequality**: Split the absolute value of a sum\n"
"5. **Use symmetry**: Apply `abs_sub_comm` to get `|L - aₘ| = |aₘ - L|`\n"
"6. **Finish with arithmetic**: Both pieces are less than `ε/2`, so the sum is less than `ε`\n"
"\n"
"## New Definition\n"
"\n"
"**`IsCauchy a`**: A sequence `a : ℕ → ℝ` is Cauchy if\n"
"`∀ ε > 0, ∃ N, ∀ n ≥ N, ∀ m ≥ n, |a m - a n| < ε`\n"
"\n"
"## New Theorem\n"
"\n"
"**`abs_sub_comm`**: `|x - y| = |y - x|`\n"
"(Subtraction is commutative inside absolute values)\n"
"\n"
"This is your first Big Boss level working with the Cauchy definition. Take your time, and remember: when in doubt, divide epsilon by 2!"
msgstr ""

#: Game.Levels.L18Pset.L07
msgid "AntitoneSeriesOdd"
msgstr ""

#: Game.Levels.L22Levels.L03
msgid "The sum `∑ i ∈ range n, ((i : ℝ) + 1) = (n * (n + 1)) / 2`."
msgstr ""

#: Game.Levels.L1RealAnalysisStory.L06_intro
msgid "The intro tactic"
msgstr ""

#: Game.Levels.L24Levels.L05
msgid "# 🎉 HEINE-BOREL THEOREM: COMPLETE! 🎉\n"
"\n"
"You did it! You've just completed the proof of one of the most important theorems in all of mathematics:\n"
"\n"
"**HEINE-BOREL THEOREM**: `S ⊆ ℝ is compact ⟺ S is closed and bounded`\n"
"\n"
"**What You've Accomplished**:\n"
"- ✅ **Level 1**: Compact ⟹ Bounded\n"
"- ✅ **Level 2**: Compact ⟹ Closed\n"
"- ✅ **Level 3**: Least Upper Bound Property of ℝ\n"
"- ✅ **Level 4**: Closed Interval [a,b] is Compact\n"
"- ✅ **Level 5**: Closed Subset of Compact is Compact\n"
"\n"
"**The Sum Type Mastery**: Your final proof showcased advanced Lean programming with sum types. You learned to:\n"
"- **Construct** disjoint unions `α ⊕ β`\n"
"- **Pattern match** with `match` and `cases`\n"
"- **Extract components** with `Finset.lefts`\n"
"- **Combine different index types** into unified covering systems\n"
"\n"
"This isn't just theorem proving - it's sophisticated type-level programming!\n"
"\n"
"**The Mathematical Journey**: You've traveled from elementary compactness through:\n"
"- **Topology** (open/closed sets, covers)\n"
"- **Real Analysis** (supremums, completeness of ℝ)\n"
"- **Logic** (proof by contradiction, case analysis)\n"
"- **Type Theory** (dependent types, sum types)\n"
"\n"
"**Why This Theorem Changes Everything**:\n"
"\n"
"🧮 **For Calculus**: Every continuous function on [a,b] is now guaranteed to be:\n"
"   - Uniformly continuous (by Level 23)\n"
"   - Integrable (Riemann sums converge)\n"
"   - Bounded and achieving max/min\n"
"\n"
"📊 **For Analysis**: You can now easily check compactness just by verifying \"closed and bounded\" - no more wrestling with covers and subcovers!\n"
"\n"
"🔬 **For Topology**: You've connected the abstract (compactness) with the concrete (closed + bounded), making topology applicable to real analysis.\n"
"\n"
"**Historical Impact**: Your theorem unified 19th-century analysis. Before Heine (1872) and Borel (1895), mathematicians had intuitions about why [a,b] was special but couldn't prove it rigorously.\n"
"\n"
"**The Complete Chain**: You can now trace the full logical chain:\n"
"\n"
"`f continuous on [a,b] → [a,b] compact (Heine-Borel)\n"
"                     → f uniformly continuous (Level 23)\n"
"                     → f integrable (Level 23)`\n"
"\n"
"**Looking Forward**: You've built the foundation for advanced analysis - measure theory, functional analysis, and differential geometry all build on compactness.\n"
"\n"
"You've just proved one of the crown jewels of mathematics! Take a moment to appreciate the elegant interplay of topology, analysis, and logic you've mastered. 🏆\n"
"\n"
"Welcome to the ranks of real analysts!"
msgstr ""

#: Game.Levels.L10Levels.L08_Mono
msgid "`(σ : ℕ → ℕ) := ∀ i j, i < j → σ i < σ j`\n"
"\n"
"A sequence `σ : ℕ → ℕ` is a *subsequence* if `∀ i j, i < j → σ (i) < σ (j)`."
msgstr ""

#: Game.Levels.L3Pset.L3Pset2
msgid "# Problem 2\n"
"\n"
"Prove that the sequence `(n + 1) / n` has a limit, say, `L`, and determine what it is.\n"
"\n"
"We haven't yet learned a good way to use the theorem `OneOverNLimZero`\n"
"that we already proved, so just adapt the proof of that, rather than trying to quote it. (It's good practice!)"
msgstr ""

#: Game.Levels.L1RealAnalysisStory.L07_specialize
msgid "Great! You've learned the `specialize` tactic.\n"
"\n"
"Notice what happened:\n"
"1. Initially, `hf : ∀ x > 0, f (x) = x^2` was a universal statement\n"
"2. `specialize hf t` transformed it into `hf : t > 0 → f (t) = t ^ 2`\n"
"3. Another `specialize` command, namely `specialize hf t_pos` turned the\n"
"hypothesis `hf` into `hf : f (t) = t ^ 2`\n"
"4. And finally, `apply hf` worked because the hypothesis matched the goal.\n"
"\n"
"The pattern is:\n"
"- `intro` when you have `∀` in the goal (\"introduce an arbitrary term...\")\n"
"- `specialize` when you have `∀` in a hypothesis (\"apply the hypothesis to specific value...\")\n"
"\n"
"This is fundamental in real analysis when working with:\n"
"- Function properties that hold \"for all x\"\n"
"- Limit definitions involving \"for all ε > 0\"\n"
"- Continuity statements\n"
"\n"
"Last lesson in Lecture 1 coming up."
msgstr ""

#: Game.Levels.L17PsetIntro
msgid "# Problem Set 17: Solve these problems in Natural Language:\n"
"\n"
"$\\# 1)$ True or false: If a sequence `a : ℕ → ℝ` is bounded, then the\n"
"Cesaro-average sequence (see Problem Set 15, Problem 3) converges. Give a proof or a counterexample.\n"
"\n"
"$\\# 2)$\n"
"Following Euler, work out the Taylor series for `sin(x)/x`, and show that it equals `1 - x²/3! + x⁴/5! - ...`.\n"
"\n"
"\n"
"$\\# 3)$\n"
"The next thing Euler did was totally crazy: he treated the sine function's infinite series like a polynomial, and factored it!\n"
"He claimed that\n"
"\n"
"`sin(x)/x = (1 - x²/π²)(1 - x²/(4π²))(1 - x²/(9π²))...`\n"
"\n"
"holds (it would take a long while to make this rigorous, but it *can* be done). Assume that this identity holds.\n"
"Compare the coefficient of `x²` in Problem 2 to the coefficient that comes from multiplying out this formula.\n"
"You should be able to deduce that\n"
"\n"
"`1 + 1/4 + 1/9 + ... = π²/6`.\n"
"\n"
"[Euler's claim was considered scandalous at the time—treating infinite series like polynomials! But Euler's intuition was correct, and later mathematicians -- most notably Weierstrass -- made it rigorous and general.]"
msgstr ""

#: Game.Levels.L1RealAnalysisStory.L06_intro
msgid "Excellent! You've learned the `intro` tactic for universal statements.\n"
"\n"
"Notice what happened:\n"
"1. `intro ε` introduced the arbitrary real number ε\n"
"2. `intro hε` introduced the hypothesis `hε : ε > 0`\n"
"3. The goal became `(ε + 1)^2 = (ε + 1)^2`\n"
"4. `rfl` solved the goal, by the reflexive property of the equals sign.\n"
"\n"
"You might have noticed something interesting: we used `intro` in two seemingly different ways -- first to introduce an \"Object\" (the real number `ε`), and second to introduce an \"Assumption\" or hypothesis (that `ε > 0`). In Lean's underlying logic (\"dependent type theory\"), there's actually a deep unity here that mathematicians call the *Curry-Howard correspondence*: propositions are \"Types\", and proofs are \"Terms\" of those Types. This means that introducing a hypothesis is really just introducing a term of a certain type, just like introducing a variable.\n"
"\n"
"But here's an even more mind-bending perspective: our entire Statement is really a *function*! Its inputs are first an `ε : ℝ`, then a proof that `ε > 0`, and its output is a proof that `(ε + 1)^2 = (ε + 1)^2`. When we write `intro ε` and `intro h`, we're literally defining this function by saying \"given these inputs, here's how to compute the output.\" In this view, all of mathematics -- from the simplest definitions to proofs of the deepest theorems -- is secretly just **functions** transforming inputs into outputs!\n"
"\n"
"This beautiful connection between logic and computation underlies much of modern proof assistants, though we won't dive into the details in this course -- it's perfectly fine if you didn't follow the last two paragraphs! For now, just appreciate that `intro` works uniformly whether you're introducing mathematical objects or logical assumptions, and that every proof you write is secretly a program!\n"
"\n"
"The `intro` tactic is absolutely crucial in real analysis. You'll use it constantly to:\n"
"- Handle \"for all ε > 0\" statements in limit definitions\n"
"- Introduce arbitrary points in domain/range proofs\n"
"- Work with function definitions\n"
"\n"
"This pattern of `intro` followed by algebraic manipulation is everywhere in analysis!"
msgstr ""

#: Game.Levels.L5Levels.L01_DoubleSeqConv
msgid "Start by unfolding the definition: `change ∀ ε > 0, ∃ N : ℕ, ∀ n ≥ N, |b n - 2 * L| < ε`"
msgstr ""

#: Game.Levels.L19Levels.L02
msgid "# Level 2: Rearrangements\n"
"\n"
"In this level, we introduce the formal concept of a rearrangement and prove a crucial technical lemma about how rearrangements behave.\n"
"\n"
"## New Definitions\n"
"\n"
"**Definition** (`Injective`): A function `f : X → Y` is *injective* (one-to-one) if whenever `f i = f j`, we have `i = j`. In other words, different inputs give different outputs.\n"
"\n"
"**Definition** (`Surjective`): A function `f : X → Y` is *surjective* (onto) if for every `y : Y`, there exists some `x : X` with `f x = y`. In other words, every output is achieved by some input.\n"
"\n"
"**Definition** (`Rearrangement`): A function `σ : ℕ → ℕ` is a *rearrangement* if it is both injective and surjective—that is, a bijection of the natural numbers.\n"
"\n"
"A rearrangement `σ` gives us a new ordering of ℕ. For a sequence `a`, the rearranged sequence `a ∘ σ` is defined by `(a ∘ σ) n = a (σ n)`.\n"
"\n"
"## The Main Result\n"
"\n"
"**Theorem** (`EventuallyCovers_of_Rearrangement`): If `σ` is a rearrangement, then for any `M : ℕ`, there exists `N` such that for all `n ≥ N`, we have:\n"
"\n"
"`range M ⊆ image σ (range n)`\n"
"\n"
"In other words: the image of `σ` on `{0, 1, ..., n-1}` contains `{0, 1, ..., M-1}`.\n"
"\n"
"## What This Means\n"
"\n"
"Even though a rearrangement `σ` might scramble the order of natural numbers dramatically, it must \"eventually catch up\" with the original ordering. By the time we reach index `N`, we're guaranteed to have seen all of the first `M` elements as outputs of `σ`.\n"
"\n"
"For example, if `σ` sends `0 → 1000000`, we might have to wait a while, but eventually (before reaching some `N`), all of `{0, 1, ..., M}` will have appeared as values `σ(k)` for `k < N`.\n"
"\n"
"## Why This Matters\n"
"\n"
"This theorem is essential for proving that rearranged series converge to the same limit. We'll need to know that when we've computed enough terms of the rearranged series, we've included all the important early terms from the original series.\n"
"\n"
"Your task: Prove that every rearrangement eventually covers any initial segment!"
msgstr ""

#: Game.Levels.L24Levels.L03
msgid "`(S : Set ℝ) (M : ℝ) : Prop := ∀ s ∈ S, s ≤ M`\n"
"\n"
"The point `M` is an upper bound of the set `S` if every element `s` in `S` satisfies `s ≤ M`."
msgstr ""

#: Game.Levels.L11Pset.L11Pset1
msgid "# Problem 1:\n"
"\n"
"Prove that the sequence `a n = n` has no convergent subsequence."
msgstr ""

#: Game.Levels.L10PsetIntro
msgid "# Problem Set 10\n"
"\n"
"Good luck!"
msgstr ""

#: Game.Levels.L18Levels.L01
msgid "If `Series (fun n ↦ |a n|)` converges, then `Series a` converges."
msgstr ""

#: Game.Levels.L1Pset.L1Pset3
#: Game.Levels.L3Pset.L3Pset3
#: Game.Levels.L6Pset.L6Pset3
#: Game.Levels.L7Pset.L7Pset3
#: Game.Levels.L8Pset.L8Pset3
#: Game.Levels.L9Pset.L9Pset3
#: Game.Levels.L10Pset.L10Pset4
#: Game.Levels.L16Pset.L16Pset3
msgid "Problem 3"
msgstr ""

#: Game.Levels.L2NewtonsCalculationOfPi.L01_SeqConvDef
msgid "Prove that the constant sequence converges to its constant value.\n"
"This is the Machinist's dream scenario: we're already producing exactly what's required!"
msgstr ""

#: Game.Levels.L5Levels.L01_DoubleSeqConv
msgid "For any real numbers `x` and `y`, we have `|x * y| = |x| * |y|`."
msgstr ""

#: Game.Levels.L11Levels.L01_IsCauchyOfLim
msgid "Usage: `have factName : |x - y| = |y - x| := by apply abs_sub_comm`"
msgstr ""

#: Game.Levels.L14Levels.L01_BolzanoWeierstrass
msgid "If a sequence `a : ℕ → X` (where `X` could be `ℚ` or `ℝ`) has unbounded peaks, then it has an `Antitone` subsequence."
msgstr ""

#: Game.Levels.L17Pset.L06
msgid "The Comparison Test"
msgstr ""

#: Game.Levels.L9Pset.L9Pset3
msgid "`1 + 2 + ... + N = N * (N + 1) / 2`."
msgstr ""

#: Game.Levels.L16Pset.L16Pset1
msgid "For any real `x` and natural number `n`,\n"
"`(1-x)*(1+...+x^(n-1)) = 1- x^n`."
msgstr ""

#: Game.Levels.L20Levels.L01
msgid "Limits of Functions"
msgstr ""

#: Game.Levels.L3Levels.L01_ArchProp
msgid "The `push_cast` tactic handles coercions between number types, particularly useful when working with natural numbers that need to be treated as real numbers (or integers, or rationals)."
msgstr ""

#: Game.Levels.L18Pset.L06
msgid "Prove `MonotoneSeriesEven`"
msgstr ""

#: Game.Levels.L17Levels.L03
msgid "Series Order Theorem"
msgstr ""

#: Game.Levels.L6Levels.L02_LeftRight
msgid "# Level 3: Left and Right - Making Choices in Mathematics\n"
"\n"
"After mastering `split_ands` to handle situations where we need to prove multiple things simultaneously, we now turn to a fundamentally different scenario: proving that at least one of several possibilities is true. This is the world of \"or\" statements (`∨`), and it requires a completely different strategic approach.\n"
"\n"
"While `split_ands` was about being comprehensive—proving every part of a conjunction—proving an \"or\" statement (\"disjunction\") is about making a strategic choice. When faced with proving \"P or Q,\" you don't need to prove both `P` and `Q`. You just need to prove one of them! This might seem easier, but it requires good mathematical judgment: which path should you choose?\n"
"\n"
"Think of this like a detective solving a case. To prove \"the butler did it OR the gardener did it,\" you don't need to prove both are guilty -- you just need solid evidence against *one* of them. The `left` and `right` tactics are your way of saying \"I'm going to focus my investigation on this suspect.\"\n"
"\n"
"In mathematical analysis, this choice-making appears everywhere. For instance, when proving that a sequence is bounded, you might show either that it's bounded above by some constant, or bounded below by another constant, or both. Sometimes one direction is much easier to establish than the other.\n"
"\n"
"## New Tools You'll Need\n"
"\n"
"- `left` and `right` tactics\n"
"\n"
"When your goal is to prove an \"Or\" statement, `P ∨ Q`, you can do that by proving either `P` or `Q`. If you want to prove `P`, then say `left`, and the Goal will turn into `P`.\n"
" If you want to prove `Q`, then say `right`, and the Goal will turn into `Q`."
msgstr ""

#: Game.Levels.L3PsetIntro
msgid "Pset 3"
msgstr ""

#: Game.Levels.L4Levels.L01_NonConverge
msgid "Step 3:\n"
"Once more, in natural language.\n"
"\n"
"\n"
"## Natural Language Proof\n"
"\n"
"**Theorem:** The sequence `1`, `-1`, `1`, `-1`, ... does not converge.\n"
"\n"
"**Proof by contradiction:**\n"
"1. Suppose the sequence converges to some limit `L`\n"
"2. Set `ε = 1 / 2` and apply the convergence definition\n"
"3. This guarantees some `N` such that `|a n - L| < 1 / 2` for all `n ≥ N`\n"
"4. Consider two specific indices: `n = 2N` and `n = 2N+1` (both are `≥ N`)\n"
"   - `a (2N) = (-1)²ᴺ = 1`, so `|1 - L| < 1 / 2`\n"
"   - `a (2N+1) = (-1)²ᴺ⁺¹ = -1`, so `|-1 - L| < 1 / 2`.\n"
"5. But then:\n"
"\n"
"   `2 = |1 - (-1)| = |(1 - L) + (L + 1)|`\n"
"\n"
"     `≤ |1 - L| + |L + 1|`     [triangle inequality]\n"
"\n"
"     `= |1 - L| + |-1 - L|`    [algebraic manipulation]\n"
"\n"
"     `< 1/2 + 1/2 = 1`         [from steps above]\n"
"6. This gives us `2 < 1`, which is impossible. QED\n"
"\n"
"## Key Insights\n"
"\n"
"- **Geometric intuition:** Any proposed limit L must be within 1/2 of both 1 and -1 simultaneously, but these values are distance 2 apart\n"
"- **Critical ε choice:** We chose ε = 1/2 strategically; larger values like ε = 1.5 wouldn't work since L = 0 could satisfy the constraints.\n"
"- **Triangle inequality:** The key step uses |a + b| ≤ |a| + |b| to convert the distance between sequence values into a sum of distances from the limit.\n"
"\n"
"This proof exemplifies how rigorous definitions resolve historical mathematical debates and provide clear criteria for convergence."
msgstr ""

#: Game.Levels.L6PsetIntro
msgid "Pset 6"
msgstr ""

#: Game.Levels.L6Levels.L03_DotNotation
msgid "Dot Notation"
msgstr ""

#: Game.Levels.L23Levels.L02
msgid "Integration Converges!"
msgstr ""

#: Game.Levels.L1Pset.L1Pset3
msgid "# Problem 3\n"
"\n"
"You've just learned to add any necessary\n"
"auxiliary\n"
"facts to the list of hypotheses via the\n"
"`have` tactic.\n"
"In this problem,\n"
"you might find the following new idea useful.\n"
"\n"
"You already know that if you\n"
"have a hypothesis `h : X = Y`, and the Goal\n"
"contains `X`, then if you `rewrite [h]`,\n"
"then any instances of `X` in the goal\n"
"get replaced by `Y`.\n"
"But what if you have another hypothesis `h2`,\n"
"and you want to replace `X`'s in `h2` by `Y`s, what should you do then?\n"
"Elementary, my dear Watson!\n"
"You simply type:\n"
"\n"
"`rewrite [h] at h2`.\n"
"\n"
"So the syntax is `rewrite [h]` as before, then\n"
"the word `at`, and finally the name of the\n"
"hypothesis where you want the rewriting to happen.\n"
"Similarly, you can say `ring_nf at h2`,\n"
"and any algebra in hypothesis `h2` will be put into normal form.\n"
"\n"
"Now you should be able to solve this problem!"
msgstr ""

#: Game.Levels.L1PsetIntro
msgid "Pset 1"
msgstr ""

#: Game.Levels.L23Levels.L01
msgid "# Level 1: Riemann Sum Refinement\n"
"\n"
"**The Setup**: We have a uniformly continuous function on `[a,b]` - that is, there's a single `δ > 0` such that whenever two points are within `δ` of each other, the function values differ by at most `ε`.\n"
"\n"
"**The Question**: If we refine our Riemann sum partition from `n` subintervals to `n * k` subintervals, how much can the Riemann sum change?\n"
"\n"
"**The Intuition**: When we go from `n` to `n * k` subintervals, we're making the partition finer. If our original partition was already fine enough (meaning `2 * (b - a) / n < δ`), then the sample points in the refined partition shouldn't be too far from the corresponding sample points in the coarse partition. By uniform continuity, this means the function values shouldn't differ by much either.\n"
"\n"
"**Your Goal**: Prove that under these conditions, the difference between the two Riemann sums is bounded by `(b - a) * ε`. This makes sense dimensionally: `ε` measures how much the function can vary locally, and `(b - a)` measures the size of the interval we're integrating over.\n"
"\n"
"**Key Tool**: The `sum_of_prod` lemma lets you reorganize a sum over `m * n` terms as a double sum:\n"
"\n"
"`∑ i ∈ range (m * n), f i = ∑ j ∈ range m, ∑ k ∈ range n, f (j + k * m)`\n"
"\n"
"This will help you compare the refined sum (with `n * k` terms) to the original sum (with `n` terms) by grouping the refined sum into `n` blocks of `k` terms each."
msgstr ""

#: Game.Levels.L8Pset.L8Pset4
msgid "If a sequence `σ : ℕ → ℕ` is strictly increasing, then it grows at least linearly."
msgstr ""

#: Game.Levels.L3Levels.L02_OneOverN
msgid "Multiply the inequality `N ≤ n` by ε: `have f4 : N * ε ≤ n * ε := by bound`"
msgstr ""

#: Game.Levels.L18Pset.L01
msgid "# Level 1: `DiffOfSeries`\n"
"\n"
"Prove `DiffOfSeries`.\n"
"\n"
"## New Theorem: `sum_Ico_succ`."
msgstr ""

#: Game.Levels.L2NewtonsCalculationOfPi.L01_SeqConvDef
msgid "The `change` tactic changes a goal to something definitionally equal to it. If the definition of `X` is `Y`, that is, `X := Y`, and the Goal is `X`, you can write `change Y` and the Goal will change to `Y`. You can also\n"
"do this at a hypothesis; if you have a hypothesis `h : X`, you can write `change Y at h`, and `h` will change to `h : Y`."
msgstr ""

#: Game.Levels.L25Lecture
msgid "# Lecture 25: Swapping Limits and Integrals\n"
"\n"
"**SIMPLICIO:** We meet one last time, Socrates.\n"
"\n"
"**SOCRATES:** For now, old friend.\n"
"\n"
"**SIMPLICIO:** Hey, quick question. Why do we need general indexing types, can't we just index everything by natural numbers?\n"
"\n"
"**SOCRATES:** Ah, great question! Besides the generality that abstract indexing types provide, there's a crucially important reason: sometimes, the objects we want to index by have *no* possible indexing by natural numbers at all!\n"
"\n"
"**SIMPLICIO:** Really? Like what?\n"
"\n"
"**SOCRATES:** Let's back up a little. Professor David Hilbert liked to tell this story in terms of a magical hotel. So: imagine a hotel with infinitely many rooms, numbered `R1, R2, R3, ...`. Now, suppose that every room is occupied, with guest `G1` in room `R1`, guest `G2` in room `R2`, and so on.\n"
"There are infinitely many rooms, but also infinitely many guests, so everybody has a room, and every room is taken. $\\infty = \\infty$. So far so good?\n"
"\n"
"**SIMPLICIO:** I mean, yeah, except for the infinitely large hotel and infinitely many people thing...\n"
"\n"
"**SOCRATES:** Come on, go with me here. Now, on the first night, a new guest, `G0`, arrives, asking for a place to stay. The clerk says, \"Hey buddy, can't you read? No vacancy. Sorry!\"\n"
"\n"
"Professor Hilbert overhears this from his office, and comes around to the front desk. He says, \"Wait a minute, sir; I'm sorry, yes, we can host you tonight.\"\n"
"\n"
"The clerk protests: \"But Professor, all the rooms are taken! Just because the hotel has infinitely many rooms doesn't mean you can ask `G0` to go all the way to the 'end' somehow, right?\"\n"
"\n"
"Hilbert replies: \"You're absolutely right, that would be impossible. I can't tell guest `G0` to go to 'the end', because that's not a room assignment. Here's the hotel's ledger; every guest needs to have exactly one room assigned to them. But! That doesn't necessarily mean that we're out of luck,\" and he gets on the hotel loudspeaker: \"Attention all guests! I'm sorry to inconvenience you, but may I please request that the guest in room `Rn` move to room `R(n+1)`? Thank you!\"\n"
"\n"
"Hilbert turns to the guest, \"In just a moment, sir, room `R1` will be free for you.\" He asks the clerk to update the ledger, and returns to his office.\n"
"\n"
"**SIMPLICIO:** Wow, that's clever! So wait, $\\infty + 1 = \\infty$ after all?\n"
"\n"
"**SOCRATES:** You ain't seen nothin' yet, kid. On the second night, the hotel is again full, with guest `G1` back to room `R1`, and so on.\n"
"\n"
"**SIMPLICIO:** Oh so guest `G0` left, and everybody had to move again? I don't think I'd like to stay at this hotel...\n"
"\n"
"**SOCRATES:** Shush. On the second night, a car pulls up with 10 people in it. The clerk knows exactly what to do; he gets on the speaker and says, \"Will the guest in room `Rn` please move to room `R(n+10)`? Thank you!\" And just like that, rooms `R1` through `R10` are free for the new guests.\n"
"\n"
"Then on the third night, a bus arrives, but this time it has *infinitely* many passengers, `P1`, `P2`, `P3`, and so on. The clerk says to them, \"Gee, I'm really sorry. I could accommodate 100 or 1,000 or even 1,000,000 of you, but I can't tell the guest in room `Rn` to move to room `R(n+∞)`, that's not a room assignment! I'm really sorry, but we just won't be able to host you tonight.\"\n"
"\n"
"**SIMPLICIO:** Well, yeah, now you're asking for $\\infty + \\infty$! Surely that's bigger than $\\infty$... No?\n"
"\n"
"**SOCRATES:** Professor Hilbert again overhears this, and comes out from his office. He says to the bus driver, \"Please give me just a moment, and we'll make space for you all.\"\n"
"\n"
"The clerk protests, \"But Professor, how can we do that? You said I couldn't send anyone infinitely far down the hotel?\"\n"
"\n"
"Professor Hilbert, ignoring the clerk, gets on the speaker: \"Attention all guests! I'm sorry to inconvenience you, but may I please request that the guest in room `Rn` move to room `R(2n)`? Thank you!\" Hilbert turns to the clerk: \"And now, all the odd numbered rooms are free for the bus passengers. Please update the ledger accordingly.\"\n"
"\n"
"**SIMPLICIO:** Whoa, cool! So $\\infty + \\infty = \\infty$ too!\n"
"\n"
"**SOCRATES:** On the fourth night, the bus has left, and the original guests are back in their rooms. Now ten buses arrive, each with infinitely many passengers. The clerk knows exactly what to do.\n"
"\n"
"**SIMPLICIO:** Ok, I get it.\n"
"He gets on the speaker and tells the guest in room `Rn` to move to room `R(10n)`, right? Then passengers from bus 1 go to rooms `R1, R11, R21, ...`, the passengers from bus 2 go to rooms `R2, R12, R22, ...`, and so on. That's cool, so $10 \\times \\infty = \\infty$ too.\n"
"\n"
"**SOCRATES:** Right! On the fifth night, the hotel is back as it started, and a caravan arrives of *infinitely many* buses, each with *infinitely many* passengers. Bus `1` has passengers `P(1,1), P(1,2), P(1,3), ...`, and bus `2` has passengers `P(2,1), P(2,2), P(2,3), ...`, and so on.\n"
"\n"
"The clerk says to them, \"Look, I think we don't have room, because I can't tell the guest in room `Rn` to move to room `R(n × ∞)`. But this Professor here is a real whiz; he just might have something up his sleeve.\"\n"
"\n"
"Hilbert comes out from his office, and says to the clerk, \"Indeed, we can handle them all! Please ask the guests to move to twice their room number as before, to free up infinitely many rooms.\"\n"
"\n"
"The clerk starts to protest, thinking the absentminded Professor might have not seen that the caravan has infinitely many buses. But Hilbert cuts him off: \"Here's what we're going to do: In the first available room, please place passenger `P(1,1)`. Then `P(1,2)`, then `P(2,1)`. Then `P(3,1)`, `P(2,2)`, and `P(1,3)`, and so on, zigzagging through the passenger list. As you'll see, everyone has a clearly defined, finite room number, with nobody left behind.\"\n"
"\n"
"**SIMPLICIO:** Whoa, that's crazy, even $\\infty \\times \\infty = \\infty$! So I guess infinity is so big, you can fit just about anything!\n"
"\n"
"**SOCRATES:** Well, now it's the sixth night, and the hotel is empty. I guess the guests got tired of being moved around so much, and the reviews started to tank! Only one bus arrives. But this is an extremely large party bus from Sweden, blasting ABBA tunes. Everybody on this bus has a very strange name. It consists of an infinite sequence of `A`s and `B`s. For example, one passenger has the name `ABBAAABABBA...`, going on forever. And another is called `AAABBBBAA...`, and so on. In fact, for *any* sequence of `A`s and `B`s, there is a single passenger on this bus with exactly that name. Their manager comes off the bus to speak with the clerk.\n"
"\n"
"The clerk says, \"Gee whiz, that's a pretty big bus, sir. But don't worry, I'm *sure* we can find a way to fit everybody. Let me just get the Professor.\"\n"
"\n"
"Hilbert steps out of his office, and sighs with disappointment. \"I'm very sorry,\" he says to the manager, \"but we will *not* be able to accommodate your passengers.\"\n"
"\n"
"The clerk is shocked. \"But Professor, why not? We've handled infinitely many buses with infinitely many passengers before! This is just *one* bus!\"\n"
"\n"
"Hilbert says to the clerk, \"Take out the ledger. Let's work backwards. Imagine that we're done placing *every single person* from that bus into a room. So in room `R1`, we have `ABBAAA...`, say, and in room `R2`, we have `AAABBB...`, and in room `R3` is `BABBAA...` and so on. Ok? I claim we're not done, and we've left someone off the ledger. If I can prove to you that at least *one passenger hasn't been assigned a room, then do you see how the entire enterprise is futile?\"\n"
"\n"
"The clerk nods reluctantly. Hilbert continues: \"The person in room `R1` is named `ABBAAA...`, which starts with `A`. So if I give you the name of a person whose first letter is `B`, then that person is certainly not in room `R1`, right?\" The clerk nods. \"Now, the person in room `R2` is named `AAABBB...`. If I give you the name of a person whose *second* letter is `B`, then that differs from the second letter of the person in room `R2`, and so that person is not in room `R2`. Do you follow?\" The clerk nods again.\n"
"\n"
"**SIMPLICIO:** Oh, I see it!! You're going to take the name of the person in room `Rn`, and change the `n`-th letter! That way, you'll make a name that differs from *everybody's* name in the ledger, by at least one letter! So whoever that passenger is, and it's certainly someone on the bus, they can't be in any room! Whoa! So wait, how big of an infinity is on this bus?\n"
"\n"
"**SOCRATES:** Indeed! Let's think. If we only had names that were four letters long, like `ABBA` or `AABB` or `BABA`, how many such names are there?\n"
"\n"
"**SIMPLICIO:** Easy peasy, there are $2^4 = 16$ such names, since each of the four letters can be either `A` or `B`. Oh! So the ABBA bus has $2^\\infty$ people on it? Whoa, and we just showed that $2^\\infty > \\infty$!\n"
"\n"
"**SOCRATES:** Exactly right. This is called the *Cantor diagonalization argument*, and it shows that there are different sizes of infinity. So let me ask you: what the heck does any of this have to do with indexing sets?\n"
"\n"
"**SIMPLICIO:** Ok, I see it! The first night we just reindexed the naturals `ℕ` by `n ↦ n + 1`. The third night, we indexed all the integers `ℤ`, which are 'twice' as large as `ℕ`. That is, we can list every element of `ℤ` as: `0`, `-1`, `1`, `-2`, `2`, and so on (the even indices are the original sequence, and the odd indices are the negative newcomers!). What's the meaning of the fifth night?\n"
"\n"
"**SOCRATES:** So then we had infinitely many buses with infinitely many passengers. We can think of the buses as denominators, and passengers as numerators. We indexed the rationals, `ℚ`! We can assign an ordering to the rationals by zigzagging through the fraction table, just like we did with the infinitely many passengers on infinitely many buses.\n"
"\n"
"**SIMPLICIO:** Hah! So cool! And the sixth night?\n"
"\n"
"**SOCRATES:** Think about the real numbers `ℝ`. Can we index those, assign *every* real number to a room in the hotel? I claim we can't even do it for all the reals in `[0, 1]`. In fact, just look at the decimals in that range that use only `0`s and `1`s, like `0.101100111...` and `0.111000101...`. That *is* the ABBA bus, and those real numbers can't be indexed by `ℕ`, so certainly all of the reals can't either!\n"
"Here's a fun Veritasium video you can watch all about this topic (right-click to get it to pop up in a new tab):\n"
"[![Veritasium Video](https://img.youtube.com/vi/OxGsU8oIWjY/maxresdefault.jpg)](https://youtu.be/OxGsU8oIWjY)\n"
"\n"
"**SIMPLICIO:** That's wild stuff! Hey, if $2^\\infty$ is strictly bigger than $\\infty$, in this sense, is there some infinity, like, in between them?\n"
"\n"
"**SOCRATES:** Whoa, hold your horses, lad! That question is too deep for us now. (Go google the `Continuum Hypothesis`. It turns out: that depends on what the definition of \"is\" is... Don't google *that*.) All I want you to understand for now is that there are surprisingly many things that we *can* index by `ℕ` (by the way, anything that can be indexed by `ℕ` is called *countable*), but there are also many \"*uncountable*\" things, that is, those that cannot be indexed by `ℕ`. So we need general indexing types to handle all the different situations that arise in analysis.\n"
"\n"
"**SIMPLICIO:** Cool! So what's today's lesson?\n"
"\n"
"**SOCRATES:** Well, I still owe you a justification for Newton's term-by-term integration of infinite series. So let's jump straight there. If you recall, Newton argued that, since\n"
"\n"
"$\n"
"\\sqrt{1-x^2}\n"
"= 1 - \\frac{x^2}{2} - \\frac{x^4}{8} - \\frac{x^6}{16} - \\frac{5x^8}{128} - \\cdots,\n"
"$\n"
"\n"
"he could integrate term by term:\n"
"\n"
"$\\int_0^{1/2} \\sqrt{1-x^2} \\, dx =\n"
"\\int_0^{1/2} 1 dx - \\int_0^{1/2}  \\frac{x^2}{2}  dx -  \\int_0^{1/2} \\frac{x^4}{8} dx  - \\int_0^{1/2} \\frac{x^6}{16}dx - \\cdots.$\n"
"\n"
"In other words, he had a sequence of functions `fₙ(x)` (the sum of the first `n` terms of the series),\n"
"and he claimed that since `fₙ` converged to `F(x) = √(1 - x²)`, then\n"
"\n"
"`∫ F = lim (∫ fₙ)`.\n"
"\n"
"So is this actually true, and under what conditions can it be justified?\n"
"\n"
"**SIMPLICIO:** Ok, let me guess. Of course each `fₙ` had better be integrable, otherwise the whole thing falls apart. But I bet you're going to tell me a slew of examples where pointwise convergence isn't enough?\n"
"\n"
"**SOCRATES:** You know me very well by now. Indeed, you need to keep just a few examples in mind, and you'll\n"
"see clearly what's going on, and what can go wrong. Let's start with this example. Let `fₙ(x)` be the indicator function of the interval `[n, n+1]`.\n"
"That is, it's `1` if `x ∈ [n, n+1]`, and `0` otherwise. Each `fₙ` is integrable, since it's just a step function, and has integral `1`.\n"
"So `lim (∫ fₙ) = 1`.\n"
"\n"
"But for any fixed `x`, what happens to the limit of `fₙ(x)`?\n"
"\n"
"**SIMPLICIO:** Yep, I see it, eventually `fₙ(x)` becomes `0` for all sufficiently large `n`, once `n` exceeds `x`. So the pointwise limit function `F(x)` is identically `0`, which of course has integral `∫ F = 0 ≠ 1`. What else? Maybe this example is bad because you're shifting the intervals off to infinity? What if we keep all the action in `[0,1]`?\n"
"\n"
"**SOCRATES:** Good idea. Let's try this: let `fₙ(x) = n` if `x ∈ [0, 1/n]`, and `0` otherwise, and let's integrate it on the nice, *compact* region `[0, 1]`. What's going on there?\n"
"\n"
"**SIMPLICIO:** Ok, each `fₙ` is integrable, since it's again a step function. The integral is `∫ fₙ = n × (1/n) = 1`. So again `lim (∫ fₙ) = 1`. But for any fixed `x > 0`, eventually `n` gets so large that `x` is outside `[0, 1/n]` (`ArchProp`!!), so `fₙ(x) = 0` for all sufficiently large `n`. And at `x = 0`, well, `fₙ(0) = n`, which diverges. So the pointwise limit function `F(x)` is again identically `0` for all `x > 0`, and undefined at `x = 0`. But I'm guessing a single point doesn't affect the integral; we can just say `F(x) = 0` everywhere, and so again `∫ F = 0 ≠ 1`. Ah, but these functions are not continuous! Maybe that's the problem?\n"
"\n"
"**SOCRATES:** Good thinking. Let's try to make them continuous. Consider the functions `fₙ(x)` defined as follows:\n"
"- `fₙ(x) = n^2 x` for `x ∈ [0, 1/n]`\n"
"- `fₙ(x) = -n^2 x + 2n` for `x ∈ [1/n, 2/n]`\n"
"- `fₙ(x) = 0` for `x ∉ [0, 2/n]`\n"
"So we've made a little \"tent\" shape that peaks at height `n` at `x = 1/n`, and goes back down to `0` by `x = 2/n`. Each `fₙ` is continuous, and integrable, with integral `∫ fₙ = 1`, because the area is a triangle with base `2/n` and height `n`.\n"
"So `lim (∫ fₙ) = 1`. But again, for any fixed `x > 0`, eventually `n` gets so large that `x` is outside `[0, 2/n]`, so `fₙ(x) = 0` for all sufficiently large `n`. And at `x = 0`, we have `fₙ(0) = 0` for all `n`. So the pointwise limit function `F(x)` is again identically `0` for all `x`, and so again `∫ F = 0 ≠ 1`. Hmm, so continuity isn't enough either.\n"
"\n"
"**SIMPLICIO:** Wow, these are some tricky examples. Ok, so what is it, what's the condition we need to make this work?\n"
"\n"
"**SOCRATES:** You already know it!\n"
"\n"
"**SIMPLICIO:** Oh... Is it... *uniform convergence*? Let's think. Suppose `fₙ` is integrable, and converges to `F` uniformly. Let's think about\n"
"the difference between the order `N` Riemann sum for `F`, and the order `N` Riemann sum for `fₙ`. Since the convergence is uniform, for any `ε > 0`, there exists `M` such that for all `n ≥ M`, we have `|fₙ(x) - F(x)| < ε`, regardless of what `x` is.\n"
"So the difference between the Riemann sums will be:\n"
"\n"
"`| (Σ (i=1 to N) fₙ(xᵢ) Δx) - (Σ (i=1 to N) F(xᵢ) Δx) | ≤ Σ (i=1 to N) |fₙ(xᵢ) - F(xᵢ)| Δx < Σ (i=1 to N) ε Δx = N × ε × ((b-a)/N) = ε (b-a)`.\n"
"\n"
"Cool! That means that we can *simultaneously* show that `F` is integrable (by comparing its Riemann sums to those of `fₙ` for large `n`), and that the integrals of the `fₙ`s converge to the integral of `F` (by the same reasoning). So uniform convergence should do it all for us!\n"
"\n"
"**SOCRATES:** Exactly right! So let's finish strong with a proof!"
msgstr ""

#: Game.Levels.L6Pset.L6Pset1
msgid "# Problem 1\n"
"\n"
"You know that `hx : x = 2`, `hy : y = 3`, and that `hz : z = 4`.\n"
"Your goal is to show that: `x = 2 ∧ y = 3 ∧ z = 4`."
msgstr ""

#: Game.Levels.L1RealAnalysisStory.L09_big_boss
msgid "# The Final Challenge\n"
"\n"
"Congratulations! You've learned many fundamental tactics for mathematical reasoning in Lean:\n"
"- `apply hypothesisName` for when a hypothesis matches the goal\n"
"- `rfl` for reflexivity (proving `X = X`)\n"
"- `rewrite [hypothesisName]` for rewriting using equalities\n"
"- `ring_nf` for algebraic manipulation\n"
"- `use` for providing witnesses to existence statements in goals\n"
"- `intro` for handling universal quantifiers in goals\n"
"- `specialize` for applying universal statements to specific values in hypotheses\n"
"- `choose value hypothesisOnValue using ExistentialHypothesis` for extracting information from existence statements in hypotheses\n"
"\n"
"Here's a little \"Universal/Existential Quantifier Cheat Sheet\":\n"
"\n"
"|           | ∀        | ∃      |\n"
"|-----------|----------|--------|\n"
"| **Goal**  | `intro`    | `use`    |\n"
"| **Hypothesis** | `specialize` | `choose` |\n"
"\n"
"Now it's time for your first **Big Boss** - a problem that requires you to use almost ALL of these tactics in a single proof!\n"
"\n"
"**Lecture 1 Big Boss**\n"
"Given a function `f` and information about its behavior, prove a complex statement that involves existence, universals, algebra, and rewriting.\n"
"\n"
"This is what real mathematical proofs look like - a careful orchestration of multiple reasoning steps. You've got this! Use everything you've learned.\n"
"\n"
"**Extra Challenge**\n"
"If you want to *really* challenge yourself, play this level \"blind\". Write the assumptions and goal down on paper, close the computer, solve it by hand, keeping track *in your mind* of what happens to the game board after each command, and only once you’ve worked it all out, open the computer and see if Lean accepts your solution.\n"
"\n"
"Why do you think that this would this be a good thing to do?\n"
"\n"
"In general, I hope your *goal* in taking this course is to make your \"Real Analysis Brain Muscles\" stronger. By the end, you should be *really good* at\n"
"solving Real Analysis problems on paper, where you don't have Lean showing\n"
"you the Goal State after every move.\n"
"More broadly, the purpose of learning to solve Real Analysis problems is to learn to *think*, clearly, precisely. Strengthening your ability to work with pen and paper (or just mentally) directly transfers to *any* other context where you're exploring ideas, wrestling with complicated arguments, or trying to communicate clearly to others.\n"
"\n"
"An LLM could easily work through all these Lean levels by pattern matching and logical manipulation - just as you could solve multiplication problems by plugging them into a calculator instead of memorizing your times tables. But that completely defeats the purpose of the exercise, which is to rewire your brain and build mathematical intuition. It's like deciding that you want to bench press 200 pounds, loading up the bar, and then using a forklift to lift it for you while you stand underneath - you might have moved the weight, but you haven't gotten any stronger. The real value isn't in producing correct proofs, it's in the cognitive transformation that happens when you *struggle* through the reasoning yourself, building the mental pathways that let you see mathematical structure intuitively."
msgstr ""

#: Game.Levels.L18Pset.L03
msgid "Prove `AntitoneLimitBound`"
msgstr ""

#: Game.Levels.L25Levels.L01
msgid "If `fₙ` converges uniformly to `F`, and each `fₙ` is integrable on `[a, b]`, then `F` is integrable on `[a, b]`, and the integral of `F` equals the limit of the integrals of `fₙ`."
msgstr ""

#: Game.Levels.L1RealAnalysisStory.L08_choose
msgid "If you're struggling to prove that `2 ^ 2 = 4`, it's\n"
"a basic fact in a *ring*..."
msgstr ""

#: Game.Levels.L23Lecture
msgid "# Lecture 23: Uniformity II: Continuity\n"
"\n"
"**SOCRATES:** Last time, we saw that limits of continuous functions are continuous, but only if the convergence is *uniform*. And we saw how Riemann sums, if they converge\n"
"to a limit, define the integral of a function on an interval. Let's talk about what conditions might ensure that Riemann sums converge.\n"
"\n"
"**SIMPLICIO:** Hmm... Is it enough for the function to be continuous?\n"
"\n"
"**SOCRATES:** Well, that's a good guess. The answer is *no*... and *yes*. Let's think about how we could prove that the sequence of Riemann sums converges. First of all, do we know what it should converge *to*?\n"
"\n"
"**SIMPLICIO:** Umm... I guess we don't know yet -- that's the mystery of the integral! We just want to show that it converges to *something*. Oh! I know what to do in these cases: we need to show that the sequence of Riemann sums is Cauchy.\n"
"\n"
"**SOCRATES:** Exactly! So let's think about how the difference\n"
"\n"
"`|RiemannSum f a b m - RiemannSum f a b n|`\n"
"\n"
"can be made small.\n"
"\n"
"**SIMPLICIO:** Well, if `m` and `n` are very large, then the partitions are very fine, so the Riemann sums should be close to each other. Right? I guess if you make the partitions finer, after a certain point the Riemann sums shouldn't change much.\n"
"\n"
"**SOCRATES:** Yes, that's the right intuition. But we need to be a bit more precise.\n"
"Is there something we could do to compare Riemann sums with different numbers of subintervals? What if one of the numbers is a multiple of the other?\n"
"\n"
"**SIMPLICIO:** Oh! If `m` is a multiple of `n`, say `m = n * k`, then we can compare `RiemannSum f a b (n * k)` to `RiemannSum f a b n`. Maybe we can show that if the partition with `n` subintervals is fine enough, then the Riemann sum with `n * k` subintervals is close to that with `n` subintervals. I think i see how to do it. But! We'll need a single `δ` that works for *all* points in `[a,b]`, not a different `δ` for each point.\n"
"\n"
"**SOCRATES:** Bingo! You just invented the notion of *uniform continuity*! Tell me what it should mean.\n"
"\n"
"**SIMPLICIO:** Wait, what's uniform continuity? Does that have anything to do with uniform convergence that we just discussed?\n"
"\n"
"**SOCRATES:** Oh, sorry! You're right, that can be confusing. We need to make sure to distiguish these two somewhat similar-sounding but actually rather different concepts. I think of uniform convergence as a \"vertical\" notion: you have a family of different functions `fₙ` converging to `F`, and the convergence happens uniformly over the entire domain. Uniform continuity, on the other hand, is more of a \"horizontal\" notion: it applies to a single function `f`. What should it mean, given our discussion about Riemann sums?\n"
"\n"
"**SIMPLICIO:** Hmm... So ordinary continuity of a function `f` at a point `x` means the following:\n"
"\n"
"Given an `ε > 0` and a point `x`, we can find a `δ > 0` (which may depend on `x`!!) such that for all `y` with `|x - y| < δ`, we have `|f x - f y| < ε`.\n"
"\n"
"\n"
"And so the \"uniformity\" should say that the `δ > 0` can be chosen regardless of what `x` is. Ah! Something like this?\n"
"\n"
"Given an `ε > 0`, we can find a `δ > 0` such that for *all* `x` and `y` in the domain, if `|x - y| < δ`, then `|f x - f y| < ε`.\n"
"\n"
"Again, it's just about reordering the quantifiers?\n"
"\n"
"**SOCRATES:** Yes, that's exactly right! You've just defined *uniform continuity*. So just like in pointwise convergence where `N` can depend on the point `x` but uniform convergence requires a single `N` that works for all `x`, here ordinary continuity allows `δ` to depend on `x` but uniform continuity requires a single `δ` that works for all `x` and `y`. So that's how they're similar but different!\n"
"\n"
"**SIMPLICIO:** Ok, I think I get it.\n"
"\n"
"**SOCRATES:** What we'll prove today is that if a function is uniformly continuous on `[a,b]`, then its Riemann sums converge to a limit, and this limit is what we call the integral of the function on `[a,b]`. But this raises another fundamental question: When is a continuous function *uniformly* continuous? Remember how we proved that `f(x) = x ^ 2 - 1` is continuous everywhere? Remember what value of `δ` we chose once `ε` was given?\n"
"\n"
"**SIMPLICIO:** For the third time, we chose `δ = ε / (2|x|+1)`. Oh, I see! So `δ` depended on `x`, which means that `f(x) = x ^ 2 - 1` is not uniformly continuous on all of `ℝ`.\n"
"\n"
"**SOCRATES:** Right. But! When we integrate a function on a finite interval like `[a, b]`, we only care about its behavior on that interval. Let's say we wanted to integrate `f(x) = x ^ 2 - 1` on the interval `[-10,10]`. Can we find a `δ` that works for *all* `x`, just in that range?\n"
"\n"
"**SIMPLICIO:** Hmm... Well, on `[-10,10]`, the maximum value of `|x|` is `10`. Instead of a different value of `δ = ε / (2|x|+1)` for each `x`, we can just use the largest possible denominator, which is when `|x| = 10`. That is, we can use `δ = ε / (2*10 + 1) = ε / 21` for *all* `x` in `[-10,10]`.\n"
"\n"
"**SOCRATES:** Exactly! So on the interval `[-10,10]`, the function `f(x) = x ^ 2 - 1` *is* uniformly continuous. In fact, there's a general theorem here: It turns out that any function that is continuous on a \"*compact*\" interval like `[-10, 10]` is automatically uniformly continuous on that interval. But this is not a theorem in calculus; it's a result in topology! So to understand some of the next steps of calculus, we need to learn a bit of topology first.\n"
"\n"
"**SIMPLICIO:** Ok, what's topology?\n"
"\n"
"**SOCRATES:** Well, of all the subjects in mathematics, topology is among the youngest. Geometry and algebra have been studied for thousands of years, and calculus for a few hundred years. But topology only really started to be developed \"officially\" in the 19th and early 20th centuries. In fact, once you see just how important topology is for understanding calculus, you'll feel embarrassed for all of the great mathematicians of the past who did calculus without it! The proper notion of compactness was not fully understood until the late 19th century, well after Riemann's fundamental work on integration.\n"
"\n"
"**SIMPLICIO:** Wow, that's surprising. Ok, so what is compactness?\n"
"\n"
"**SOCRATES:** Like so many other concepts in this course, I hope you'll come to\n"
"appreciate how complicated and subtle the idea is, despite the fact that we can now\n"
"make the definition quite intuitively clear. It took people decades to figure out *exactly* what compactness should mean! Let's go back to uniform continuity. You have continuity at every single point `x` in your set `S`. So for every `x`, there's a little ball `(x - δₓ, x + δₓ)` where continuity holds with `δₓ` depending on `x`. And of course all these balls cover your set `S ⊆ ⋃ x, (x - δₓ, x + δₓ)`.\n"
"Here's the key idea for compactness. What if: whenever you can cover `S` by any number of balls (possibly infinitely many, even uncountably many), you can *always* find a subcover that uses only *finitely many* of those balls? **That** is the key idea and definition of compactness!\n"
"\n"
"**SIMPLICIO:** Ah! And if I have only finitely many balls covering `S`, then I can just take the minimum of all the `δ`s for those balls, and that minimum `δ` will work for the entire set `S`! I see now how compactness leads to uniform continuity. At least I think I do.\n"
"\n"
"**SOCRATES:** Good; let's find out for *sure*. :)"
msgstr ""

#: Game.Levels.L19Levels.L03
msgid "For a sequence `a : ℕ → ℝ` and an injective `σ : ℕ → ℕ`, we have that:\n"
"`Series (a ∘ σ) n = ∑ k ∈ image σ (range n), a k` holds for any `n`."
msgstr ""

#: Game.Levels.L10Lecture
msgid "# Lecture 10: Algebraic Limit Theorem, Part V\n"
"\n"
"Welcome to Lecture 10! We're completing the foundation of sequence theory by tackling three major topics:\n"
"\n"
"## 1. Products of Sequences (The Big Boss!)\n"
"\n"
"We finish the **Algebraic Limit Theorem** by proving that products of convergent sequences converge:\n"
"- If `a n → L` and `b n → M`, then `a n * b n → L * M`\n"
"\n"
"This is the hardest part of the Algebraic Limit Theorem, requiring a clever trick. The geometric intuition comes from thinking about rectangles and the product rule from calculus.\n"
"\n"
"Combined with our earlier work, you'll be able to compute limits of any algebraic expression!\n"
"\n"
"## 2. Order Limit Theorem\n"
"\n"
"Next, we shift from algebra to **inequalities**. Does boundedness pass through limits?\n"
"- If `a n ≤ K` for all `n` and `a n → L`, then `L ≤ K`\n"
"\n"
"This theorem respects the order structure of the real numbers and is fundamental for comparison arguments. We'll prove it by contradiction—a beautiful example of when that technique is the natural choice.\n"
"\n"
"**Warning:** Strict inequalities don't pass through! Even if `a n < K` for all `n`, we only get `L ≤ K`.\n"
"\n"
"## 3. Subsequences\n"
"\n"
"Finally, we introduce **subsequences**—sequences formed by dropping out some terms and sliding everyone to the left.\n"
"\n"
"The key result: **every subsequence of a convergent sequence converges to the same limit**.\n"
"\n"
"The contrapositive gives us a powerful divergence test: if two subsequences converge to different limits, the original sequence diverges!\n"
"\n"
"We'll see this in action with `a n = (-1)^n`, which oscillates but has subsequences converging to 1 (even indices) and -1 (odd indices).\n"
"\n"
"---\n"
"\n"
"**What You'll Learn:**\n"
"\n"
"By the end of this lecture, you'll have:\n"
"- ✅ The complete **Algebraic Limit Theorem** (sums, products, quotients, scalar multiples)\n"
"- ✅ Tools for working with **inequalities and limits**\n"
"- ✅ The **Subsequence Theorem** and how to use it to prove divergence\n"
"- ✅ New proof techniques: geometric thinking for products, contradiction for orders\n"
"\n"
"Let's dive in!"
msgstr ""

#: Game.Levels.L18Pset.L09
msgid "BddSeriesOdd"
msgstr ""

#: Game.Levels.L22Pset.L02
msgid "Continuity Exercise"
msgstr ""

#: Game.Levels.L19Levels.L03
msgid "**Big Boss**: Rearrangement Theorem"
msgstr ""

#: Game.Levels.L18Levels.L02
msgid "If `a → 0`, then the difference of odd and even alternating series, `n ↦ ∑ k ∈ range (2n+1), (-1)^k * a k - ∑ k ∈ range (2n), (-1)^k * a k` goes to `0`."
msgstr ""

#: Game.Levels.L9Levels.L04_FiniteSums
msgid "If a function is nonnegative, then its sum is also."
msgstr ""

#: Game.Levels.L24Levels.L02
msgid "`(S : Set ℝ) : Prop := ∀ x ∈ S, ∃ r > 0, Ball x r ⊆ S`\n"
"\n"
"A set is open if for every point `x` in the set, there exists a radius `r > 0` such that the ball of radius `r` centered at `x` is entirely contained within the set."
msgstr ""

#: Game.Levels.L16Pset.L16Pset3
msgid "# Problem 3: Prove that the sum of two series is the series of the sum."
msgstr ""

#: Game.Levels.L5Levels.L01_DoubleSeqConv
msgid "Now we'll need to show that `0 < ε / 2`. Try: `have eps_half_pos : 0 < ε / 2 := by linarith [hε]`"
msgstr ""

#: Game.Levels.L3Levels.L01_ArchProp
msgid "Archimedean Property"
msgstr ""

#: Game.Levels.L17Pset.L05'
msgid "Monotone Limit Bound"
msgstr ""

#: Game.Levels.L18Pset.L06
msgid "MonotoneSeriesEven"
msgstr ""

#: Game.Levels.L18Pset.L05
msgid "A natural number `n` is either `Even` (that is, `∃ k, n = 2 * k`), or `Odd` (that is, `∃ k, n = 2 * k + 1`)"
msgstr ""

#: Game.Levels.L9Pset.L9Pset1
msgid "If `a : ℕ → ℝ` is a sequence which converges, then it is bounded."
msgstr ""

#: Game.Levels.L9Levels.L05_BddOfConv
msgid "# 🎉 Outstanding Achievement!\n"
"\n"
"You've just proven one of the **cornerstone theorems of real analysis**: convergent sequences with nonzero limits are bounded! This is a result you'll use again and again throughout your journey in analysis.\n"
"\n"
"## What You Accomplished\n"
"\n"
"You proved that convergence implies boundedness:\n"
"```\n"
"SeqLim a L → L ≠ 0 → SeqBdd a\n"
"```\n"
"\n"
"This tells us something profound: **convergent sequences can't escape to infinity**. They must remain trapped in a finite region of the real line.\n"
"\n"
"### Key Techniques You Mastered:\n"
"\n"
"1. **Two-region strategy** - You split the natural numbers into two parts:\n"
"   - Eventually (n ≥ N): where convergence gives you control\n"
"   - Initially (n < N): where you used your TermLtSum theorem\n"
"\n"
"2. **Constructing clever bounds** - You built `M = 2*|L| + ∑ k ∈ range N, |a k|`, which elegantly captures both regions in a single expression\n"
"\n"
"3. **Case analysis** - You used `by_cases` to handle the two regions separately, applying the appropriate bound for each\n"
"\n"
"4. **Connecting theorems** - You saw how `TermLtSum` from Level 1 became an essential tool for handling finitely many terms\n"
"\n"
"## Why This Matters\n"
"\n"
"The boundedness of convergent sequences is fundamental throughout mathematics:\n"
"\n"
"- **Bolzano-Weierstrass Theorem**: Every bounded sequence has a convergent subsequence (you've proven half of this!)\n"
"- **Uniform Convergence**: Bounded sequences are essential for proving uniform convergence results\n"
"- **Compactness**: This result is key to understanding compactness in metric spaces\n"
"- **Practical Analysis**: Knowing a sequence stays bounded helps with error analysis and numerical computations\n"
"\n"
"## The Missing Piece: L = 0\n"
"\n"
"Notice we assumed `L ≠ 0` in this proof. The case where `L = 0` is left as an exercise, but the idea is similar:\n"
"- Use convergence with `ε = 1` to bound terms eventually by `1`\n"
"- Handle the finitely many initial terms with TermLtSum\n"
"- The bound becomes `M = 1 + ∑ k ∈ range N, |a k|`\n"
"\n"
"## Looking Ahead\n"
"\n"
"You now understand that convergent sequences live in a bounded world. This prepares you for deeper results:\n"
"- Sequences that are bounded but don't converge (like `(-1)^n`)\n"
"- The relationship between boundedness, monotonicity, and convergence\n"
"- Cauchy sequences and completeness of the reals\n"
"\n"
"Congratulations on mastering this essential theorem! You're building the foundation for advanced analysis. Keep going! 🚀"
msgstr ""

#: Game.Levels.L7Levels.L00_Uniqueness
msgid "If `x ≠ 0`, then `0 < |x|`."
msgstr ""

#: Game.Levels.L12Levels.L00_SubseqIterate
msgid "# Level 1: Iterated Subsequence\n"
"\n"
"Let's warm up to the topics of this lecture with a foundational exercise.\n"
"\n"
"Suppose you have a sequence of natural numbers, `σ : ℕ → ℕ`, and all you know about it is that it always exceeds the identity:\n"
"\n"
"`hσ : ∀ n, n < σ n`\n"
"\n"
"This doesn't mean that `σ n` is itself strictly increasing (what we call a `Subseq`). The sequence could jump around all over the place, as long as its graph stays above that of $y = x$.\n"
"\n"
"But hopefully it's \"intuitively clear\" from `hσ` that `σ` eventually blows up, gets larger and larger over time, just not monotonically so. That is, there should be *some* way to \"accelerate\" `σ` so that it becomes a `Subseq`. The only problem is: how do you *actually* do this?\n"
"\n"
"## The Key Idea: Orbits\n"
"\n"
"The key idea is that of an **orbit**. In astronomy, you can imagine looking up at the sky night after night and trying to track the location of, say, Jupiter against the \"fixed\" stars (celestial sphere). You start your observations with Jupiter having some \"phase-space\" (position, velocity) $x_0$; let $T$ be the function that runs Newtonian dynamics for one day, so that $T(x_0)$ is the new phase-space of Jupiter tomorrow, moving as it does according to Newton's laws and gravity. Then $T(T(x_0))$ is the phase space after two days, and so on. The whole **orbit** of Jupiter over time is then the sequence:\n"
"$$x_0, T(x_0), T(T(x_0)), T(T(T(x_0))), \\ldots$$\n"
"\n"
"More generally, if you have any function $f : X \\to X$ that takes an abstract space $X$ to itself, and you start with some base point $x_0 : X$, then we write $f^{[n]}(x_0)$ for $f$ iterated $n$ times applied to $x_0$. The sequence $n \\mapsto f^{[n]}(x_0)$ is called the \"orbit of $x_0$ under the action of $f$\".\n"
"\n"
"## Application to Our Problem\n"
"\n"
"How does that help us here? We could start with any base point `n₀ : ℕ`, and we know from `hσ` specialized to `n = n₀` that `n₀ < σ n₀`, but we have no idea how big `σ n₀` is; it could be huge. So how do we ensure that the next term exceeds `σ n₀`?\n"
"\n"
"(Want to think about it for a minute before reading on?)\n"
"\n"
"Given our previous discussion, hopefully you see right away that: if we were to specialize `hσ` to `n = σ n₀`, we would get: `σ n₀ < σ (σ n₀)`. So now it's clear: the way to get larger and larger terms from the sequence `σ` is to take the orbit!\n"
"\n"
"**Your goal in this level:** Prove that for any fixed `n₀`, the orbit `n ↦ σ^[n] n₀` is a `Subseq`.\n"
"\n"
"## New Tools\n"
"\n"
"### Function Iteration: `succ_iterate`\n"
"\n"
"While `σ^[k] (σ n) = σ^[k+1] (n)` is true by definition, it takes an argument by induction to show that if instead of adding a `σ` on the right, we add it on the left:\n"
"\n"
"`σ (σ^[k] n) = σ^[k+1] n`\n"
"\n"
"We'll spare you that proof and give you the theorem `succ_iterate`.\n"
"\n"
"### Subsequence from Successor: `subseq_of_succ`\n"
"\n"
"To prove that `σ` is a `Subseq`, the definition speaks of all `i < j`, but it's enough to do it one step at a time. The theorem `subseq_of_succ` says that it's enough to show that `σ n < σ (n+1)` holds for all `n` to conclude `Subseq σ`. You can `apply` this fact to reduce showing `Subseq σ` to just showing that `σ` increases from `n` to `n+1`.\n"
"\n"
"### Tactic: `show`\n"
"\n"
"Syntax: `show fact by proof`. For example, if you want to rewrite by the fact that `σ (σ^[n] n₀) = σ^[n+1] n₀` without a separate `have` declaration, you can write:\n"
"\n"
"`rewrite [show σ (σ^[n] n₀) = σ^[n+1] n₀ by apply succ_iterate]`"
msgstr ""

#: Game.Levels.L13Levels.L03_MonotoneSubseq
msgid "`(a : ℕ → X) := ∀ k, ∃ n > k, IsAPeak a n`\n"
"\n"
"We say that a sequence `a : ℕ → X` (where `X` is `ℚ` or `ℝ`)\n"
"satisfies `UnBddPeaks a`, if its set of peaks is unbounded."
msgstr ""

#: Game.Levels.L10Levels.L09_Subseq
msgid "Excellent! You've shown that the oscillating sequence `(-1)^n` has a convergent subsequence.\n"
"\n"
"**What We Constructed:**\n"
"\n"
"The subsequence `σ(n) = 2*n` extracts the even-indexed terms:\n"
"- Original sequence: `-1, 1, -1, 1, -1, 1, ...`\n"
"- Even subsequence: `1, 1, 1, 1, ...` → converges to 1\n"
"\n"
"**The Other Subsequence:**\n"
"\n"
"Similarly, the odd-indexed subsequence `τ(n) = 2*n + 1` gives:\n"
"- Odd subsequence: `-1, -1, -1, -1, ...` → converges to -1\n"
"\n"
"**Why This Proves Divergence:**\n"
"\n"
"We now have **two subsequences converging to different limits** (1 and -1). By the Subsequence Theorem, if the full sequence `(-1)^n` converged to some limit `L`, then *every* subsequence would have to converge to that same `L`.\n"
"\n"
"But we have subsequences converging to 1 and -1, which are different! This is a contradiction, so `(-1)^n` does not converge.\n"
"\n"
"This is a powerful technique: **to prove divergence, exhibit two subsequences with different limits.**\n"
"\n"
"**The `let` Tactic in Action:**\n"
"\n"
"Notice how `let` allowed us to define `σ` cleanly within the proof. The `fun n ↦ 2*n` syntax creates an anonymous function, and `let` gives it a name we can use.\n"
"\n"
"This is much cleaner than trying to construct the function implicitly!\n"
"\n"
"**Subsequences Extract Hidden Structure:**\n"
"\n"
"Even though `(-1)^n` oscillates wildly and has no limit, by looking at subsequences we can isolate the \"constant behavior\" hidden within:\n"
"- The even terms are constantly 1\n"
"- The odd terms are constantly -1\n"
"\n"
"Subsequences let us zoom in on specific patterns and behaviors that might be obscured in the full sequence.\n"
"\n"
"**Coming Up:**\n"
"\n"
"- Other oscillating sequences with convergent subsequences\n"
"- The **Bolzano-Weierstrass Theorem**: every *bounded* sequence has a convergent subsequence (this is much deeper!)\n"
"- Using subsequences to understand **limsup** and **liminf**\n"
"\n"
"Great work on completing Lecture 10! You now have the complete Algebraic Limit Theorem, order properties of limits, and the power of subsequences at your disposal."
msgstr ""

#: Game.Levels.L22Levels.L02
msgid "# Level 2: Uniform Convergence\n"
"\n"
"Welcome to one of the most profound and beautiful theorems in real analysis! After seeing how nicely continuous functions compose, you might think that continuous functions always \"play well\" together. But as we hinted in our introduction dialogue, this isn't always the case when infinite processes are involved.\n"
"\n"
"## The Crisis We're Solving\n"
"\n"
"Remember Cauchy's mistake? In the early 1800s, even the great Augustin-Louis Cauchy \"proved\" that the pointwise limit of continuous functions must be continuous. His proof looked rock-solid—until counterexamples like $f_n(x) = x^n$ on $[0,1]$ shattered the illusion.\n"
"\n"
"The problem isn't with Cauchy's logic—it's with pointwise convergence itself. When we say $f_n \\to F$ pointwise, we're saying:\n"
"\n"
"**Pointwise**: \"For each point $x$, eventually the functions $f_n(x)$ get close to $F(x)$\"\n"
"\n"
"But \"eventually\" might mean very different things at different points! At some points, $f_n$ might converge to $F$ after just 10 steps. At nearby points, it might take 1000 steps. This non-uniformity destroys continuity.\n"
"\n"
"## The Beautiful Solution: Uniform Convergence\n"
"\n"
"**Uniform convergence** fixes this by demanding the same rate of convergence everywhere:\n"
"\n"
"**Uniform**: \"There's a single moment in time after which all the functions $f_n$ are close to $F$ at all points simultaneously\"\n"
"\n"
"## The New Definition: `UnifConv`\n"
"\n"
"`UnifConv (f : ℕ → ℝ → ℝ) (F : ℝ → ℝ) : Prop :=\n"
"  ∀ ε > 0, ∃ N, ∀ n ≥ N, ∀ x, |f n x - F x| < ε`\n"
"\n"
"**Read this carefully**: For every tolerance $\\varepsilon > 0$, there exists a \"convergence moment\" $N$ such that for all later functions $f_n$ (with $n \\geq N$) and for all points $x$ simultaneously, we have $|f_n(x) - F(x)| < \\varepsilon$.\n"
"\n"
"## The Quantifier Order Revolution\n"
"\n"
"The difference between pointwise and uniform convergence is entirely about **quantifier order**:\n"
"\n"
"- **Pointwise**: $\\forall \\varepsilon > 0, \\forall x, \\exists N, \\forall n \\geq N, |f_n(x) - F(x)| < \\varepsilon$\n"
"- **Uniform**: $\\forall \\varepsilon > 0, \\exists N, \\forall n \\geq N, \\forall x, |f_n(x) - F(x)| < \\varepsilon$\n"
"\n"
"In pointwise convergence, $N$ can depend on both $x$ and $\\varepsilon$. In uniform convergence, $N$ depends only on $\\varepsilon$—the same $N$ must work for *every* point $x$.\n"
"\n"
"## Why This Saves Continuity\n"
"\n"
"Think back to our failed attempt to prove continuity with pointwise convergence. The breakdown was:\n"
"\n"
"1. We picked $f_N$ to approximate $F(x)$ well at our point $x$\n"
"2. We used $f_N$'s continuity to control behavior near $x$\n"
"3. **DISASTER**: We needed $f_N$ to approximate $F(y)$ well at nearby points $y$, but our choice of $N$ was only guaranteed to work at $x$!\n"
"\n"
"With uniform convergence:\n"
"1. We pick $f_N$ to approximate $F$ well **everywhere simultaneously**\n"
"2. We use $f_N$'s continuity to control behavior near $x$\n"
"3. **SUCCESS**: Since $f_N$ approximates $F$ uniformly, it automatically works at all nearby points $y$!\n"
"\n"
"## The Theorem You'll Prove\n"
"\n"
"**Theorem**: If each $f_n$ is continuous and $f_n$ converges uniformly to $F$, then $F$ is continuous.\n"
"\n"
"This is the theorem that rehabilitated Cauchy's intuition. Continuous functions do preserve continuity under limits—you just need the right kind of limit!\n"
"\n"
"## Your Proof Strategy: The $\\varepsilon/3$ Trick\n"
"\n"
"To show $F$ is continuous at a point $x$, given $\\varepsilon > 0$, you'll want to show $|F(y) - F(x)| < \\varepsilon$ when $y$ is close to $x$.\n"
"\n"
"Use the triangle inequality:\n"
"$$|F(y) - F(x)| \\leq |F(y) - f_N(y)| + |f_N(y) - f_N(x)| + |f_N(x) - F(x)|$$\n"
"\n"
"Make each term less than $\\varepsilon/3$:\n"
"- **First term**: Uniform convergence gives you this everywhere\n"
"- **Second term**: Continuity of $f_N$ gives you this near $x$\n"
"- **Third term**: Uniform convergence gives you this everywhere\n"
"\n"
"The magic is that uniform convergence gives you control over the first and third terms **simultaneously** for all points.\n"
"\n"
"## A Historical Note\n"
"\n"
"This distinction between pointwise and uniform convergence was one of the great clarifications of 19th-century analysis. It helped mathematicians understand exactly when their intuitions about limits and continuity could be trusted.\n"
"\n"
"## Your Challenge\n"
"\n"
"Prove that the uniform limit of continuous functions is continuous:\n"
"\n"
"**Lean signature**: `(∀ n, FunCont (f n)) → UnifConv f F → FunCont F`\n"
"\n"
"Ready to fix Cauchy's \"mistake\" and see how the right kind of convergence preserves continuity? The $\\varepsilon/3$ method awaits!"
msgstr ""

#: Game.Levels.L23Levels.L03
msgid "Compactness"
msgstr ""

#: Game.Levels.L17Pset.L05
msgid "If `a : ℕ → ℝ` is nonnegative, then `Series a` is `Monotone`."
msgstr ""

#: Game.Levels.L24Lecture
msgid "# Lecture 24: Topology\n"
"\n"
"**SIMPLICIO:** So wait, is \"compact\" just about being bounded?\n"
"\n"
"**SOCRATES:** Good question! Tell me about the function `f(x) = 1/x` on the interval `(0,1)`. It's certainly continuous (as long as we don't include `0`). The interval `(0,1)` is bounded. If that interval were compact, then `f` would be uniformly continuous on `(0,1)`. Is `f` uniformly continuous on `(0,1)`?\n"
"\n"
"**SIMPLICIO:** Ooh, doesn't look it; the slope gets really steep as `x` approaches `0`. That means that if I want to keep the fluctuation of `f`, that is, `|f y - f x|`, small, I need to make `|y - x|` ever smaller and smaller, for `x` getting closer to `0`. So I can't pick a single `δ` that works for all `x` in `(0,1)`.\n"
"\n"
"**SOCRATES:** Good. Can you see another way to see that `(0,1)` is not compact, directly from the definition?\n"
"\n"
"**SIMPLICIO:** Umm... I guess I could try to cover `(0,1)` with balls. Like, I could cover it with the balls `(1/2, 1) ⋃ (1/3, 1) ⋃ (1/4, 1) ⋃ ...`. The ... Archimedean property (again!!) says that these balls cover all of `(0,1)`. But if only finitely many of them are used, say up to `(1/N, 1)`, then the point `1/(N+1)` is not covered. So there's no finite subcover.\n"
"\n"
"**SOCRATES:** Excellent! So `(0,1)` is not compact; that is, being bounded is not enough for compactness. But it's easy to see that bounded *is* necessary. Can you see why?\n"
"\n"
"**SIMPLICIO:** Oh, I see it! Let `S` be our compact set. We can conver `S` by the balls `(-n, n)` for all natural numbers `n`. Since `S` is compact, there must be a finite subcover. That means that there is some largest `N` such that `(-N, N)` covers all of `S`. Therefore, `S` is bounded.\n"
"\n"
"**SOCRATES:** Perfect. So boundedness is necessary but, as we just saw with the example of `(0,1)`, not sufficient for compactness. There's one more ingredient we need.\n"
"\n"
"**SIMPLICIO:** What is it?\n"
"\n"
"**SOCRATES:** The set also needs to be *closed*. Here's some more topology-speak for you: A set is *closed* if its complement is *open*.\n"
"\n"
"**SIMPLICIO:** Greaaaat, more definitions.\n"
"\n"
"**SOCRATES:** Last one, for now. A set `S` is *open* if: for every point in `S`, there is a ball around that point which is entirely contained in `S`. That is: `S` is open if:\n"
"\n"
"`∀ x ∈ S, ∃ δ > 0, Ball x δ ⊆ S`\n"
"\n"
"Let's check your understanding: is a ball itself open?\n"
"\n"
"**SIMPLICIO:** Hmm let's see. I have a point `y ∈ Ball x r`. I have to find a `δ > 0` such that `Ball y δ ⊆ Ball x r`. The condition that `y` is in the ball means that `|x - y| < r`, which looks something like this:\n"
"\n"
"---|(x-r)----(y)---(x)-------(x+r)|----\n"
"\n"
"So if we let `δ := min (y - (x - r)) (x + r - y)`, then `Ball y δ` will fit inside `Ball x r`. So yes, a ball is open!\n"
"\n"
"**SOCRATES:** Excellent! So now you have all the ingredients to understand compactness in `ℝ`: A famous result called the *Heine-Borel Theorem* says that a set `S ⊆ ℝ` is compact if and only if:\n"
"\n"
"it is closed and bounded.\n"
"\n"
"Heine proved this in 1872, and Borel generalized it to higher dimensions in 1895. This is a very important theorem in real analysis, because it allows us to easily check whether a set is compact or not. For example, the complement of `[a, b]` is the union of `(-∞, a)` and `(b, ∞)`, both of which are open, so `[a, b]` is closed. And of course `[a, b]` is bounded. Therefore, by Heine-Borel, `[a, b]` is compact. This gives us the important result we wanted:\n"
"\n"
"**Theorem:** For any function that is continuous on a closed and bounded interval `[a, b]`, the sequence of Riemann sums converges to a limit, which we call the integral of the function on `[a, b]`.\n"
"\n"
"(Note again that `f` must be continuous on the *entire* closed interval `[a, b]`. The function `f(x) = 1/x` is continuous on `(0,1]`, all but one point; but the Riemann sums do not converge, because `∫₀¹ 1/x dx = ∞`!)\n"
"\n"
"The proof is very simple: `[a, b]` is closed and bounded, and hence compact by Heine-Borel. Any function that is continuous on a compact set is uniformly continuous there. And if a function is uniformly continuous on an interval, then the Riemann sums converge to a limit. Just chain everything we've learned together!\n"
"\n"
"**SIMPLICIO:** Wow, that's really elegant. How is Heine-Borel proved? I guess we already proved half of one direction, if a set is compact then it's bounded. How do we prove that it's also closed?\n"
"\n"
"**SOCRATES:** You tell me!\n"
"\n"
"**SIMPLICIO:** Ok, let's try. Suppose `S` is compact. We want to show that its complement `Sᶜ` is open. So take any point `x ∈ Sᶜ`. We need to show that there's a whole ball around `x` that stays away from `S`. And the only way to make use of compactness is to cover `S` with balls. Oh, I think I see it!\n"
"\n"
"For every point `y ∈ S`, look at the ball centered at `y` of radius `|y - x| / 2`, say. That's a ball that contains `y` but stays away from `x`. The collection of all such balls covers `S`, and hence only finitely many such balls cover `S`. So we have `V : Finset I` and for each `i ∈ V`, we have a point `yᵢ ∈ S` and a ball `Ball yᵢ (|yᵢ - x| / 2)`, and these finitely many balls cover `S`. Now let `δ > 0` be the minimum of all the `|yᵢ - x| / 2` for `i ∈ V`. Then the ball `Ball x δ` stays away from all the balls covering `S`, and hence from `S` itself. Therefore, `Sᶜ` is open, and so `S` is closed.\n"
"\n"
"**SOCRATES:** Well done! You hardly need me anymore! :) Channel your inner me; what's the next thing I'd say?\n"
"\n"
"**SIMPLICIO:** You'd tell me to try to prove the other direction. Ok, let's say that `S` is closed and bounded. We want to show that it's compact. So take any cover of `S` by balls. We need to find a finite subcover. I ... don't see what to do.\n"
"\n"
"**SOCRATES:** Ok, this direction is a bit harder. Let's build up to it with a few more definitions. (I know, I know.) Given a set `S` and a real number `M`, we say that `M` is an *upper bound* for `S` if for all `s ∈ S`, `s ≤ M`. Easy, right? We say that `L` is a *least upper bound* (or *supremum*) for `S` if `L` is an upper bound for `S`, and for any other upper bound `M`, we have `L ≤ M`. In other words, `L` is the smallest of all upper bounds.\n"
"\n"
"**SIMPLICIO:** Ok, so far so good... So what?\n"
"\n"
"**SOCRATES:** Now, here's an important property of the real numbers: *every nonempty set of real numbers that is bounded above has a least upper bound*. This is called the *Least Upper Bound Property*. Let's talk about how you might go about proving it.\n"
"\n"
"**SIMPLICIO:** Hmm... Let me think. Ok, I start with at least one point `s₀ ∈ S`, since `S` is nonempty, and at least one upper bound `M₀`. I think I see what to do! Let's think about the middle point between `s₀` and `M₀`, that is, `(s₀ + M₀) / 2`. Is that an upper bound for `S`? If not, then there exists some point `s₁ ∈ S` such that `s₁ > (s₀ + M₀) / 2`. Otherwise, if it *is* an upper bound, then we can set `M₁ := (s₀ + M₀) / 2`. In either case, we have a smaller interval `[s₁, M₀]` or `[s₀, M₁]`. We can keep repeating this process, halving (or more) the interval each time. This gives us a sequence of nested intervals whose lengths go to zero. The bottoms are all points in `S` and increasing and bounded, hence have a limit `L`. The tops are all upper bounds and decreasing and bounded, hence have a limit `U`. Since the lengths of the intervals go to zero, `L = U`. Now, I need to show that `L` is *the* least upper bound for `S`. I think I can do that by showing that `L` is an upper bound, and that any smaller number is not an upper bound. Ok, I'm satisfied.\n"
"\n"
"**SOCRATES:** Excellent! Now, armed with the Least Upper Bound Property, you can finally prove that any closed and bounded set is compact. First let's prove that a closed interval `[a, b]` is compact. Take any cover of `[a, b]` by balls. We want to find a finite subcover. Consider the set `T` of all points `t ∈ [a, b]` such that the interval `[a, t]` can be covered by finitely many of the balls. Clearly, `a ∈ T`, so `T` is nonempty. Also, every point in `T` is at most `b`, so `T` is bounded above by `b`. By the Least Upper Bound Property, `T` has a least upper bound `L`. We want to show that `L = b`. If not, then since the balls cover `[a, b]`, there is some ball covering `L`. Since the ball has positive radius, it covers some interval around `L`, say `[L - δ, L + δ]`. Since `L` is the least upper bound of `S`, there must be some point `t ∈ S` with `t > L - δ`. But then we can cover `[a, t]` with finitely many balls (since `t ∈ S`), and also cover `[t, L + δ]` with the ball around `L`. This gives us a finite cover for `[a, L + δ]`, contradicting the fact that `L` is an upper bound for `S`. Therefore, `L = b`, and hence `[a, b]` can be covered by finitely many balls.\n"
"\n"
"**SIMPLICIO:** Ok, I'm with you. But what do we do for *any* closed and bounded set?\n"
"\n"
"**SOCRATES:** Ah, and here's the last step. Any closed subset of a compact set is itself compact! Can you see why?\n"
"\n"
"**SIMPLICIO:** Hmm, let's see. Let `S` be a closed subset of a compact set `T`. Take any cover of `S` by balls. We want to find a finite subcover. Since `S` is closed, its complement `Sᶜ` is open. Therefore, for every point `x ∈ Sᶜ`, there is a ball around `x` that stays within `Sᶜ`, that is, away from `S`. The collection of all such balls, together with the balls covering `S`, forms an open cover of the entire set `T`. Since `T` is compact, there is a finite subcover of `T`. This finite subcover must include finitely many balls covering `S`, since the balls covering `Sᶜ` do not cover any points in `S`. Therefore, we have found a finite subcover for `S`. Hence, `S` is compact. Nice! Since a bounded set is a subset of some closed interval `[a, b]`, and we've just shown that `[a, b]` is compact, it follows that any closed and bounded set is compact.\n"
"\n"
"**SOCRATES:** Well done, Simplicio! You've just proved the Heine-Borel Theorem. And to bring it all the way back to calculus, this means that any continuous function on a closed and bounded interval `[a, b]` is uniformly continuous there, and hence Riemann integrable. Now let's do all this \"for real\"..."
msgstr ""

#: Game.Levels.L13Lecture
msgid "Lecture 13: Monotone Subsequence"
msgstr ""

#: Game.Levels.L3Levels.L02_OneOverN
msgid "Again, you presumably you know\n"
"now to do `intro n hn`. But let's also give `hn` the more descriptive name `n_ge_N`. So that I can keep giving you hints, try `intro n n_ge_N`."
msgstr ""

#: Game.Levels.L10Pset.L10Pset4
msgid "# Problem 3:\n"
"\n"
"We proved `OrderLimLe`; now prove `OrderLimGt`. Notice that the assumption is a **strict** inequality, but the conclusion is not. Why not? (See next Exercise...)"
msgstr ""

#: Game.Levels.L1RealAnalysisStory.L00_the_problem
msgid "# Theorem Prover Software\n"
"\n"
"In this course, we will be using a \"proof assistant\" called Lean. This is software that checks that our proofs prove *exactly* what we\n"
"claim they prove. It has other really cool pedagogical features that we'll get to later.\n"
"It will take a little while to get used to the syntax, so until we're comfortable, we'll intersperse exercises teaching Lean with exercises teaching Real Analysis. Pretty soon all the exercises will just be about Real Analysis.\n"
"\n"
"\n"
"For this first exercise, we have a hypothesis that we called `h` (but we could've called it anything, like `x_eq_5`, or `Alice`) that says a real number `x` equals 5. Our goal is to prove that `x` equals 5.\n"
"This shouldn't be very hard, but if you don't know\n"
"the command, you'll be out of luck. Our goal is to\n"
"prove the same statement as one of the hypotheses.\n"
"To solve that goal, the syntax is to write `apply`, then a space, and then the name of the hypothesis which matches the goal."
msgstr ""

#: Game.Levels.L3Levels.L02_OneOverN
msgid "Prove that the sequence `a(n) = 1 / n` converges to 0.\n"
"This is our first substantive limit proof, requiring the Archimedean Property."
msgstr ""

#: Game.Levels.L7PsetIntro
msgid "Pset 7"
msgstr ""

#: Game.Levels.L10Levels.L06_Prod
msgid "Congratulations! You've completed the hardest part of the Algebraic Limit Theorem.\n"
"\n"
"Postscript:\n"
"**Why would you think to add and subtract `b n * L`?**\n"
"\n"
"Think about the product rule in calculus: `(fg)' = f'g + fg'`. Multiplication always corresponds to a rectangle. When you have two quantities `f` and `g` both changing, the change in their product `fg` can be visualized as the change in area:\n"
"\n"
"```\n"
"      f        Δf\n"
"   +-----+-------+\n"
"   |     |       |\n"
" g |     |       |\n"
"   +-----+-------+\n"
" Δg|     |  tiny |\n"
"   +-----+-------+\n"
"```\n"
"\n"
"The total change is `(f + Δf)(g + Δg) - fg = f·Δg + g·Δf + Δf·Δg`.\n"
"\n"
"In our proof, we replaced `M` with `b n` (adding and subtracting `b n * L`) to get the same decomposition. The `Δf·Δg` term (the tiny corner) gets absorbed into `(a n - L) * b n`, and since both factors are small, it doesn't cause problems.\n"
"\n"
"This geometric picture explains the algebraic trick: we're decomposing the area difference into two manageable strips that we can control independently.\n"
"\n"
"# Algebraic Limit Theorem - Complete!\n"
"\n"
"You can now:\n"
"- **Add** sequences: if `a n → L` and `b n → M`, then `a n + b n → L + M`\n"
"- **Multiply by constants**: if `a n → L`, then `c * a n → c * L`\n"
"- **Multiply** sequences: if `a n → L` and `b n → M`, then `a n * b n → L * M`\n"
"- **Invert** (when limit is nonzero): if `a n → L ≠ 0`, then `1 / a n → 1 / L`\n"
"\n"
"This is incredibly powerful! For any algebraic combination of convergent sequences, you can compute the limit by just plugging in the individual limits.\n"
"\n"
"**Example:** If `a n → L` and `b n → M`, what is\n"
"```\n"
"lim ((a n)² + 2*a n + b n) / (3*b n + 2 - (a n)²)\n"
"```\n"
"\n"
"**Answer:** `(L² + 2*L + M) / (3*M + 2 - L²)` (provided the denominator ≠ 0).\n"
"\n"
"You can build this up step by step using the algebraic limit rules!\n"
"\n"
"**Note:** The case where `L = 0` or `M = 0` is left as an exercise. The proof requires slightly different techniques since you can't divide by `|L|` or ensure `b` is bounded away from zero. Try it yourself!"
msgstr ""

#: Game.Levels.L1Pset.L1Pset3
#: Game.Levels.L1Pset.L1Pset4
#: Game.Levels.L1Pset.L1Pset5
msgid "Solve the problem"
msgstr ""

#: Game.Levels.L1PsetIntro
msgid "# Problem Set 1\n"
"\n"
"Just because it's a problem set doesn't mean\n"
"you can't learn new things..."
msgstr ""

#: Game.Levels.L8Levels.L03_Induction'
msgid "If a natural number `n ≠ 0`, then `1 ≤ n`."
msgstr ""

#: Game.Levels.L6Levels.L05_AbsLt
msgid "# 📐 Absolute Value Mastery Achieved! 📐\n"
"\n"
"Outstanding! You've just completed a proof that demonstrates the power of combining logical reasoning with analytical techniques. This type of argument—extracting bounds from convergence conditions—is absolutely fundamental in real analysis.\n"
"\n"
"**Why This Matters:**\n"
"What you just proved is that any convergent sequence is eventually bounded below (relative to its limit). This might seem like a small technical detail, but it's actually a building block for many major theorems. For instance, this type of reasoning is crucial in proving that convergent sequences are bounded, and that continuous functions on compact sets achieve their minima.\n"
"\n"
"**The Strategic Breakdown:**\n"
"Notice the elegant flow of your proof: you started with the abstract convergence condition, chose a specific `ε` (namely `1`), extracted the absolute value condition, unpacked it using `abs_lt` to get both bounds, and then focused on just the bound you needed. This is mathematical reasoning at its finest—systematic, precise, and efficient.\n"
"\n"
"**Technical Insight:**\n"
"The `abs_lt` theorem is your gateway between the world of absolute values (which are natural for expressing \"closeness\") and the world of ordinary inequalities (which are easier to manipulate algebraically). Learning to move fluently between these representations is a key skill in analysis.\n"
"\n"
"**Looking Forward:**\n"
"As we progress to more advanced topics, you'll find yourself using this pattern repeatedly: taking convergence hypotheses, specializing them to specific epsilons, and then extracting the directional information you need. The techniques you've mastered here will be essential for proving results about monotonic sequences, bounded sequences, and much more.\n"
"\n"
"You're not just learning tactics—you're developing the analytical intuition that separates novice proof-writers from experienced mathematicians. Keep building on these foundations!"
msgstr ""

#: Game.Levels.L10Pset.L10Pset4
msgid "If a sequence `a` converges to `L` and `K < a n` for all `n`, then `K ≤ L`."
msgstr ""

#: Game.Levels.L22Levels.L02
msgid "If a sequence of functions `fₙ` converges uniformly to `F`, and each `fₙ` is continuous, then `F` is continuous."
msgstr ""

#: Game.Levels.L21Levels.L08
msgid "# Level 4: Continuous Functions\n"
"\n"
"Just as we moved from derivatives at a point to derivative functions, we can move from continuity at a point to continuity everywhere!\n"
"\n"
"## From Point Continuity to Global Continuity\n"
"\n"
"So far, `FunContAt f c` tells us that `f` is continuous at the specific point `c`.\n"
"\n"
"But many functions (like polynomials) are continuous at *every* point.\n"
"\n"
"## The New Definition\n"
"\n"
"**Definition (`FunCont`):** We say that `f` is **continuous** (everywhere) if:\n"
"\n"
"`∀ x, FunContAt f x`\n"
"\n"
"This is written `FunCont f`.\n"
"\n"
"In other words: `f` is continuous at every point in its domain.\n"
"\n"
"## Why Polynomials Are Continuous\n"
"\n"
"Intuitively, polynomials like `f(x) = x² - 1` are continuous because:\n"
"- You can draw them without lifting your pen\n"
"- Small changes in `x` produce small changes in `f(x)`\n"
"- There are no jumps, breaks, or asymptotes\n"
"\n"
"We've worked with continuity of `x² - 1` before. Now we'll prove it's continuous **everywhere**!\n"
"\n"
"## The Strategy\n"
"\n"
"For any point `x`, we need to show `FunContAt (fun t ↦ t^2 - 1) x`.\n"
"\n"
"This means: given `ε > 0`, find `δ > 0` such that `|t - x| < δ` implies `|f(t) - f(x)| < ε`.\n"
"\n"
"The algebra follows a familiar pattern:\n"
"\n"
"`f(t) - f(x) = (t² - 1) - (x² - 1) = t² - x² = (t - x)(t + x)`\n"
"\n"
"So `|f(t) - f(x)| = |t - x| · |t + x|`.\n"
"\n"
"If we restrict `|t - x| < 1`, then `|t + x| < |2x| + 1`.\n"
"\n"
"Taking `δ = min(1, ε / (|2x| + 1))` will work!\n"
"\n"
"## Your Challenge\n"
"\n"
"Prove that `f(x) = x² - 1` is continuous everywhere:\n"
"\n"
"`FunCont (fun x ↦ x^2 - 1)`\n"
"\n"
"**Hint:** After introducing `x`, you need to bound `|t + x|` in terms of `x` (not a constant like `5`).\n"
"\n"
"Use `min 1 (ε / (|2 * x| + 1))` as your `δ`. The key is showing that when `|t - x| < 1`, we have `|t + x| < |2 * x| + 1`."
msgstr ""

#: Game.Levels.L4Levels.L01_NonConverge
msgid "Prove that the sequence `1`, `-1`, `1`, `-1`,... diverges."
msgstr ""

#: Game.Levels.L2NewtonsCalculationOfPi.L01_SeqConvDef
msgid "While you may see `0 < ε` in the goal and `ε > 0` in the hypothesis `hε`, Lean will still know that these two things are exactly the same..."
msgstr ""

#: Game.Levels.L9Levels.L04_FiniteSums
msgid "# 🎉 Excellent Work!\n"
"\n"
"You've just proven a fundamental result about finite sums! This theorem might seem simple, but it's a powerful building block that appears throughout analysis.\n"
"\n"
"## What You Accomplished\n"
"\n"
"You successfully proved that **every term is bounded by the total sum**:\n"
"```\n"
"∀ n < N, |a n| ≤ ∑ k ∈ range N, |a k|\n"
"```\n"
"\n"
"### Key Techniques You Mastered:\n"
"\n"
"1. **Strategic induction** - You learned to use induction on `N` *before* introducing the universal quantifier, which made the proof structure much cleaner\n"
"\n"
"2. **Working with finite sums** - You used `sum_range_succ` to peel off terms and `sum_nonneg` to establish nonnegativity\n"
"\n"
"3. **Case analysis** - You split the proof into two cases (`n < N` vs `n = N`) and handled each appropriately\n"
"\n"
"4. **Combining results** - You cleverly used the inductive hypothesis for earlier terms and nonnegativity for the final term\n"
"\n"
"## Why This Matters\n"
"\n"
"This result is essential for the next level! You'll use `TermLeSum` to prove that **convergent sequences are bounded**. Here's the connection:\n"
"\n"
"- Every convergent sequence is eventually close to its limit\n"
"- But what about the finitely many terms *before* it gets close?\n"
"- That's where your theorem comes in! You can bound those initial terms by their finite sum\n"
"- Combine this with the eventual bound, and you get a global bound for the entire sequence\n"
"\n"
"## Looking Ahead\n"
"\n"
"In the next level, you'll prove `Bdd_of_ConvNonzero`: convergent sequences with nonzero limits are bounded. This is a cornerstone result in analysis that tells us convergent sequences can't escape to infinity.\n"
"\n"
"Ready to see your theorem in action? Let's move on!"
msgstr ""

#: Game.Levels.L19Levels.L01
msgid "More Flexible Cauchy"
msgstr ""

#: Game.Levels.L19Levels.L04
msgid "Prove the `Conditional Convergence Theorem`"
msgstr ""

#: Game.Levels.L10Levels.L09_Subseq
msgid "The `let` tactic is like `have`, but for creating variable names or functions."
msgstr ""

#: Game.Levels.L10Levels.L07_Order
msgid "If a sequence `a` converges to `L` and `a n ≤ K` for all `n`, then `L ≤ K`."
msgstr ""

#: Game.Levels.L1RealAnalysisStory.L06_intro
msgid "# Universal statements\n"
"\n"
"In mathematics, we often need to prove statements that are true \"for all\" values of some variable. For example, we might want to prove: \"for all $\\varepsilon > 0$, we have $(\\varepsilon + 1)^2 = (\\varepsilon + 1)^2$.\"\n"
"(Of course the condition that `ε` be positive is mathematically superfluous, and is only here for pedagogical purposes.)\n"
"\n"
"If you're thinking that `rfl` will do the trick, that's a good idea, but it won't work, because the goal isn't (yet) an equality. So we need to do something else first.\n"
"\n"
"In Lean, as in mathematics, \"for all\" is written using `∀`; this is called the *universal quantifier*, and is gotten by typing \\forall, that is, backslash, then `forall`, then a space. In Lean, this goal looks like so:\n"
"\n"
"`∀ ε > 0, (ε + 1)^2 = (ε + 1)^2`.\n"
"\n"
"(Note that to write an epsilon in Lean, you just type \\\\e, that is, backslash, then `e`, then space.)\n"
"\n"
"To prove a \"for all\" statement, you need to show that it's true for an arbitrary element. In English, you would say: give me an arbitrary `ε`, and give me the fact that it's positive (we can give that fact a name, like `hε`, since it's a hypothesis about `ε`, or perhaps an even more descriptive name like `ε_pos`, since the hypothesis is the positivity of `ε`). Note that `ε` here is a dummy variable, and we could choose to name it something else on the fly. In English, we might say: give me some `ε`, but I want to call it `Alice`; then give me the fact that `Alice` is positive, and my goal will be to prove that `(Alice + 1)^2 = (Alice + 1)^2`. If we were more polite, we might replace \"give me\" above with \"introduce\", like:\n"
"introduce an `ε`, and introduce the fact, call it `hε`, that `ε` is positive.\n"
"\n"
"In Lean, the syntax for this is the command `intro`, followed by whatever name you want to give a dummy variable or a hypothesis.\n"
"\n"
"So: when you see a goal that starts with `∀`, you can write `intro` to \"introduce\" the variable. For example:\n"
"- `intro ε` introduces the variable ε. But look at the goal state now! It changes to: `ε > 0 → (ε + 1)^2 = (ε + 1)^2`. So we're not done introducing things.\n"
"- Then `intro hε` introduces the hypothesis that `ε > 0` (and again, you can call the hypothesis whatever you want; try `intro ε_pos` instead).\n"
"\n"
"After using `intro` twice, the goal will become one that you\n"
"should know how to solve.\n"
"\n"
"If you want to be really slick, you can combine the two `intro` commands into\n"
"one: `intro ε hε`. But don't feel obliged."
msgstr ""

#: Game.Levels.L18Pset.L03
msgid "AntitoneLimitBound"
msgstr ""

#: Game.Levels.L3Levels.L01_ArchProp
msgid "# Level 1: The Archimedean Property\n"
"\n"
"The so-called Archimedean Property (which I think is originally due to Eudoxus, and appears already in Euclid's Elements Book V) is a fundamental property of the real numbers that captures the intuitive notion that there are no \"infinitely large\" or \"infinitesimally small\" positive real numbers.\n"
"\n"
"More precisely, it states that no matter how small `ε > 0` is, there is always a natural number `N` so that `1 / N` is even smaller than `ε` (and of course positive). Equivalently, we can state it as: for any positive real number `ε`, there exists a natural number `N` such that `1 / ε < N`.\n"
"\n"
"*Why does this matter?* The Archimedean Property is one of the most fundamental properties distinguishing the real numbers from other number systems. Without it, we could have \"infinitely large\" or \"infinitesimally small\" positive numbers, which would break most of calculus and analysis.\n"
"\n"
"Our goal will be to prove the following:\n"
"\n"
"**Theorem (ArchProp)**: For any `ε : ℝ` with `0 < ε`, there exists `N : ℕ` such that `1 / ε < N`.\n"
"\n"
"This is mathematically \"obvious\" to most people—if you have a positive number ε, no matter how small, you can always find a natural number large enough that 1 / ε is smaller than it. (At least it seems obvious, and perhaps becomes less so once you remember that we don't yet know what the real numbers actually *are*... We'll continue postponing the construction for some time.) But how do you actually formalize this in Lean?\n"
"\n"
"## The Natural Language Proof Strategy\n"
"\n"
"First, let's think about this in natural language. The key insight is that we need to provide a specific natural number `N` that works.\n"
"\n"
"A natural choice would be to use something related to the ceiling function. The ceiling function `x ↦ ⌈x⌉` rounds any real number up to the nearest integer. However, there's a subtle issue here: the standard ceiling function takes values in integers `ℤ`, but we need values in `ℕ` (the natural numbers). These are *not* the same thing!!\n"
"\n"
"Fortunately, Lean provides the \"natural number ceiling function\" written `x ↦ ⌈x⌉₊`, which takes any real number and returns a natural number.\n"
"(You can write these symbols using `\\lceil`, `\\rceil`, and `\\_+`. Or if you're lazy like me, just copy and paste them from elsewhere.)\n"
" For negative inputs, this function returns `0`. For example, `⌈-3.14⌉₊ = 0` and `⌈3.14⌉₊ = 4`.\n"
"\n"
"Now our strategy becomes clear:\n"
"- **Choice of N**: Use `N = ⌈1 / ε⌉₊ + 1`\n"
"- **Why this works**: We have the \"key inequality\": `1 / ε ≤ ⌈1 / ε⌉₊`, which holds by the definition of the ceiling function\n"
"- **Getting strict inequality**: Adding 1 gives us `1 / ε < ⌈1 / ε⌉₊ + 1`\n"
"\n"
"## The Lean Implementation Challenges\n"
"\n"
"In Lean, the first two steps of our natural language proof work fine, but then we encounter the issue of **type coercion** (\"casting\" between different number types). We'll discuss this in more detail later, but again it has to do with the fact that `ℕ`, `ℤ`, `ℚ`, and `ℝ` are all different kinds of things, and we need to be able to move numbers up the \"sophistication\" heirarchy, with natural numbers being the simplest objects and the reals being the most complicated (so much so that we keep postponing their construction).\n"
"\n"
"For example, notice that when we'll write our `have` statement to establish the key inequality:\n"
"\n"
"`have fact : 1 / ε ≤ ⌈1 / ε⌉₊ := by WhateverTheProofIs`\n"
"\n"
"Lean will record it as:\n"
"\n"
"`fact : 1 / ε ≤ ↑⌈1 / ε⌉₊`\n"
"\n"
"Notice the mysterious up arrow `↑`. This represents a coercion function from natural numbers to real numbers:\n"
"\n"
"↑ : ℕ → ℝ\n"
"\n"
"This is because `ℕ`, `ℤ`, `ℚ`, and `ℝ` are all **different** types in Lean's type system (and really, in mathematics, as we'll see when we construct the real numbers)! Even though we think of natural numbers as being \"contained\" in the real numbers, formally they are distinct types of things, and Lean needs explicit coercion functions to convert between them.\n"
"\n"
"*Think of it this way*: the natural number `3 : ℕ` and the fraction `3 / 1 : ℚ` and the real number `3.000 : ℝ` are different objects that just happen to represent the same mathematical value.\n"
"\n"
"The `push_cast` tactic helps manage these coercions, kind of like `ring_nf` but for casting instead of ring operations.\n"
"\n"
"## New Tools You'll Need\n"
"\n"
"- `⌈ ⬝ ⌉₊`: The natural number ceiling function\n"
"- `push_cast`: Tactic that handles coercions between number types\n"
"- `bound`: Solves many routine inequalities\n"
"\n"
"The `bound` tactic can solve many \"trivial\" inequalities once the types are properly aligned.\n"
"\n"
"## Hint:\n"
"\n"
"If you get stuck and don't see a Hint, try backtracking until you do."
msgstr ""

#: Game.Levels.L17Pset.L06
msgid "# Level 3: The Comparison Test\n"
"\n"
"Prove the `ComparisonTest`: if `a n` is dominated by a convergent series,\n"
"then it also converges.\n"
"\n"
"(In lecture 17, we proved a special case of this theorem, when we started studying the Basel Problem.)"
msgstr ""

#: Game.Levels.L16Levels.L01_check
msgid "# Level 1: The Vanishing Term Test\n"
"\n"
"Welcome to the study of infinite series! We now begin one of the most important topics in analysis.\n"
"\n"
"Given a sequence `a : ℕ → ℝ`, we want to understand what it means to add up *all* its terms:\n"
"`a 0 + a 1 + a 2 + a 3 + ...`\n"
"\n"
"Since we can't literally add infinitely many numbers, we instead look at the sequence of **partial sums**:\n"
"\n"
"**Definition (Series):** `Series (a : ℕ → ℝ) : ℕ → ℝ := fun n ↦ ∑ k ∈ range n, a k`\n"
"\n"
"So `Series a n` is the sum of the first `n` terms of `a`.\n"
"\n"
"**Definition (SeriesConv):** A series **converges** if its sequence of partial sums converges:\n"
"`SeriesConv (a : ℕ → ℝ) : Prop := SeqConv (Series a)`\n"
"\n"
"**Definition (SeriesLim):** If the series converges to `L`, we write:\n"
"`SeriesLim (a : ℕ → ℝ) (L : ℝ) : Prop := SeqLim (Series a) L`\n"
"\n"
"---\n"
"\n"
"Your challenge: Prove that **if a series converges, its terms must go to zero**.\n"
"\n"
"This is sometimes called the **nth-term test for divergence**: if the terms don't vanish, the series can't possibly converge!\n"
"\n"
"**Hint:** If the partial sums form a convergent (hence Cauchy) sequence, what can you say about consecutive partial sums? And what's the relationship between `Series a (n+1)` and `Series a n`?\n"
"\n"
"**Warning:** The converse is FALSE! The harmonic series `∑ 1/k` has terms going to zero, but it diverges. So vanishing terms are *necessary* but not *sufficient* for convergence."
msgstr ""

#: Game.Levels.L4Pset.L4Pset1
msgid "Prove that this sequence diverges."
msgstr ""

#: Game.Levels.L15PsetIntro
msgid "# Problem Set 15: Solve these problems in Natural Language:\n"
"\n"
"$\\# 1)$ Let $a_0 := \\sqrt2$, and $a_{n+1}:=\\sqrt{2+\\sqrt{a_n}}$. Prove that $a_n < 2$ holds for all $n$, and that $a_n$ converges.\n"
"\n"
"$\\# 2)$ Calculate $\\lim_{n\\to\\infty}\\left(\\sqrt{n^2+n}-n\\right)$ rigorously.\n"
"\n"
"$\\# 3)$ Show that if a sequence `a : ℕ → ℝ` is convergent,\n"
" then the \"Cesaro-average\" sequence given by:\n"
"\n"
" `b n = (a 0 + a 1 + ... + a (n-1)) / n`\n"
"\n"
"converges, and to the same limit. Give an example of a sequence `a : ℕ → ℝ` which\n"
"does *not* converge, but for which the Cesaro average sequence does converge."
msgstr ""

#: Game.Levels.L3Lecture
msgid "# More on sequences\n"
"\n"
"In Lecture 2, we learned the definition of a sequence `a : ℕ → ℝ` converging to a limit `L`: for any tolerance\n"
"`ε > 0`, there exists a time `N`, so that, for any point after that time, `n ≥ N`, we are within the tolerance, `|a n - L| < ε`.\n"
"\n"
"We also learned how to do something completely trivial with it, namely, show that the constant sequence converges, with that constant as its limit.\n"
"\n"
"Let's step it up a notch, shall we?"
msgstr ""

#: Game.Levels.L12Levels.L02_IterateGap
msgid "Prove `IterateGap`"
msgstr ""

#: Game.Levels.L15Levels.L01_check
msgid "The real numbers are complete; Cauchy sequences in the reals converge to a real number."
msgstr ""

#: GameServer.RpcHandlers
msgid "level completed! 🎉"
msgstr ""

#: Game.Levels.L24Levels.L04
msgid "# The Crown Jewel Achievement!\n"
"\n"
"You've just proved that **closed intervals are compact**! This is one of the most important theorems in all of real analysis.\n"
"\n"
"**What Made This Proof Extraordinary**:\n"
"- **Three Mathematical Universes Colliding**: Your proof beautifully combined:\n"
"  - **Topology** (open covers and balls)\n"
"  - **Real Analysis** (supremums and the LUB property)\n"
"  - **Logic** (proof by contradiction)\n"
"- **The Supremum Trick**: The idea of considering the set of points where finite covering \"reaches\" was pure genius. You turned a global problem (covering all of `[a,b]`) into a supremum problem.\n"
"- **Positive Radius Magic**: The contradiction came from the fact that balls have positive radius - if you can finitely cover up to the supremum, the ball covering the supremum lets you \"jump past\" it.\n"
"\n"
"**Why This Result is Fundamental**:\n"
"- **Calculus Foundation**: Every time you integrate a continuous function on `[a,b]`, you're using this theorem! Continuous functions on compact sets are uniformly continuous, hence integrable.\n"
"- **Optimization**: Every continuous function on `[a,b]` attains its maximum and minimum (extreme value theorem) - because compact sets are where continuous functions behave nicely.\n"
"- **Approximation Theory**: Polynomial approximation theorems (like Weierstrass) rely heavily on compactness of intervals.\n"
"\n"
"**The Historical Significance**: This theorem was the missing piece that made 19th-century analysis rigorous. Before understanding compactness, mathematicians had intuitions about why closed intervals were \"nice\" but couldn't prove it.\n"
"\n"
"**What's Left**: You've proved that all closed intervals are compact. Level 5 will extend this to prove that ANY closed and bounded set is compact, by showing that closed subsets of compact sets inherit compactness.\n"
"\n"
"**The Payoff**: Once you complete Level 5, you'll have the complete Heine-Borel theorem:\n"
"\n"
"`S is compact ⟺ S is closed and bounded`\n"
"\n"
"You could in theory stop at this point, because closed intervals are what we were after for applications to convergence of Riemann sums and uniform continuity. But the full Heine-Borel theorem is a cornerstone of real analysis, so let's finish the job!\n"
"\n"
"**Looking Back**: Your journey from compactness ⟹ boundedness (Level 1) to this deep result shows the power of mathematical abstraction. You've connected the discrete (finite covers), the continuous (supremums), and the topological (open sets) into one unified theory.\n"
"\n"
"You're almost at the summit of one of mathematics' great theorems! 🏔️"
msgstr ""

#: Game.Levels.L4Levels.L01_NonConverge
msgid "NonConvergence"
msgstr ""

#: Game.Levels.L7Levels.L04_ByCases
msgid "## Case Analysis Mastered!\n"
"\n"
"You've now learned how to perform case analysis even when you don't have an existing hypothesis\n"
"to split on. The `by_cases` tactic is a powerful addition to your proof toolkit.\n"
"\n"
"## What You Accomplished\n"
"\n"
"In this level, you proved `EventuallyGeHalfLim` without assuming `L ≠ 0`, making it strictly\n"
"more general than `EventuallyGeHalfLimPos`. The proof was elegant:\n"
"- When `L = 0`, the inequality becomes trivial since both sides equal zero\n"
"- When `L ≠ 0`, you could invoke your earlier theorem\n"
"\n"
"This pattern -- handling edge cases separately, then applying more powerful results in the main\n"
"case -- is ubiquitous throughout mathematics.\n"
"\n"
"## The Power of Case Analysis\n"
"\n"
"The `by_cases` tactic allows you to:\n"
"- **Prove more general theorems** by removing unnecessary assumptions and handling special cases\n"
"- **Organize complex proofs** by separating different scenarios that require different strategies\n"
"- **Handle edge cases systematically** rather than hoping they don't arise\n"
"- **Make logical structure explicit** by formally splitting on conditions that matter\n"
"\n"
"## When to Reach for `by_cases`\n"
"\n"
"You'll find `by_cases` particularly useful when:\n"
"- Your proof strategy differs significantly based on whether some condition holds\n"
"- You need to handle a potential edge case (like zero denominators, empty sets, etc.)\n"
"- You want to generalize a theorem by removing a hypothesis and treating it as a case\n"
"- The problem naturally divides into distinct scenarios\n"
"\n"
"## Looking Ahead\n"
"\n"
"Combined with `cases'` for existing hypotheses and `split_ands` for conjunctions, you now\n"
"have a complete toolkit for working with logical connectives in Lean. These techniques will\n"
"serve you throughout your journey in formal mathematics, from basic analysis to abstract\n"
"algebra and beyond.\n"
"\n"
"The ability to systematically handle all cases is what makes mathematical proofs rigorous and\n"
"complete. You're well on your way to mastering the art of formal proof!"
msgstr ""

#: Game.Levels.L2NewtonsCalculationOfPi.L01_SeqConvDef
msgid "This is where you might find it useful to call `norm_num` and normalize `|0|` to `0`."
msgstr ""

#: Game.Levels.L20Pset.L04
msgid "Prove `Bdd_of_LimAt`"
msgstr ""

#: Game.Levels.L18Pset.L01
msgid "This is the analog of `sum_range_succ` to summing on intervals."
msgstr ""

#: Game.Levels.L1RealAnalysisStory.L06_intro
msgid "For all positive real numbers, this algebraic identity holds."
msgstr ""

#: Game.Levels.L12PsetIntro
msgid "# Problem Set 12\n"
"\n"
"Good luck!"
msgstr ""

#: Game.Levels.L1Pset.L1Pset1
#: Game.Levels.L2Pset.L2Pset1
#: Game.Levels.L3Pset.L3Pset1
#: Game.Levels.L4Pset.L4Pset1
#: Game.Levels.L6Pset.L6Pset1
#: Game.Levels.L7Pset.L7Pset1
#: Game.Levels.L8Pset.L8Pset1
#: Game.Levels.L9Pset.L9Pset1
#: Game.Levels.L10Pset.L10Pset2
#: Game.Levels.L11Pset.L11Pset1
#: Game.Levels.L12Pset.L12Pset1
#: Game.Levels.L13Pset.L13Pset1
#: Game.Levels.L15Pset.L15Pset1
#: Game.Levels.L16Pset.L16Pset1
msgid "Problem 1"
msgstr ""

#: Game.Levels.L1RealAnalysisStory.L05_use
msgid "Write `use 42`, but with `42` replaced by the correct answer. Then how should you finish?"
msgstr ""

#: Game.Levels.L6Levels.L02_LeftRight
msgid "When your goal is to prove an \\\"Or\\\" statement, `P ∨ Q`, you can do that by proving either `P` or `Q`. If you want to prove `P`, then say `left`, and the Goal will turn into `P`."
msgstr ""

#: Game.Levels.L12Levels.L00_SubseqIterate
msgid "The `show` tactic has syntax `show fact by proof`."
msgstr ""

#: Game.Levels.L8PsetIntro
msgid "# Problem Set 8\n"
"\n"
"Good luck!"
msgstr ""

#: Game.Levels.L18Pset.L07
msgid "Prove `AntitoneSeriesOdd`"
msgstr ""

#: Game.Levels.L14Levels.L01_BolzanoWeierstrass
msgid "# 🏆 You Just Proved Bolzano-Weierstrass!\n"
"\n"
"Stop for a moment. Breathe. You've just proved one of the most important theorems in real analysis.\n"
"\n"
"**Every bounded sequence has a Cauchy subsequence.**\n"
"\n"
"This isn't just another result—this is a *cornerstone* of modern mathematics. Textbooks build entire chapters around this theorem. Graduate qualifying exams test it. Researchers use it daily. And you just proved it formally, rigorously, in Lean.\n"
"\n"
"## What Just Happened\n"
"\n"
"The proof was... short. Almost suspiciously short. Just:\n"
"1. Split the absolute value bound using `abs_le`\n"
"2. Case split on whether peaks are unbounded\n"
"3. Extract the appropriate subsequence (monotone or antitone)\n"
"4. Apply the right Cauchy theorem\n"
"\n"
"Done. Twenty lines of code for a theorem that's worth its weight in gold.\n"
"\n"
"**Why was it so short?** Because you built the right foundation. This lecture wasn't about clever tricks—it was about *architecture*. You spent lectures building:\n"
"- `IsCauchy_of_MonotoneBdd` (Lecture 12)\n"
"- `IsCauchy_of_AntitoneBdd` (Pset 12)\n"
"- `MonotoneSubseq_of_BddPeaks` (Lecture 13)\n"
"- `AntitoneSubseq_of_UnBddPeaks` (Pset 13)\n"
"\n"
"When you have the right pieces, the cathedral builds itself.\n"
"\n"
"## The Profound Insight\n"
"\n"
"Here's what Bolzano and Weierstrass understood:\n"
"\n"
"**Boundedness is suffocating.**\n"
"\n"
"If you trap infinitely many values in a finite region, they have nowhere to spread out. They *must* accumulate. They *must* cluster. Convergent behavior isn't a special case—it's *inevitable*.\n"
"\n"
"Your sequence might bounce around chaotically. It might oscillate wildly. It might seem to have no pattern whatsoever. But the moment you say \"it's bounded,\" you've sealed its fate: somewhere within it, convergence is hiding, waiting to be extracted.\n"
"\n"
"## The Dichotomy: Complete\n"
"\n"
"Every sequence falls into exactly one of two categories:\n"
"\n"
"**Has unbounded peaks →** Extract the peaks themselves → Get an antitone bounded subsequence → Cauchy\n"
"\n"
"**Doesn't have unbounded peaks →** Peaks eventually stop → Get a monotone bounded subsequence → Cauchy\n"
"\n"
"There is no third option. There is no escape. Boundedness + infinity → convergence.\n"
"\n"
"This is why the proof by cases works so elegantly. We're not being clever—we're being *exhaustive*. The law of excluded middle gives us both cases, and both roads lead to Rome.\n"
"\n"
"## What This Unlocks\n"
"\n"
"With Bolzano-Weierstrass, you can now prove:\n"
"\n"
"**Extreme Value Theorem:** Continuous functions on closed bounded intervals attain their maximum and minimum. (Why? The sequence of values must have a Cauchy—hence convergent—subsequence, and continuity preserves limits.)\n"
"\n"
"**Heine-Borel Theorem:** Closed and bounded subsets of ℝⁿ are compact. (Sequential compactness = compactness in metric spaces, and you just proved sequential compactness for bounded sets.)\n"
"\n"
"**Existence of solutions:** Optimization problems, differential equations, fixed points—countless existence proofs rely on extracting convergent subsequences from bounded sequences.\n"
"\n"
"**Compactness arguments:** Throughout topology, functional analysis, PDE theory—whenever you see \"compact,\" Bolzano-Weierstrass is lurking nearby.\n"
"\n"
"This theorem is a *skeleton key* for real analysis.\n"
"\n"
"## The Technique: Synthesis\n"
"\n"
"This lecture taught you something crucial about mathematical maturity:\n"
"\n"
"**The best proofs are the shortest ones.**\n"
"\n"
"Not because you're cutting corners, but because you've built the right infrastructure. Compare this proof to what it would look like if you tried to prove Bolzano-Weierstrass from scratch without the lemmas. You'd be drowning in cases, wrestling with constructions, fighting to keep track of which subsequence does what.\n"
"\n"
"Instead, you:\n"
"- Identified the key dichotomy (peaks or no peaks)\n"
"- Proved a result for each case separately (Lectures 12-13, Psets 12-13)\n"
"- Combined them with one simple case split\n"
"\n"
"This is how mathematics should feel at the highest level: each theorem builds naturally on what came before, and the major results feel almost inevitable once you have the right perspective.\n"
"\n"
"## The Bigger Picture: Compactness\n"
"\n"
"In topology, a space is called **sequentially compact** if every sequence has a convergent subsequence. You just proved:\n"
"\n"
"**Bounded subsets of ℝ (or ℚ with the right structure) are sequentially compact.**\n"
"\n"
"In metric spaces, sequential compactness is equivalent to compactness (every open cover has a finite subcover). This connection between sequences and topology is one of the deepest in mathematics.\n"
"\n"
"Compactness is often called \"the next best thing to finiteness.\" Finite sets are easy to work with—you can always find maxima, minima, you can't have infinite descent, etc. Compact sets preserve many of these nice properties. And Bolzano-Weierstrass is what makes boundedness behave \"almost like finiteness.\"\n"
"\n"
"## Historical Legacy\n"
"\n"
"When Bolzano and Weierstrass worked on this theorem in the 19th century, they were doing something revolutionary: making infinity *rigorous*.\n"
"\n"
"Before them, analysis was full of vague intuitions about \"approaching\" and \"tending toward.\" Mathematicians knew calculus worked, but couldn't really explain why. Infinity was mysterious, even suspicious.\n"
"\n"
"Bolzano-Weierstrass (along with Cauchy's work on limits and Weierstrass's ε-δ definitions) changed everything. They showed you could reason about infinite processes with the same precision as finite ones. You could *prove* things about limits, not just calculate them.\n"
"\n"
"This theorem is part of the foundation that transformed calculus from a bag of tricks into *analysis*—a rigorous mathematical discipline.\n"
"\n"
"## What You've Mastered\n"
"\n"
"✓ **Proof by exhaustive case analysis:** Using `by_cases` to split on propositions and handle all possibilities\n"
"\n"
"✓ **Working with absolute values:** Decomposing `|x| ≤ M` into simultaneous bounds with `abs_le`\n"
"\n"
"✓ **Duality arguments:** Seeing how monotone/antitone, increasing/decreasing, upper/lower bounds are mirror images\n"
"\n"
"✓ **Synthesizing results:** Combining multiple lemmas into a cohesive whole\n"
"\n"
"✓ **Mathematical architecture:** Building theories so major theorems become natural consequences\n"
"\n"
"✓ **The power of dichotomies:** Finding the right case split that makes everything fall into place\n"
"\n"
"These skills transcend this particular theorem. You're thinking like a mathematician now.\n"
"\n"
"## Reflection: The Journey\n"
"\n"
"Let's trace where you've been:\n"
"\n"
"**Lecture 12:** You learned about orbits and iteration. You proved bounded monotone sequences are Cauchy by contradiction—if they weren't, gaps would accumulate and violate the bound.\n"
"\n"
"**Lecture 13:** You discovered the peak dichotomy. You proved that without unbounded peaks, you can extract monotone subsequences using clever orbit constructions.\n"
"\n"
"**Psets 12-13:** You filled in the dual results for antitone sequences and sequences with unbounded peaks.\n"
"\n"
"**Today:** You combined everything. The pieces clicked together. The theorem emerged.\n"
"\n"
"This is real mathematics. Not memorizing formulas, not following algorithms—*building*. Constructing a foundation stone by stone, then stepping back to see the edifice you've created.\n"
"\n"
"## Looking Forward\n"
"\n"
"Where do we go from here? With Bolzano-Weierstrass in your toolkit, vast territories of analysis open up:\n"
"\n"
"- **Convergence theorems:** Dominated convergence, monotone convergence, equicontinuity\n"
"- **Functional analysis:** Weak compactness, reflexivity, dual spaces\n"
"- **Optimization:** Existence of extrema, constrained optimization, variational methods\n"
"- **Differential equations:** Existence and uniqueness theorems via fixed points\n"
"- **Topology:** Compactness, connectedness, continuous maps between spaces\n"
"\n"
"Each of these builds on what you've proved today. Bolzano-Weierstrass isn't the end—it's the *beginning* of deep analysis.\n"
"\n"
"## Final Thought\n"
"\n"
"Mathematics has a peculiar beauty: the most powerful theorems are often the simplest to state.\n"
"\n"
"*Every bounded sequence has a Cauchy subsequence.*\n"
"\n"
"Eleven words. A freshman can understand the statement. But hidden in those words is profound insight about the nature of infinity, limits, and convergence. Hidden in the proof is a elegant dichotomy that exhausts all possibilities.\n"
"\n"
"You didn't just prove a theorem today. You glimpsed the architecture of analysis itself—how careful definitions, well-chosen lemmas, and strategic case analysis can tame infinity and make it rigorous.\n"
"\n"
"Bolzano and Weierstrass would be proud. You've carried their torch forward, proving their theorem not just with pencil and paper, but formally, mechanically, in a way that a computer can verify.\n"
"\n"
"**This is real mathematics. And you just did it.**\n"
"\n"
"---\n"
"\n"
"## 🎓 Achievement Unlocked: Bolzano-Weierstrass Theorem\n"
"\n"
"You are now equipped with one of the most powerful tools in real analysis. Use it wisely. Use it well. And remember: bounded sequences can run, but they cannot hide from convergence.\n"
"\n"
"**Onward to new theorems!**"
msgstr ""

#: Game.Levels.L25Levels.L02
msgid "**COURSE COMPLETE!** You've just proven the most fundamental theorem about continuous functions and conquered the final boss of Real Analysis: The Game.\n"
"\n"
"**What you accomplished**: You proved that continuous functions have no \"jumps\"—a property so basic that mathematicians assumed it for millennia without proof. Your proof revealed the intimate connection between:\n"
"- **Topology** (continuity of functions)\n"
"- **Order** (the structure of real numbers)\n"
"- **Completeness** (the Least Upper Bound Principle)\n"
"\n"
"**The deeper significance**: This \"obvious\" theorem actually characterizes what makes ℝ special. In ℚ, continuous functions CAN change sign without crossing zero (like x² - 2). The IVT is really a theorem about the **completeness** of the real line—there are no gaps.\n"
"\n"
"**Your proof technique** was a masterpiece of mathematical reasoning: you used the supremum of a carefully chosen set, then eliminated both f(c) < 0 and f(c) > 0 through elegant contradictions involving continuity. This is analysis at its finest.\n"
"\n"
"**Historical triumph**: You've now rigorously proven what Archimedes used, what Newton assumed, and what Euler took for granted. The theorem they used intuitively for centuries finally has the rigorous foundation it deserves.\n"
"\n"
"**Congratulations!** You've mastered the interplay between limits, continuity, completeness, and proof—the very heart of real analysis. From ε-δ definitions to the deepest theorems about ℝ, you've built mathematics from the ground up.\n"
"\n"
"*Welcome to the ranks of real analysts.*"
msgstr ""

#: Game.Levels.L18Pset.L08
msgid "BddSeriesEven"
msgstr ""

#: Game.Levels.L3Pset.L3Pset3
msgid "# Problem 3\n"
"\n"
"Determine what the limit of the sequence `1 / n ^ 2` is, and prove it.\n"
"\n"
"Hints you may find useful:\n"
"- We have yet to learn about dealing with the square-root function.\n"
"So see if you can be even lazier in your choice of parameters...\n"
"- If you know that `h : 0 < N` holds in the *natural* numbers, then you can prove that that `1 ≤ N` simply by `apply`ing `h`, that is: `have h' : 1 ≤ N := by apply h`. (This would not work for an inequality in the real numbers, since it's in general not true!)"
msgstr ""

#: Game.Levels.L6Levels.L06_Squeeze
msgid "# 🏆 Squeeze Theorem Conquered! 🏆\n"
"\n"
"Magnificent! The Squeeze Theorem is not just mathematically beautiful—it's also incredibly practical and will serve you throughout your mathematical journey.\n"
"\n"
"**Why This Is a Big Deal:**\n"
"The Squeeze Theorem is a workhorse of mathematical analysis. It's the tool that lets us prove challenging convergence results by reducing them to easier problems. Can't directly show that a complex sequence converges? Find two simpler sequences that squeeze it, and you're done!\n"
"\n"
"**Technical Mastery:**\n"
"Notice how your proof elegantly combined multiple techniques: epsilon-N arguments, absolute value manipulation with `abs_lt`, logical decomposition with `split_ands`, and inequality reasoning. This synthesis of tools is what makes advanced mathematical proof possible.\n"
"\n"
"**The Power of Transitivity:**\n"
"The heart of your proof was recognizing that if `L - ε < a(n) ≤ b(n) ≤ c(n) < L + ε`, then by transitivity, `L - ε < b(n) < L + ε`, which is exactly what we needed. This kind of inequality chaining is fundamental to analysis.\n"
"\n"
"**Real-World Applications:**\n"
"This theorem proves convergence for sequences that would be nearly impossible to handle directly. For example:\n"
"- `sin(1/n) → 0` (squeezed between `-1/n` and `1/n`)\n"
"- Recursive sequences where exact formulas are intractable\n"
"- Sequences defined by complex geometric or probabilistic processes\n"
"\n"
"**Looking Forward:**\n"
"The Squeeze Theorem will reappear throughout analysis: in proving continuity results, establishing uniform convergence, and even in advanced topics like measure theory. You've now mastered not just the theorem itself, but the proof techniques that make it work.\n"
"\n"
"You're developing the kind of mathematical sophistication that allows you to see structure and opportunity where others see only complexity. That's the mark of a true mathematician!"
msgstr ""

#: Game.Levels.L19Levels.L03
msgid "`|∑ x ∈ s, f x ≤ ∑ x ∈ s, |f x|`. (More general version of `Series_abs_add`)"
msgstr ""

#: Game.Levels.L3Levels.L02_OneOverN
msgid "Simplify the absolute value: `have f2 : |1 / (n : ℝ)| = 1 / n := by bound`. Note the explicit casting to the reals, so that this is not a statement about natural numbers!"
msgstr ""

#: Game.Levels.L2NewtonsCalculationOfPi.L01_SeqConvDef
msgid "# 🎉 Excellent Work! 🎉\n"
"\n"
"You've just completed your first rigorous limit proof! Let's reflect on what you accomplished and the key insights from this foundational example.\n"
"\n"
"**What you just proved:**\n"
"You showed that if a sequence always outputs the same value `L`, then it converges to `L`. The Machinist's response to any tolerance demand `ε > 0` is beautifully simple: 'I can meet that specification immediately with any production run length `N`, because I'm already producing exactly what you want!'\n"
"\n"
"**Key Insights from this proof:**\n"
"\n"
"1. **The `change` tactic**: You learned how to unfold a definition to see what you're really trying to prove. `SeqLim a L` became the concrete epsilon-N condition.\n"
"\n"
"2. **The logical structure**: The proof followed the natural flow of the definition:\n"
"   - `intro ε hε` handled 'for every ε > 0'\n"
"   - `use 1` provided the witness `N` (any number works!)\n"
"   - `intro n hn` handled '∀ n ≥ N'\n"
"   - Then algebraic manipulation showed that `|a n - L| = |L - L| = |0|`\n"
"   - Then numerical normalization gave that `|0| = 0`, and `hε` finally proved that `|a n - L| < ε`.\n"
"\n"
"**The Beautiful Simplicity:**\n"
"This is the Machinist's dream scenario—no matter how demanding the engineer's tolerance requirements, the constant factory can satisfy them instantly. There's no trade-off between precision and effort because the output is already perfect!\n"
"\n"
"You're building the foundation for all of calculus. Every limit, derivative, and integral ultimately rests on arguments like this one.\n"
"\n"
"## Check in, in Natural Language\n"
"\n"
"Let's step back from the formal Lean proof and understand what we just proved in plain English.\n"
"\n"
"**Theorem (in natural language):** If a sequence has the same value for every term, then it converges to that constant value.\n"
"\n"
"**Proof:** Suppose we have a sequence $a(n)$ where $a(n) = L$ for all $n$, and we want to show that this sequence converges to $L$.\n"
"\n"
"By definition, we need to show that for any tolerance $\\varepsilon > 0$, we can find a point $N$ such that for all $n \\geq N$, we have $|a(n) - L| < \\varepsilon$.\n"
"\n"
"This is almost trivially simple: since $a(n) = L$ for every $n$, we have:\n"
"$$|a(n) - L| = |L - L| = |0| = 0$$\n"
"\n"
"Since $0 < \\varepsilon$ for any positive $\\varepsilon$, we can choose any $N$ we want (we chose $N = 1$ in the proof, but $N = 0$ or $N = 1000$ would work equally well).\n"
"\n"
"Therefore, for any $n \\geq N$, we have $|a(n) - L| = 0 < \\varepsilon$, which proves convergence.\n"
"**QED**"
msgstr ""

#: Game.Levels.L18Levels.L01
msgid "# Congratulations!\n"
"\n"
"You've just proven one of the most important theorems in the theory of infinite series!\n"
"\n"
"## What We've Learned\n"
"\n"
"The theorem **absolute convergence implies convergence** gives us a powerful tool: to show a series converges, it often suffices to show it converges absolutely. This is frequently easier because we can ignore the signs of the terms.\n"
"\n"
"## Key Technique\n"
"\n"
"The proof relied on the **Cauchy criterion**: a series converges if and only if its partial sums form a Cauchy sequence. We showed that if the series of absolute values is Cauchy, then the original series must be Cauchy too, using the triangle inequality to bound the partial sums.\n"
"\n"
"## Why This Matters\n"
"\n"
"This theorem is the foundation for:\n"
"- **Comparison tests**: If $|a_n| \\leq b_n$ and $\\sum b_n$ converges, then $\\sum a_n$ converges absolutely (hence converges)\n"
"- **Rearrangement theorems**: Absolutely convergent series can be rearranged without changing their sum\n"
"- **Function series**: Power series and Fourier series often converge absolutely in their domains\n"
"\n"
"## The Converse is False!\n"
"\n"
"Remember: The converse is *not* true. There exist series that converge but do not converge absolutely. These are called **conditionally convergent** series, and they behave very differently from absolutely convergent series (as we'll see in the next level with the Alternating Series Test)!\n"
"\n"
"The distinction between absolute and conditional convergence is one of the most important concepts in real analysis."
msgstr ""

#: Game.Levels.L18Pset.L04
msgid "Prove `CoherenceOfReals`"
msgstr ""

#: Game.Levels.L16Lecture
msgid "Lecture 16: Series"
msgstr ""

#: Game.Levels.L1Pset.L1Pset1
msgid "Given that `f (u) = 2 * u + 1` for all `u`, prove that there exists some `a` such that `f (3) = a`."
msgstr ""

#: Game.Levels.L11Levels.L03_IsBddOfCauchy
msgid "# Level 3: Cauchy Implies Bounded\n"
"\n"
"We've seen that convergent sequences are bounded. Now we'll prove that **Cauchy sequences are also bounded**—without ever mentioning a limit!\n"
"\n"
"This is a beautiful result because it shows that the Cauchy property alone (terms getting close to *each other*) is strong enough to guarantee boundedness, even though we don't know if the sequence converges or *where* it might converge to.\n"
"\n"
"## The Setup\n"
"\n"
"Given:\n"
"- `a : ℕ → ℝ` is Cauchy\n"
"\n"
"Prove: `a` is bounded (i.e., `∃ M, ∀ n, |a n| ≤ M`)\n"
"\n"
"## The Key Insight\n"
"\n"
"If a sequence is Cauchy, then eventually all terms are clustered together. Specifically, if we use `ε = 1` in the Cauchy definition, then for all `m ≥ N`, we have:\n"
"\n"
"$|a_m - a_N| < 1$\n"
"\n"
"This means all terms after `N` stay within distance 1 of $a_N$, so they're all bounded by $|a_N| + 1$.\n"
"\n"
"But what about the finitely many terms *before* `N`? We just take their maximum (or what's technically easier: their sum)!\n"
"\n"
"## Strategy\n"
"\n"
"1. **Apply Cauchy with `ε = 1`**: Get an `N` such that all terms after `N` are within distance 1 of $a_N$\n"
"2. **Bound the tail**: Show that for `m ≥ N`, we have $|a_m| ≤ |a_N| + 1$ using the triangle inequality\n"
"3. **Bound the initial segment**: The terms $a_0, a_1, ..., a_{N-1}$ are finitely many, so their sum of absolute values bounds each one\n"
"4. **Combine**: Take $M = |a_N| + 1 + \\sum_{k < N} |a_k|$ as your overall bound\n"
"5. **Case split**: Use `by_cases` to handle `m < N` versus `m ≥ N` separately\n"
"\n"
"Good luck!"
msgstr ""

#: Game.Levels.L2NewtonsCalculationOfPi.L01_SeqConvDef
msgid "# Level 1: The Main Definition\n"
"\n"
"Our first step to making Newton's argument rigorous is\n"
"to spell out *exactly* what we mean by a sequence\n"
"$a_n$ converging. It will take a little work to build up to the definition, and more importantly, *why*\n"
"that might seem like a reasonable definition to have.\n"
"\n"
"But first: for some reason (likely Euler is to blame), mathematics has *two* completely different conventions for how to write functions. For general functions $f : \\mathbb R \\to\\mathbb R$,\n"
"we write $f(x)$, with parentheses. But when work with sequences, $a_n$, meaning,\n"
"$a_0, a_1, a_2, \\dots$, we bizarely switch instead to subscripts.\n"
"Why? Historical accident.\n"
"A sequence is nothing but a function whose \"domain\" (that is, the set of\n"
"inputs to the function) is the natural numbers; so we will break\n"
"with tradition and unify the two conventions, henceforth writing\n"
"$a : \\mathbb N \\to \\mathbb R$ for sequences of real numbers, $a (0), a (1),\n"
"a (2), \\dots$.\n"
"\n"
"Now, the definition that mathematicians eventually came up with\n"
"for what it means for a sequence to converge, was so intricate (at least\n"
"at first sight) that it had to be invented *twice*!\n"
"The eventual formulation crystallized through the work of Karl Weierstrass in the 1860s, who transformed analysis from an intuitive art into a rigorous science. However, the seeds of this idea appeared much earlier in the work of Bernard Bolzano. In the 1810s and 1820s, Bolzano was developing remarkably modern ideas about continuity and limits, but he was too far ahead of his time for the mathematical community to accept these abstract concepts.\n"
"Only by Weierstrass's time -- a half-century later -- did these ideas catch on.\n"
"\n"
"Without further ado, here it is:\n"
"\n"
"Given a sequence `a : ℕ → ℝ` and a real number `L : ℝ`, we\n"
"write `lim a = L` and\n"
"say that the sequence `a` **converges** to `L`,\n"
" if:\n"
"\n"
"For every `ε > 0`, there exists `N : ℕ` such that, for all `n ≥ N`, we have `|a (n) - L| < ε`.\n"
"\n"
"\n"
"This definition is probably not the first, or second, or tenth thing you might've come up with.\n"
"But over time, I hope you'll come to see that it\n"
" embodies a beautiful negotiation between precision and effort.\n"
"\n"
" I like to think of it as a conversation between an Engineer and a Machinist. The Engineer arrives with specifications: 'We're going to make this widget, and I need its length to be 1 foot, with an error tolerance\n"
" of 1/100 of an inch'. The Machinist replies: 'Sure, I can do that, but I'll have to run my special equipment for at least 10 hours to guarantee that tolerance.' The Enginner\n"
" replies: 'I'm sorry, I misspoke, can we change the tolerance\n"
" to 1/1000 of an inch?' The Machinist replies: 'Oof, yeah we can do it, but it'll cost ya. I'll need at least 40 hours of operation, but after that, I'll guarantee it.'\n"
"\n"
"As long as this conversation can continue regardless of *whatever* tolerance `ε > 0` the Engineer requires, with the Machinist\n"
"always being able to reply with a finite minimum number of hours `N`,\n"
"after which the tolerance will be achieved, we can say\n"
"that the equipment **converges**.\n"
"\n"
"Now let's read Weierstrauss's (or is it Bolzano's?) definition again. We have some process\n"
"that at time `n` returns a reading `a (n)` (think: widget length). Our ultimate goal is to make the length `L`. If\n"
"for any tolerance `ε > 0`, no matter how small, there will always exist some minimum\n"
"time `N`, so that, for any future time, `n ≥ N`,\n"
"we are guaranteed to be within that tolerance, `|a (n) - L| < ε`, that's exactly the condition under which we'll\n"
"say that the sequence `a (n)` **converges** to `L`.\n"
"\n"
"[![A Sequence Converging](images/SeqLim.jpg)](https://en.wikipedia.org/wiki/Limit_of_a_sequence)\n"
"\n"
"What makes this definition so powerful is its universality. The Machinist is essentially promising: 'Give me *any* tolerance requirement, no matter how stringent, and I can meet it -- though I might need more resources (larger `N`) for tighter specifications.'\n"
"\n"
"\n"
"Notice something else about the definition: It makes no mention of something happening \"eventually\", or \"at infinity\" or any other wishy-washy squirm words. We have traded the ambiguity of speaking about infinity for the precision of existential and universal quantifiers. No more hand-waving about what happens \"as `n` gets large\" - instead, we have a concrete challenge: given *any* tolerance `ε`, can you find a specific threshold `N`? *That* idea was the key breakthrough that allowed Calculus to enter the realm of rigorous mathematics.\n"
"\n"
"In Lean, the definition is written like so:\n"
"\n"
"`def SeqLim (a : ℕ → ℝ) (L : ℝ) : Prop :=\n"
"  ∀ ε > 0, ∃ N : ℕ, ∀ n ≥ N, |a n - L| < ε`\n"
"\n"
"This syntax should be familiar from the `have` tactic you already know and love.\n"
"The special symbol `def` (instead of `have`) means that we're about to define something, and\n"
"`SeqLim` is its name (for sequence limit, of course; but we could have called it whatever we want). Then our assumptions are a sequence `a : ℕ → ℝ` and\n"
"some real number `L : ℝ`. Then after the colon `:` goes our output, which in this case is `Prop`, that is, a statement (proposition) that can be true or false. So `SeqLim` is really a function that takes a sequence and hypothetical limiting value, and returns true or false based on whether\n"
"the condition is satisfied. Then comes a colon-equals `:=`, after which the\n"
"exact condition to be tested is specified. And the condition is what we already said, for all epsilon, yadda yadda. The big difference is that you can write `have` inside a proof, but you can't write `def` inside a proof;\n"
"`def` is reserved for making global definitions that\n"
"can be referenced forever once they're introduced.\n"
"Notice that on the right hand side, the list\n"
"of Definitions now includes `SeqLim`, and, as usual,\n"
"if you forget what it means, you can click on it for a reminder.\n"
"\n"
"Let's try out the definition in practice!\n"
"\n"
"**Your Task**\n"
"\n"
"Prove that the constant sequence converges to the same constant.\n"
"That is, suppose that you have a sequence `a : ℕ → ℝ`, and there's a real number\n"
"`L`, and a hypothesis that, for all values of `n`, we have  `a (n) = L`; then prove that `a` does converge, and converges to `L`. This is the simplest possible case: if our 'factory' always produces the exact target value `L`, then we can meet any tolerance requirement immediately!\n"
"\n"
"You may find useful a new tactic called `change`. It allows you to replace a goal (or hypothesis) by\n"
"something that is definitionally equal to it. In our example here,\n"
"You will see the goal as `SeqLim a L`. What are you supposed to do with that,\n"
"how can you make progress? Well, if you remember how `SeqLim` is defined,\n"
"then you can replace the goal with the definition, by writing\n"
"\n"
"`change ∀ ε > 0, ∃ N : ℕ, ∀ n ≥ N, |a n - L| < ε`\n"
"\n"
"Lean will then change the goal to its definition.\n"
"Remember that `ε`, `N`, and `n` are all dummy variables\n"
"here, so you can have some fun:\n"
"\n"
"`change ∀ Alice > 0, ∃ Bob : ℕ, ∀ blah ≥ Bob, |a blah - L| < Alice`\n"
"\n"
"This may come in handy later. (Not Alice and Bob *per se*, but the ability to give better names for dummy variables, so as not to clash with already existing variable names...)\n"
"\n"
"**⚠️⚠️⚠️ CAUTION ⚠️⚠️⚠️** Remember how Lean *must* have space after a function name, it won't accept `f(x)` but instead requires `f (x)`? Well... it's the other way around for absolute\n"
"values. Lean won't accept a space after an absolute value.\n"
"So if you write `| a n - L|`, you'll get an error message.\n"
"Same with `|a n - L |` -- the space at the end is the problem. Sorry! I didn't write the syntax.\n"
"\n"
"**Normalizing Numerical Values**: And one last tactic you might also find useful is `norm_num` (for normalizing numerical values); it evaluates numerical expressions and proves equalities/inequalities involving concrete numbers. For example, if you're stuck with an `|0|` at some point,\n"
"and you want to convert it to plain old `0`, try calling `norm_num`.\n"
"\n"
"Ok, get to it!"
msgstr ""

#: Game.Levels.L6Levels.L04_Cases'
msgid "Cases'"
msgstr ""

#: Game.Levels.L5Lecture
msgid "# More on sequences\n"
"\n"
"\n"
"The so-called Algebraic Limit Theorem for sequences says that: if `a` and `b` are two sequences, `a b : ℕ → ℝ`, and `L` and `M` are two real numbers, with `lim a = L` and `lim b = M`, then:\n"
"\n"
"- (i) for any constant `c`, `lim c * a = c * L`\n"
"- (ii) `lim (a + b) = L + M`\n"
"- (iii) `lim (a * b) = L * M`, and\n"
"- (iv) `lim (a / b) = L / M`, as long as `M ≠ 0`.\n"
"\n"
"Let's get started."
msgstr ""

#: Game.Levels.L20PsetIntro
msgid "# Problem Set 20\n"
"\n"
"$\\# 1)$ Suppose a function $f$ has the following property: There exist two sequences, $x_n, y_n$, both never equal to $c$ and both converging to $c$, but with different sequential limits: $\\lim_{n\\to\\infty}f(x_n) \\ne \\lim_{n\\to\\infty}f(y_n)$. Show that the function limit $\\lim_{x \\to c}f(x)$ does not exist.\n"
"\n"
"$\\# 2)$ Determine whether the function $f (x) = \\sin(1/x)$ has a limit as $x\\to0$. (You may wish to plot it, say, in Desmos.) Either way, prove your claim. [Hint: Consider the sequences $x_n=1/(2n\\pi)$ and $y_n=1/(2n\\pi + \\pi/2)$.]\n"
"\n"
"$\\# 3)$ Determine whether the function $f (x) = x\\sin(1/x)$ has a limit as $x\\to0$. (Again, you may wish to plot it, say, in Desmos.) Either way, prove your claim.\n"
"\n"
"$\\# 4)$ True or False (give a proof or counterexample): If $\\lim_{x\\to c}f(x)=0$, then for any function $g$ (defined near $c$), $\\lim_{x\\to c}f(x)g(x)=0$.\n"
"\n"
"\n"
"$\\# 5)$ Compute the limit or prove that it doesn't exist: $\\lim_{x\\to 6}\\frac{x-6}{|x-6|}$."
msgstr ""

#: Game.Levels.L8Levels.L03_Induction'
msgid "The syntax for induction is: `induction' n with k hk`. This means: apply induction on the\n"
"variable `n`, use `k` for the new dummy variable (which could be `n` itself), and `hk` for\n"
"the induction hypothesis on `k`."
msgstr ""

#: Game.Levels.L21Lecture
msgid "Lecture 21: Function Limits II"
msgstr ""

#: Game.Levels.L1RealAnalysisStory.L07_specialize
msgid "# Using universal statements\n"
"\n"
"Now let's learn the flip side of `intro`. You have already learned that:\n"
"- if you have `∃` in the goal, you write `use` to provide a specific value. And\n"
"- if you have `∀` in the goal, you write `intro` to introduce an arbitrary variable\n"
"\n"
"But what if you have `∀` in a *hypothesis* and you want to use it for a particular value?\n"
"\n"
"For a concrete example, suppose you have:\n"
"- A positive real number `t`; that is, a real number `t`, together with a hypothesis, say, `t_pos` that `t > 0`\n"
"- A function `f : ℝ → ℝ`\n"
"- A hypothesis `hf : ∀ x > 0, f (x) = x^2`, meaning \"for all x positive, f (x) equals x²\". (Note that you *have* to put a space after `f` before `(x)` or else Lean will be very angry with you! In fact, Lean will often drop unnecessary parentheses, so you'll see `f x` instead of `f (x)` -- and again, definitely *not* `f(x)`.)\n"
"- And you want to prove the goal `f (t) = t^2`.\n"
"\n"
"Can you use `apply hf`? No! The hypothesis `hf` says \"for all positive x, f (x) = x²\" but the goal asks specifically about `f (t) = t²`. They're not  the same.\n"
"\n"
"This is where the `specialize` command comes in. You can write `specialize hf t` to specialize the statement `hf` to the particular value `t`. This transforms `hf` from \"∀ x > 0, f (x) = x²\" into \"t > 0 → f (t) = t²\". Just like we had to `intro` multiple times (once for the dummy variable name, and again to name the hypothesis), we can specialize multiple times; so you can now write `specialize hf t_pos`. Or you can kill two birds with one stone via: `specialize hf t t_pos`.\n"
"\n"
"I'm sure you can solve the goal from there yourself!"
msgstr ""

#: Game.Levels.L22Pset.L01
msgid "# Level 1: Pointwise of Uniform Convergence\n"
"\n"
"Prove that if a sequence of functions converges uniformly to a limit function,\n"
"then it also converges pointwise."
msgstr ""

#: Game.Levels.L4Levels.L01_NonConverge
msgid "Usage: `have factName : |x + y| ≤ |x| + |y| := by apply abs_add`"
msgstr ""

#: Game.Levels.L12Levels.L01_Choose
msgid "Try starting your proof with `choose τ hτBnd hτP using h`."
msgstr ""

#: Game.Levels.L24Levels.L04
msgid "Heine-Borel Theorem: Part 2a"
msgstr ""

#: Game.Levels.L20Levels.L02
msgid "`∀ ε > 0, ∃ δ > 0, ∀ x, |x - c| < δ → |f x - f c| < ε`\n"
"\n"
"\n"
"The function `f` is continuous at `x = c`."
msgstr ""

#: Game.Levels.L4Levels.L01_NonConverge
msgid "Usage: `have factName : |-x| = |x| := by apply abs_neg`"
msgstr ""

#: Game.Levels.L3Levels.L01_ArchProp
msgid "The `bound` tactic can solve many \\\"trivial\\\" inequalities involving standard functions and basic arithmetic."
msgstr ""

#: Game.Levels.L9Levels.L05_BddOfConv
msgid "# Level 2: Bounded\n"
"\n"
"Welcome to one of the most fundamental results in real analysis: **convergent sequences are bounded**! This theorem tells us that if a sequence converges to a limit, it can't wander off to infinity—it must stay within some finite region.\n"
"\n"
"## The Goal\n"
"\n"
"Prove that if `a : ℕ → ℝ` converges to a nonzero limit `L`, then `a` is bounded (i.e., there exists some `M > 0` such that `|a n| ≤ M` for all `n`).\n"
"\n"
"**Note:** The case `L = 0` will be handled in the exercises. For now, we focus on nonzero limits.\n"
"\n"
"## The Big Idea\n"
"\n"
"Think about what convergence means: eventually, all terms get close to `L`. So for large `n`, we have `|a n| ≤ 2|L|` (approximately).\n"
"\n"
"But what about the **finitely many terms before** the sequence gets close to `L`? That's where your `TermLeSum` theorem from Level 1 comes in! You can bound those initial terms by their finite sum.\n"
"\n"
"### The Strategy:\n"
"\n"
"1. **Eventually bounded:** Use `EventuallyBdd_of_SeqConv` to find an `N` such that `|a n| ≤ 2|L|` for all `n ≥ N`\n"
"\n"
"2. **Initially bounded:** For `n < N`, use `TermLeSum` to show `|a n| ≤ ∑ k ∈ range N, |a k|`\n"
"\n"
"3. **Global bound:** Combine both parts with:\n"
"   ```\n"
"   M = 2 * |L| + ∑ k ∈ range N, |a k|\n"
"   ```\n"
"\n"
"   This works because:\n"
"   - For `n ≥ N`: the term `|a n|` is covered by `2|L|`\n"
"   - For `n < N`: the term `|a n|` is covered by the sum\n"
"\n"
"4. **Prove `M > 0`:** Show that your bound is positive (needed for the definition of `SeqBdd`)\n"
"\n"
"5. **Prove `∀ n, |a n| ≤ M`:** Split into cases based on whether `n ≥ N` or `n < N`\n"
"\n"
"## New Tools You'll Need\n"
"\n"
"### `SeqBdd`\n"
"Definition: A sequence `a : ℕ → ℝ` is **bounded** if `∃ M > 0, ∀ n, |a n| ≤ M`\n"
"\n"
"## Your Mission\n"
"\n"
"Construct the bound `M`, prove it's positive, then verify it works for all terms by splitting into the two cases. Let your `TermLeSum` theorem shine!\n"
"\n"
"Good luck! 🚀"
msgstr ""

#: Game.Levels.L24Levels.L05
msgid "A point `a : α` is in the `lefts` of a finite set `s : Finset (α ⊕ β)` if and only if the element `Sum.inl a` is in `s`."
msgstr ""

#: Game.Levels.L19Levels.L01
msgid "If `s ⊆ t`, and `0 ≤ f i`, for all `i ∈ t`, then `∑ i ∈ s, f i ≤ ∑ i ∈ t, f i`."
msgstr ""

#: Game.Levels.L1Pset.L1Pset5
#: Game.Levels.L6Pset.L6Pset5
#: Game.Levels.L10Pset.L10Pset6
msgid "Problem 5"
msgstr ""

#: Game.Levels.L9Levels.L05_BddOfConv
msgid "Bounded"
msgstr ""

#: Game.Levels.L12Pset.L12Pset1
msgid "`(a : X → Y) {i j} (hij : i ≤ j) : a j ≤ a i`\n"
"\n"
"A sequence `a : X → Y` is said to be `Antitone` if `a m ≤ a n` whenever `n ≤ m` (note that `n` and `m` were reversed)."
msgstr ""
